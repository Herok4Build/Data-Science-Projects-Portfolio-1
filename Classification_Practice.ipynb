{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52f1310",
   "metadata": {},
   "source": [
    "<h1>Practice With Classification</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d20136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe74b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:  https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification\n",
    "\n",
    "\n",
    "def generateData1():\n",
    "    from sklearn.datasets import make_classification\n",
    "    generated_data, generated_labels = make_classification(n_samples=40000, n_features=67,n_informative=6,\n",
    "                                     n_redundant=21,n_classes=4,n_clusters_per_class=3,\n",
    "                                     class_sep=0.85, random_state=4)\n",
    "    return generated_data, generated_labels\n",
    "#Generated a dataset for classification\n",
    "generated_data, generated_labels=generateData1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86af2fb-c912-4a2d-81c9-f367f23ec860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d25078",
   "metadata": {},
   "source": [
    "<h2>Printing the Data</h2>\n",
    "<p>First going to print the data to be able to observe some of the features and entries. Then move forward to preprocessing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee85fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55886552 -1.0367371  -2.0716188  ... -1.66748974  0.88442319\n",
      "   2.47414118]\n",
      " [-0.36649363  3.99879789 -0.94638273 ... -2.37814551 -0.76884534\n",
      "  -1.0220301 ]\n",
      " [-1.0572081   0.97359163  0.34744335 ...  1.12169577 -2.40200316\n",
      "   0.56310249]\n",
      " ...\n",
      " [ 0.78227173 -0.47473335 -1.01507181 ...  1.02149934  1.93028971\n",
      "  -0.77386558]\n",
      " [ 0.65287134 -0.32653986 -0.5734769  ...  1.01438409 -1.29947182\n",
      "  -1.83709253]\n",
      " [-0.33382408  0.8938808   0.02252798 ... -1.13487992  0.09518901\n",
      "   0.58224631]]\n"
     ]
    }
   ],
   "source": [
    "print(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3199b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6   \\\n",
      "0      0.558866 -1.036737 -2.071619  2.615634  0.251788 -0.208035  2.895468   \n",
      "1     -0.366494  3.998798 -0.946383 -0.635905  2.286920 -0.637968 -1.108372   \n",
      "2     -1.057208  0.973592  0.347443 -1.655197  2.006350  0.794712 -0.900860   \n",
      "3      1.386458 -0.462859  1.708425 -0.692245 -1.184841 -0.443195 -0.265234   \n",
      "4     -0.675302 -1.535932  1.267888  1.639375 -0.236435 -1.173418  1.149061   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "39995  0.853123 -3.544765  1.625326  0.128059  1.139331  0.728333  0.815937   \n",
      "39996 -0.473624 -2.987561 -0.541470 -0.689567  0.253457 -0.221994  1.305095   \n",
      "39997  0.782272 -0.474733 -1.015072  0.227328  0.263934  0.229079  2.961405   \n",
      "39998  0.652871 -0.326540 -0.573477 -0.997861  2.130370 -0.381276 -2.629324   \n",
      "39999 -0.333824  0.893881  0.022528  0.663176  1.381133  1.004063  0.839596   \n",
      "\n",
      "             7         8         9   ...        57        58        59  \\\n",
      "0      1.198842  0.145180  1.080346  ...  1.892684  0.836829 -1.154116   \n",
      "1      0.385278 -0.520651 -0.200035  ... -0.327254 -1.786240 -1.581214   \n",
      "2      1.090486 -0.540597 -0.721043  ...  0.010024  0.135420  0.655283   \n",
      "3     -0.690467 -0.103353 -0.257949  ...  0.461589  1.174917 -1.349465   \n",
      "4     -0.513452  0.633918 -0.816238  ...  1.111512  0.767437 -1.159393   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "39995 -0.370747 -1.022110 -0.444927  ...  0.867935  1.961165 -1.342611   \n",
      "39996 -0.341721  1.161531  0.124060  ...  1.504860  2.191502 -4.111858   \n",
      "39997 -0.066889 -1.787637 -1.406811  ...  1.396869 -0.188328 -0.744552   \n",
      "39998  0.524710  0.664695 -0.629392  ... -1.020037 -0.045849  0.437240   \n",
      "39999  0.079279 -0.338432  1.294211  ...  0.561051  0.041653 -0.653239   \n",
      "\n",
      "             60        61        62        63        64        65        66  \n",
      "0      1.666794 -0.899628 -0.234645 -1.009528 -1.667490  0.884423  2.474141  \n",
      "1     -2.022363  0.396948  0.838982 -0.389692 -2.378146 -0.768845 -1.022030  \n",
      "2      1.293106 -0.619047  0.376654 -0.870834  1.121696 -2.402003  0.563102  \n",
      "3     -3.061563 -0.442438  1.056667 -1.341212  1.128780  0.788385  0.292775  \n",
      "4      3.272597 -2.224216 -1.437791 -0.189640 -0.155901  0.729326 -2.186898  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "39995 -0.018051 -1.682326 -1.220616 -0.670869 -0.451688  2.706436 -0.190048  \n",
      "39996 -3.695702 -1.997050 -0.038346  0.779446 -1.424520  4.789480 -0.322352  \n",
      "39997  0.916445  0.568651 -1.408191  0.564410  1.021499  1.930290 -0.773866  \n",
      "39998  3.007094 -2.000006 -1.600839  0.938161  1.014384 -1.299472 -1.837093  \n",
      "39999 -2.022648  0.683579  1.271801 -0.004906 -1.134880  0.095189  0.582246  \n",
      "\n",
      "[40000 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "generated_data_dataframe = pd.DataFrame(data=generated_data)\n",
    "scalerObject = StandardScaler().fit(generated_data_dataframe)\n",
    "standardized_generated_dataframe = scalerObject.transform(generated_data_dataframe)\n",
    "print(generated_data_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b6a98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.56203181 -0.31366006 -2.0805219  ... -1.65797078  0.41370309\n",
      "   2.47499216]\n",
      " [-0.3660114   1.65838212 -0.95197803 ... -2.36722943 -0.36008486\n",
      "  -1.0264752 ]\n",
      " [-1.05872933  0.47363524  0.34565145 ...  1.12573131 -1.12446028\n",
      "   0.56105859]\n",
      " ...\n",
      " [ 0.78608603 -0.09356526 -1.02086904 ...  1.02573186  0.90320548\n",
      "  -0.77793476]\n",
      " [ 0.65631031 -0.03552896 -0.57797599 ...  1.0186306  -0.60843675\n",
      "  -1.84277231]\n",
      " [-0.3332471   0.44241848  0.01978094 ... -1.12640805  0.04431367\n",
      "   0.5802314 ]]\n"
     ]
    }
   ],
   "source": [
    "print(standardized_generated_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c23e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=2)\n",
      "For  2  features: \n",
      "\n",
      "[[ 1.39242057 -0.06182259]\n",
      " [-0.59950577  0.61543763]\n",
      " [-0.50615914  0.32379436]\n",
      " ...\n",
      " [ 0.7848968  -0.80211247]\n",
      " [-0.51528767 -0.92363826]\n",
      " [-0.00433482  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=3)\n",
      "For  3  features: \n",
      "\n",
      "[[ 1.4820108   1.39242057 -0.06182259]\n",
      " [-0.33590322 -0.59950577  0.61543763]\n",
      " [-0.73089161 -0.50615914  0.32379436]\n",
      " ...\n",
      " [ 0.14106163  0.7848968  -0.80211247]\n",
      " [ 0.38289066 -0.51528767 -0.92363826]\n",
      " [-0.58159775 -0.00433482  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=4)\n",
      "For  4  features: \n",
      "\n",
      "[[ 1.4820108   1.39242057 -0.51858044 -0.06182259]\n",
      " [-0.33590322 -0.59950577  0.35894225  0.61543763]\n",
      " [-0.73089161 -0.50615914 -0.36934665  0.32379436]\n",
      " ...\n",
      " [ 0.14106163  0.7848968  -1.27003793 -0.80211247]\n",
      " [ 0.38289066 -0.51528767  0.19156057 -0.92363826]\n",
      " [-0.58159775 -0.00433482 -0.08401367  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=5)\n",
      "For  5  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   1.39242057 -0.51858044 -0.06182259]\n",
      " [-0.35328617 -0.33590322 -0.59950577  0.35894225  0.61543763]\n",
      " [-0.26103098 -0.73089161 -0.50615914 -0.36934665  0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163  0.7848968  -1.27003793 -0.80211247]\n",
      " [-1.02946779  0.38289066 -0.51528767  0.19156057 -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.00433482 -0.08401367  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=6)\n",
      "For  6  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855  1.39242057 -0.51858044 -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 -0.59950577  0.35894225  0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 -0.50615914 -0.36934665  0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978  0.7848968  -1.27003793 -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 -0.51528767  0.19156057 -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 -0.00433482 -0.08401367  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=7)\n",
      "For  7  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855 ... -0.51858044  0.16507973\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ...  0.35894225 -0.55629257\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -0.36934665 -0.20552952\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ... -1.27003793  0.20212378\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ...  0.19156057  0.52872378\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ... -0.08401367 -0.6476322\n",
      "   0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=8)\n",
      "For  8  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855 ...  0.16507973  0.54125354\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ... -0.55629257 -0.83817178\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -0.20552952  0.40152665\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ...  0.20212378  0.26068818\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ...  0.52872378  1.04241002\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ... -0.6476322  -0.8382785\n",
      "   0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=9)\n",
      "For  9  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855 ...  0.16507973  0.54125354\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ... -0.55629257 -0.83817178\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -0.20552952  0.40152665\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ...  0.20212378  0.26068818\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ...  0.52872378  1.04241002\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ... -0.6476322  -0.8382785\n",
      "   0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest()\n",
      "For  10  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855 ...  1.55245915  0.54125354\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ... -0.68410238 -0.83817178\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -1.00096733  0.40152665\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ...  1.02405554  0.26068818\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ... -0.89137174  1.04241002\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ...  0.19909785 -0.8382785\n",
      "   0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "def featureSelectionOfKBestMeasure(submitted_data, submittedLabels, focused_number_of_features):\n",
    "    for number in focused_number_of_features:\n",
    "        transform_by_features = SelectKBest(k=number)\n",
    "        transform_by_features.fit(submitted_data, submittedLabels)\n",
    "        print(transform_by_features)\n",
    "        transformed_data = transform_by_features.fit_transform(submitted_data, submittedLabels)\n",
    "        print(\"For \",number,\" features: \\n\")\n",
    "        print(transformed_data)\n",
    "        print(transform_by_features.pvalues_)\n",
    "        print(transform_by_features.scores_)\n",
    "        \n",
    "#    return transformed_data\n",
    "possible_feature_numbers = [2,3,4,5,6,7,8,9,10]\n",
    "featureSelectionOfKBestMeasure(standardized_generated_dataframe, generated_labels,possible_feature_numbers)\n",
    "\n",
    "\n",
    "#Performing transformation to reduce dimensionality of the data\n",
    "#transformed_generated_data = featureSelectionOfKBest(standardized_generated_dataframe, generated_labels, 9)\n",
    "#print(transformed_generated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14fd20c",
   "metadata": {},
   "source": [
    "Using the <code>SelectKBest</code> method with mutual info classifier metric to select the best eight features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f81a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=8,\n",
      "            score_func=<function mutual_info_classif at 0x000001C9DB096F80>)\n",
      "[[ 1.42673235  1.4820108   0.67773855 ...  0.16507973  0.54125354\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ... -0.55629257 -0.83817178\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -0.20552952  0.40152665\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ...  0.20212378  0.26068818\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ...  0.52872378  1.04241002\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ... -0.6476322  -0.8382785\n",
      "   0.88846665]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "def featureSelectionOfKBestResult(submitted_data, submittedLabels, focused_number):\n",
    "    transform_by_features = SelectKBest(score_func=mutual_info_classif,k=focused_number)\n",
    "    transform_by_features.fit(X=submitted_data, y=submittedLabels)\n",
    "    print(transform_by_features)\n",
    "    transformed_data = transform_by_features.fit_transform(submitted_data, submittedLabels) \n",
    "    print(transformed_data)\n",
    "    return transformed_data\n",
    "\n",
    "transformed_data = featureSelectionOfKBestResult(standardized_generated_dataframe, generated_labels, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf8d809",
   "metadata": {},
   "source": [
    "<h2>Exploring the Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca1fc5",
   "metadata": {},
   "source": [
    "Using the covariance matrix, we can observe if the whether the relevant features have a positive or negative relationship with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89afb127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the empirical covariance of the data:\n",
      "[[ 9.94224004e-01 -2.75944244e-02  3.44190140e-03 ...  4.49019309e-03\n",
      "   1.86278207e-02 -7.61682585e-03]\n",
      " [-2.75944244e-02  6.52016875e+00  3.71517903e-03 ... -1.39513595e-02\n",
      "  -9.39814304e-01  1.30035465e-02]\n",
      " [ 3.44190140e-03  3.71517903e-03  9.94146514e-01 ... -1.22093149e-03\n",
      "   9.02005266e-03 -5.80496093e-05]\n",
      " ...\n",
      " [ 4.49019309e-03 -1.39513595e-02 -1.22093149e-03 ...  1.00394354e+00\n",
      "   4.72660595e-03 -3.57410271e-04]\n",
      " [ 1.86278207e-02 -9.39814304e-01  9.02005266e-03 ...  4.72660595e-03\n",
      "   4.56502205e+00  4.07984927e-03]\n",
      " [-7.61682585e-03  1.30035465e-02 -5.80496093e-05 ... -3.57410271e-04\n",
      "   4.07984927e-03  9.96977225e-01]]\n",
      "SelectKBest(k=8,\n",
      "            score_func=<function mutual_info_classif at 0x000001C9DB096F80>)\n",
      "[[ 2.89546808  3.3208769   1.60383671 ...  0.39309061  1.66679368\n",
      "  -0.23464541]\n",
      " [-1.10837167 -0.27035596  1.18375352 ... -1.8917661  -2.02236295\n",
      "   0.83898195]\n",
      " [-0.9008598  -1.0506433   0.48342452 ... -0.78076793  1.29310592\n",
      "   0.37665421]\n",
      " ...\n",
      " [ 2.96140526  0.67187333  0.34498346 ...  0.51042302  0.91644531\n",
      "  -1.4081906 ]\n",
      " [-2.62932375  1.1495991   2.80043658 ...  1.54488777  3.00709439\n",
      "  -1.60083946]\n",
      " [ 0.83959625 -0.75571791 -1.19279837 ... -2.18107299 -2.02264835\n",
      "   1.27180145]]\n",
      "Calculating the empirical covariance of the transformed data:\n",
      "[[ 5.05946198  1.54303515  0.084714    3.59558993 -3.78328985  2.31973647\n",
      "   1.72969976 -0.89713192]\n",
      " [ 1.54303515  3.90247793  2.90180276  2.054525    0.06269367  1.41994524\n",
      "   1.5159754  -1.12297576]\n",
      " [ 0.084714    2.90180276  3.2053911   0.92979589  0.20127479  1.54287002\n",
      "   1.89203324 -1.15669785]\n",
      " [ 3.59558993  2.054525    0.92979589  3.75815111 -2.97337006  4.39461334\n",
      "   2.14686856 -0.80051075]\n",
      " [-3.78328985  0.06269367  0.20127479 -2.97337006  4.86730929 -4.43864217\n",
      "  -3.70613886  1.49016885]\n",
      " [ 2.31973647  1.41994524  1.54287002  4.39461334 -4.43864217 10.03226563\n",
      "   4.56638245 -2.30576065]\n",
      " [ 1.72969976  1.5159754   1.89203324  2.14686856 -3.70613886  4.56638245\n",
      "   7.15249894 -2.28110091]\n",
      " [-0.89713192 -1.12297576 -1.15669785 -0.80051075  1.49016885 -2.30576065\n",
      "  -2.28110091  2.51302038]]\n",
      "(40000, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import empirical_covariance\n",
    "print(\"Calculating the empirical covariance of the data:\")\n",
    "print(empirical_covariance(pd.DataFrame(data=generated_data)))\n",
    "transformed_origin_generated_data = featureSelectionOfKBestResult(pd.DataFrame(data=generated_data), generated_labels, 8)\n",
    "print(\"Calculating the empirical covariance of the transformed data:\")\n",
    "print(empirical_covariance(transformed_origin_generated_data))\n",
    "print(transformed_origin_generated_data.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1e200",
   "metadata": {},
   "source": [
    "<h2>Cross-Validation</h2>\n",
    "<p>Implmenting the cross-validation for the selected model. This will be done for an assortment of models and their resulting performance will be accessed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0987220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model_function(model,data,labels):\n",
    "    resultsFromCV = cross_validate(estimator=model, X=data, y=labels,cv = 10,\n",
    "                                   n_jobs = 3,\n",
    "                                   #pre_dispatch =1,\n",
    "                                   return_train_score=True, \n",
    "                                   scoring= {\"accuracy\": \"accuracy\", \n",
    "                                             \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "                                             \"F1\": \"f1_micro\"\n",
    "                                            })\n",
    "    return resultsFromCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9de1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_neural_network_cl = MLPClassifier(hidden_layer_sizes=(8,4),activation=\"relu\", solver=\"adam\", learning_rate_init=0.01,max_iter=100,)\n",
    "mlp_neural_network_cl_v2 = MLPClassifier(hidden_layer_sizes=(8,4),activation=\"relu\", solver=\"adam\", learning_rate_init=0.05,max_iter=100,)\n",
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af449c",
   "metadata": {},
   "source": [
    "<p>Will be using multilayer perceptron neural network below with <code>activation=\"relu\"</code> and <code>solver=adam</code>. The neural network consists of an input layer that accepts the input data, the hidden layers where calculations are made to perform computations on supplied features, then the ouput layer that will produce the resulting prediction. Neural networks are a more complex predictive modeling method, and can be difficult to interpret.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a56ff099",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_neural_network_cross_validation = cross_validate_model_function(\n",
    "    mlp_neural_network_cl,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "mlp_neural_network_cross_validation_v2 = cross_validate_model_function(\n",
    "    mlp_neural_network_cl_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6db5abcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training and testing scores for first MLP, learning rate = 0.009: \n",
      "\n",
      "train_accuracy  (median):  0.653\n",
      "train_accuracy  (mean):  0.652 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.653\n",
      "train_balanced_accuracy  (mean):  0.652 \n",
      "\n",
      "train_F1  (median):  0.653\n",
      "train_F1  (mean):  0.652 \n",
      "\n",
      "test_accuracy  (median):  0.651\n",
      "test_accuracy  (mean):  0.651 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.651\n",
      "test_balanced_accuracy  (mean):  0.651 \n",
      "\n",
      "test_F1  (median):  0.651\n",
      "test_F1  (mean):  0.651 \n",
      "\n",
      "\n",
      " The training and testing scores for second MLP, learning rate = 0.01: \n",
      "\n",
      "train_accuracy  (median):  0.633\n",
      "train_accuracy  (mean):  0.637 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.633\n",
      "train_balanced_accuracy  (mean):  0.637 \n",
      "\n",
      "train_F1  (median):  0.633\n",
      "train_F1  (mean):  0.637 \n",
      "\n",
      "test_accuracy  (median):  0.633\n",
      "test_accuracy  (mean):  0.634 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.633\n",
      "test_balanced_accuracy  (mean):  0.634 \n",
      "\n",
      "test_F1  (median):  0.633\n",
      "test_F1  (mean):  0.634 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_model_scores(score_key_list, score_dict):\n",
    "    for key in score_key_list:\n",
    "        print(key,\" (median): \" ,round(np.median(score_dict[key]),3))\n",
    "        print(key, \" (mean): \", round(np.mean(score_dict[key]),3), \"\\n\")\n",
    "\n",
    "def score_extract(score_dict):\n",
    "    train_score_list = [key for key in score_dict if \"train\" in key]\n",
    "    test_score_list = [key for key in score_dict if \"test\" in key]\n",
    "    get_model_scores(train_score_list, score_dict)\n",
    "    get_model_scores(test_score_list, score_dict)\n",
    "    \n",
    "print(\"The training and testing scores for first MLP, learning rate = 0.009: \\n\")\n",
    "score_extract(mlp_neural_network_cross_validation)\n",
    "\n",
    "\n",
    "print(\"\\n The training and testing scores for second MLP, learning rate = 0.01: \\n\")\n",
    "score_extract(mlp_neural_network_cross_validation_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f097595",
   "metadata": {},
   "source": [
    "<p>The KNN classifier is being used next. The models are being parallelized across three cores each.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8fcf731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model_cl_v1 = KNeighborsClassifier(n_neighbors =9, metric=\"euclidean\",n_jobs = 3)\n",
    "knn_model_cl_v2 = KNeighborsClassifier(n_neighbors =11, metric=\"euclidean\",n_jobs = 3)\n",
    "knn_model_cl_v3 = KNeighborsClassifier(n_neighbors =13, metric=\"euclidean\",n_jobs = 3)\n",
    "knn_model_cl_v4 = KNeighborsClassifier(n_neighbors =15, metric=\"euclidean\",n_jobs = 3)\n",
    "knn_model_cl_v1_validation =cross_validate_model_function(\n",
    "    knn_model_cl_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "knn_model_cl_v2_validation =cross_validate_model_function(\n",
    "knn_model_cl_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "knn_model_cl_v3_validation =cross_validate_model_function(\n",
    "    knn_model_cl_v3,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "knn_model_cl_v4_validation =cross_validate_model_function(\n",
    "    knn_model_cl_v4,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a76030d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of KNN with 9 neighbors:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.823\n",
      "train_accuracy  (mean):  0.823 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.823\n",
      "train_balanced_accuracy  (mean):  0.823 \n",
      "\n",
      "train_F1  (median):  0.823\n",
      "train_F1  (mean):  0.823 \n",
      "\n",
      "test_accuracy  (median):  0.776\n",
      "test_accuracy  (mean):  0.775 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.776\n",
      "test_balanced_accuracy  (mean):  0.775 \n",
      "\n",
      "test_F1  (median):  0.776\n",
      "test_F1  (mean):  0.775 \n",
      "\n",
      "The result of KNN with 11 neighbors:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.815\n",
      "train_accuracy  (mean):  0.816 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.815\n",
      "train_balanced_accuracy  (mean):  0.816 \n",
      "\n",
      "train_F1  (median):  0.815\n",
      "train_F1  (mean):  0.816 \n",
      "\n",
      "test_accuracy  (median):  0.778\n",
      "test_accuracy  (mean):  0.776 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.778\n",
      "test_balanced_accuracy  (mean):  0.776 \n",
      "\n",
      "test_F1  (median):  0.778\n",
      "test_F1  (mean):  0.776 \n",
      "\n",
      "The result of KNN with 13 neighbors:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.81\n",
      "train_accuracy  (mean):  0.81 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.81\n",
      "train_balanced_accuracy  (mean):  0.81 \n",
      "\n",
      "train_F1  (median):  0.81\n",
      "train_F1  (mean):  0.81 \n",
      "\n",
      "test_accuracy  (median):  0.773\n",
      "test_accuracy  (mean):  0.774 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.773\n",
      "test_balanced_accuracy  (mean):  0.774 \n",
      "\n",
      "test_F1  (median):  0.773\n",
      "test_F1  (mean):  0.774 \n",
      "\n",
      "The result of KNN with 15 neighbors:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.805\n",
      "train_accuracy  (mean):  0.805 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.805\n",
      "train_balanced_accuracy  (mean):  0.805 \n",
      "\n",
      "train_F1  (median):  0.805\n",
      "train_F1  (mean):  0.805 \n",
      "\n",
      "test_accuracy  (median):  0.775\n",
      "test_accuracy  (mean):  0.774 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.775\n",
      "test_balanced_accuracy  (mean):  0.774 \n",
      "\n",
      "test_F1  (median):  0.775\n",
      "test_F1  (mean):  0.774 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The result of KNN with 9 neighbors:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(knn_model_cl_v1_validation)\n",
    "\n",
    "print(\"The result of KNN with 11 neighbors:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(knn_model_cl_v2_validation)\n",
    "\n",
    "print(\"The result of KNN with 13 neighbors:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(knn_model_cl_v3_validation)\n",
    "\n",
    "print(\"The result of KNN with 15 neighbors:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(knn_model_cl_v4_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a325222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_ensemble_cl_v1 = GradientBoostingClassifier(n_estimators=5,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v2 = GradientBoostingClassifier(n_estimators=10,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v3 = GradientBoostingClassifier(n_estimators=15,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v4 = GradientBoostingClassifier(n_estimators=20,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v5 = GradientBoostingClassifier(n_estimators=50,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v1_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "gbc_ensemble_cl_v2_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "gbc_ensemble_cl_v3_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v3,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "gbc_ensemble_cl_v4_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v4,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "gbc_ensemble_cl_v5_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v5,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "724d4051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of Gradient Boost Classifier with 50 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.558\n",
      "train_accuracy  (mean):  0.558 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.558\n",
      "train_balanced_accuracy  (mean):  0.558 \n",
      "\n",
      "train_F1  (median):  0.558\n",
      "train_F1  (mean):  0.558 \n",
      "\n",
      "test_accuracy  (median):  0.552\n",
      "test_accuracy  (mean):  0.552 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.552\n",
      "test_balanced_accuracy  (mean):  0.552 \n",
      "\n",
      "test_F1  (median):  0.552\n",
      "test_F1  (mean):  0.552 \n",
      "\n",
      "The result of Gradient Boost Classifier with 100 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.581\n",
      "train_accuracy  (mean):  0.581 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.581\n",
      "train_balanced_accuracy  (mean):  0.581 \n",
      "\n",
      "train_F1  (median):  0.581\n",
      "train_F1  (mean):  0.581 \n",
      "\n",
      "test_accuracy  (median):  0.572\n",
      "test_accuracy  (mean):  0.572 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.573\n",
      "test_balanced_accuracy  (mean):  0.572 \n",
      "\n",
      "test_F1  (median):  0.572\n",
      "test_F1  (mean):  0.572 \n",
      "\n",
      "The result of Gradient Boost Classifier with 150 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.601\n",
      "train_accuracy  (mean):  0.6 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.601\n",
      "train_balanced_accuracy  (mean):  0.6 \n",
      "\n",
      "train_F1  (median):  0.601\n",
      "train_F1  (mean):  0.6 \n",
      "\n",
      "test_accuracy  (median):  0.588\n",
      "test_accuracy  (mean):  0.589 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.588\n",
      "test_balanced_accuracy  (mean):  0.589 \n",
      "\n",
      "test_F1  (median):  0.588\n",
      "test_F1  (mean):  0.589 \n",
      "\n",
      "The result of Gradient Boost Classifier with 200 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.616\n",
      "train_accuracy  (mean):  0.615 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.616\n",
      "train_balanced_accuracy  (mean):  0.615 \n",
      "\n",
      "train_F1  (median):  0.616\n",
      "train_F1  (mean):  0.615 \n",
      "\n",
      "test_accuracy  (median):  0.602\n",
      "test_accuracy  (mean):  0.603 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.602\n",
      "test_balanced_accuracy  (mean):  0.603 \n",
      "\n",
      "test_F1  (median):  0.602\n",
      "test_F1  (mean):  0.603 \n",
      "\n",
      "The result of Gradient Boost Classifier with 50 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.674\n",
      "train_accuracy  (mean):  0.675 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.675\n",
      "train_balanced_accuracy  (mean):  0.675 \n",
      "\n",
      "train_F1  (median):  0.674\n",
      "train_F1  (mean):  0.675 \n",
      "\n",
      "test_accuracy  (median):  0.653\n",
      "test_accuracy  (mean):  0.652 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.653\n",
      "test_balanced_accuracy  (mean):  0.652 \n",
      "\n",
      "test_F1  (median):  0.653\n",
      "test_F1  (mean):  0.652 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The result of Gradient Boost Classifier with 50 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v1_validation)\n",
    "\n",
    "print(\"The result of Gradient Boost Classifier with 100 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v2_validation)\n",
    "\n",
    "print(\"The result of Gradient Boost Classifier with 150 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v3_validation)\n",
    "\n",
    "print(\"The result of Gradient Boost Classifier with 200 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v4_validation)\n",
    "\n",
    "print(\"The result of Gradient Boost Classifier with 50 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v5_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ed88a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_red_cl_v1 = LogisticRegression(penalty=\"l2\",C=0.85, random_state = 3, solver=\"newton-cg\", max_iter=200,n_jobs=2)\n",
    "log_red_cl_v2 = LogisticRegression(penalty=\"l2\",C=0.85, random_state = 3, solver=\"sag\", max_iter=200,n_jobs=2)\n",
    "log_red_cl_v3 = LogisticRegression(penalty=\"l2\",C=0.75, random_state = 3, solver=\"newton-cg\", max_iter=200,n_jobs=2)\n",
    "log_red_cl_v4 = LogisticRegression(penalty=\"l2\",C=0.75, random_state = 3, solver=\"sag\", max_iter=200,n_jobs=2)\n",
    "log_red_cl_v1_validation = cross_validate_model_function(\n",
    "    log_red_cl_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_red_cl_v2_validation = cross_validate_model_function(\n",
    "    log_red_cl_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_red_cl_v3_validation = cross_validate_model_function(\n",
    "    log_red_cl_v3,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_red_cl_v4_validation = cross_validate_model_function(\n",
    "    log_red_cl_v4,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9ce0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cv_train_test_results(results_dict):\n",
    "    print(\"The training scores:\")\n",
    "    print(results_dict[\"train_score\"])\n",
    "    print(\"The testing scores:\")\n",
    "    print(results_dict[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1255cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression train and test scores: \n",
      "Newton solver logistic regression C = 0.85:\n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n",
      "SAG solverlogistic regression C = 0.85: \n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n",
      "Newton solver logistic regression C = 0.75:\n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n",
      "SAG solverlogistic regression C = 0.75: \n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Going into logistic regression\n",
    "# Printing the training and testing scores\n",
    "print(\"Logistic Regression train and test scores: \")\n",
    "print(\"Newton solver logistic regression C = 0.85:\" )\n",
    "score_extract(log_red_cl_v1_validation)\n",
    "print(\"SAG solverlogistic regression C = 0.85: \")\n",
    "score_extract(log_red_cl_v2_validation)\n",
    "print(\"Newton solver logistic regression C = 0.75:\")\n",
    "score_extract(log_red_cl_v3_validation)\n",
    "print(\"SAG solverlogistic regression C = 0.75: \")\n",
    "score_extract(log_red_cl_v4_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47a0d040-8df2-42b9-ae72-335a21f621cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msklearn\u001b[49m\u001b[38;5;241m.\u001b[39m__version__\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c97b18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with logistic regression Newton solver C= 0.85:\n",
      "Training and testing scores:\n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n",
      "Bagging with logistic regression SAG solver C= 0.85:\n",
      "Training and testing scores:\n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "log_reg_cl_use_bagging_v1 = BaggingClassifier(estimator=log_red_cl_v1,n_estimators=5, n_jobs = 2 ,random_state=3)\n",
    "log_reg_cl_use_bagging_v2 = BaggingClassifier(estimator=log_red_cl_v2,n_estimators=5, n_jobs = 2 ,random_state=3)\n",
    "\n",
    "log_reg_cl_use_bagging_v1_validation = cross_validate_model_function(\n",
    "    log_reg_cl_use_bagging_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_reg_cl_use_bagging_v2_validation = cross_validate_model_function(\n",
    "    log_reg_cl_use_bagging_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "\n",
    "print(\"Bagging with logistic regression Newton solver C= 0.85:\")\n",
    "print(\"Training and testing scores:\")\n",
    "score_extract(log_reg_cl_use_bagging_v1_validation)\n",
    "print(\"Bagging with logistic regression SAG solver C= 0.85:\")\n",
    "print(\"Training and testing scores:\")\n",
    "score_extract(log_reg_cl_use_bagging_v2_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6c01a0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboosting with Logistic Regression: \n",
      "Bagging with logistic regression Newton solver C= 0.85:\n",
      "Training and testing scores:\n",
      "train_accuracy  (median):  0.451\n",
      "train_accuracy  (mean):  0.452 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.451\n",
      "train_balanced_accuracy  (mean):  0.452 \n",
      "\n",
      "train_F1  (median):  0.451\n",
      "train_F1  (mean):  0.452 \n",
      "\n",
      "test_accuracy  (median):  0.45\n",
      "test_accuracy  (mean):  0.451 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.45\n",
      "test_balanced_accuracy  (mean):  0.451 \n",
      "\n",
      "test_F1  (median):  0.45\n",
      "test_F1  (mean):  0.451 \n",
      "\n",
      "Bagging with logistic regression SAG solver C= 0.85:\n",
      "Training and testing scores:\n",
      "train_accuracy  (median):  0.452\n",
      "train_accuracy  (mean):  0.452 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.452\n",
      "train_balanced_accuracy  (mean):  0.452 \n",
      "\n",
      "train_F1  (median):  0.452\n",
      "train_F1  (mean):  0.452 \n",
      "\n",
      "test_accuracy  (median):  0.451\n",
      "test_accuracy  (mean):  0.452 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.451\n",
      "test_balanced_accuracy  (mean):  0.452 \n",
      "\n",
      "test_F1  (median):  0.451\n",
      "test_F1  (mean):  0.452 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "log_reg_cl_adaboost_v1 = AdaBoostClassifier(estimator=log_red_cl_v1,n_estimators=15,random_state=3)\n",
    "log_reg_cl_adaboost_v2 = AdaBoostClassifier(estimator=log_red_cl_v2,n_estimators=15,random_state=3)\n",
    "\n",
    "log_reg_cl_adaboost_v1_validation = cross_validate_model_function(\n",
    "    log_reg_cl_adaboost_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_reg_cl_adaboost_v2_validation = cross_validate_model_function(\n",
    "    log_reg_cl_adaboost_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "\n",
    "print(\"Adaboosting with Logistic Regression: \")\n",
    "print(\"Bagging with logistic regression Newton solver C= 0.85:\")\n",
    "print(\"Training and testing scores:\")\n",
    "score_extract(log_reg_cl_adaboost_v1_validation)\n",
    "print(\"Bagging with logistic regression SAG solver C= 0.85:\")\n",
    "print(\"Training and testing scores:\")\n",
    "score_extract(log_reg_cl_adaboost_v2_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34848bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "# Reference: https://stats.stackexchange.com/questions/362619/why-the-accuracy-of-my-neural-network-is-falling-when-epoch-increases by Tonca\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "opimize_by_adam =keras.optimizers.Adam(learning_rate=0.001)\n",
    "#opimize_by_adam =Adam(learning_rate=0.000023)\n",
    "def generate_keras_model():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance = generate_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7f66a7a-b6bc-41f8-883d-5495962bde99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model callbacks for checkpoints\n",
    "model_callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8a8d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_epochs = 1000\n",
    "set_metrics = [\"binary_accuracy\", \"categorical_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08da3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa88fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(transformed_origin_generated_data,generated_labels, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d59f9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9ebf65e70>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2, callbacks = [model_callbacks], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "209ff653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 1s 1ms/step - loss: 1.2007 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2225\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2006809711456299, 0.2498749941587448, 0.2224999964237213]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "926b6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keras_model_2():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(8,activation=\"relu\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_2 = generate_keras_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d8304d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22d3581a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9ec2df2b0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_2.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2, callbacks = [model_callbacks], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eb87c515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 2s 2ms/step - loss: 0.9673 - binary_accuracy: 0.2585 - categorical_accuracy: 0.1810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9672691822052002, 0.25850892066955566, 0.18103571236133575]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe434673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keras_model_3():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(8,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(16,activation=\"relu\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_3 = generate_keras_model_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b2bcb3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a0411a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9ed5d5cf0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d921dfc48>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_3.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2, callbacks = [model_callbacks], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "433d0706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 2s 2ms/step - loss: 0.7648 - binary_accuracy: 0.2516 - categorical_accuracy: 0.2527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7647585272789001, 0.25155356526374817, 0.25271427631378174]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_3.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a3fc50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\n",
    "# Reduction of overfitting by dropout decreased learning rate over time\n",
    "\n",
    "def generate_keras_model_4():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(32,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dropout(0.25))\n",
    "    keras_model.add(tf.keras.layers.Dense(32,activation=\"relu\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_4 = generate_keras_model_4()\n",
    "\n",
    "optim_schedule = keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.0012, decay_steps =4000,decay_rate=0.5)\n",
    "opimize_by_adam_2 = keras.optimizers.Adam(optim_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "21b0cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_4.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam_2, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "003adbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9ed968250>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d93486708>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_4.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2, callbacks = [model_callbacks], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "40947e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 2s 3ms/step - loss: 0.5864 - binary_accuracy: 0.2523 - categorical_accuracy: 0.2399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.586382269859314, 0.25232142210006714, 0.2398928552865982]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_4.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f42e2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keras_model_5():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(64,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dropout(0.25))\n",
    "    keras_model.add(tf.keras.layers.Dense(64,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_5 = generate_keras_model_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "26e51718",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_5.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam_2, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "96e9d844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9ec2dcdc0>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9131 - binary_accuracy: 0.2513 - categorical_accuracy: 0.2421 - val_loss: 0.9109 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2479\n",
      "Epoch 146/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9141 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2454 - val_loss: 0.9094 - val_binary_accuracy: 0.2552 - val_categorical_accuracy: 0.2542\n",
      "Epoch 147/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9123 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2548 - val_loss: 0.9093 - val_binary_accuracy: 0.2570 - val_categorical_accuracy: 0.2500\n",
      "Epoch 148/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9132 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2452 - val_loss: 0.9095 - val_binary_accuracy: 0.2558 - val_categorical_accuracy: 0.2438\n",
      "Epoch 149/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9111 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2420 - val_loss: 0.9088 - val_binary_accuracy: 0.2558 - val_categorical_accuracy: 0.2475\n",
      "Epoch 150/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9081 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2522 - val_loss: 0.9077 - val_binary_accuracy: 0.2547 - val_categorical_accuracy: 0.2571\n",
      "Epoch 151/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9114 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2493 - val_loss: 0.9064 - val_binary_accuracy: 0.2569 - val_categorical_accuracy: 0.2479\n",
      "Epoch 152/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9111 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2443 - val_loss: 0.9057 - val_binary_accuracy: 0.2560 - val_categorical_accuracy: 0.2446\n",
      "Epoch 153/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9057 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2441 - val_loss: 0.9050 - val_binary_accuracy: 0.2559 - val_categorical_accuracy: 0.2533\n",
      "Epoch 154/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9082 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2522 - val_loss: 0.9050 - val_binary_accuracy: 0.2556 - val_categorical_accuracy: 0.2529\n",
      "Epoch 155/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9087 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2439 - val_loss: 0.9047 - val_binary_accuracy: 0.2569 - val_categorical_accuracy: 0.2392\n",
      "Epoch 156/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9044 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2412 - val_loss: 0.9030 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2550\n",
      "Epoch 157/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9068 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2498 - val_loss: 0.9025 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2554\n",
      "Epoch 158/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9055 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2549 - val_loss: 0.9014 - val_binary_accuracy: 0.2547 - val_categorical_accuracy: 0.2508\n",
      "Epoch 159/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9046 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2515 - val_loss: 0.9007 - val_binary_accuracy: 0.2570 - val_categorical_accuracy: 0.2479\n",
      "Epoch 160/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9042 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2458 - val_loss: 0.9002 - val_binary_accuracy: 0.2572 - val_categorical_accuracy: 0.2454\n",
      "Epoch 161/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8993 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2402 - val_loss: 0.8994 - val_binary_accuracy: 0.2549 - val_categorical_accuracy: 0.2483\n",
      "Epoch 162/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8987 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2522 - val_loss: 0.8990 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2550\n",
      "Epoch 163/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9028 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2509 - val_loss: 0.8985 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2525\n",
      "Epoch 164/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9016 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2501 - val_loss: 0.8982 - val_binary_accuracy: 0.2558 - val_categorical_accuracy: 0.2467\n",
      "Epoch 165/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9028 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2421 - val_loss: 0.8967 - val_binary_accuracy: 0.2557 - val_categorical_accuracy: 0.2512\n",
      "Epoch 166/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9026 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2569 - val_loss: 0.8957 - val_binary_accuracy: 0.2542 - val_categorical_accuracy: 0.2525\n",
      "Epoch 167/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9011 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2526 - val_loss: 0.8953 - val_binary_accuracy: 0.2555 - val_categorical_accuracy: 0.2425\n",
      "Epoch 168/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8966 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2398 - val_loss: 0.8941 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2463\n",
      "Epoch 169/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9000 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2564 - val_loss: 0.8936 - val_binary_accuracy: 0.2558 - val_categorical_accuracy: 0.2571\n",
      "Epoch 170/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8939 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2574 - val_loss: 0.8948 - val_binary_accuracy: 0.2561 - val_categorical_accuracy: 0.2454\n",
      "Epoch 171/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8929 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2423 - val_loss: 0.8952 - val_binary_accuracy: 0.2546 - val_categorical_accuracy: 0.2417\n",
      "Epoch 172/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8906 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2453 - val_loss: 0.8934 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2583\n",
      "Epoch 173/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8920 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2650 - val_loss: 0.8928 - val_binary_accuracy: 0.2549 - val_categorical_accuracy: 0.2533\n",
      "Epoch 174/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8946 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2516 - val_loss: 0.8928 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2400\n",
      "Epoch 175/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8927 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2377 - val_loss: 0.8905 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2508\n",
      "Epoch 176/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8902 - binary_accuracy: 0.2466 - categorical_accuracy: 0.2535 - val_loss: 0.8897 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2571\n",
      "Epoch 177/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8941 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2572 - val_loss: 0.8903 - val_binary_accuracy: 0.2545 - val_categorical_accuracy: 0.2446\n",
      "Epoch 178/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8907 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2470 - val_loss: 0.8895 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2417\n",
      "Epoch 179/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8932 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2530 - val_loss: 0.8874 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2571\n",
      "Epoch 180/200\n",
      "9600/9600 [==============================] - 0s 4us/sample - loss: 0.8909 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2586 - val_loss: 0.8873 - val_binary_accuracy: 0.2553 - val_categorical_accuracy: 0.2517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8879 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2474 - val_loss: 0.8874 - val_binary_accuracy: 0.2555 - val_categorical_accuracy: 0.2463\n",
      "Epoch 182/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8886 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2468 - val_loss: 0.8863 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2517\n",
      "Epoch 183/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8914 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2571 - val_loss: 0.8839 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2571\n",
      "Epoch 184/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8917 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2559 - val_loss: 0.8843 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2454\n",
      "Epoch 185/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8864 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2428 - val_loss: 0.8838 - val_binary_accuracy: 0.2551 - val_categorical_accuracy: 0.2408\n",
      "Epoch 186/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8917 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2485 - val_loss: 0.8833 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2488\n",
      "Epoch 187/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8848 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2574 - val_loss: 0.8832 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2467\n",
      "Epoch 188/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8850 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2510 - val_loss: 0.8821 - val_binary_accuracy: 0.2550 - val_categorical_accuracy: 0.2475\n",
      "Epoch 189/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8913 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2456 - val_loss: 0.8809 - val_binary_accuracy: 0.2545 - val_categorical_accuracy: 0.2442\n",
      "Epoch 190/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8855 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2459 - val_loss: 0.8801 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2521\n",
      "Epoch 191/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8874 - binary_accuracy: 0.2471 - categorical_accuracy: 0.2610 - val_loss: 0.8803 - val_binary_accuracy: 0.2549 - val_categorical_accuracy: 0.2533\n",
      "Epoch 192/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8824 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2486 - val_loss: 0.8808 - val_binary_accuracy: 0.2553 - val_categorical_accuracy: 0.2442\n",
      "Epoch 193/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8833 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2460 - val_loss: 0.8796 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2521\n",
      "Epoch 194/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8813 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2594 - val_loss: 0.8786 - val_binary_accuracy: 0.2546 - val_categorical_accuracy: 0.2533\n",
      "Epoch 195/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8819 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2510 - val_loss: 0.8803 - val_binary_accuracy: 0.2561 - val_categorical_accuracy: 0.2429\n",
      "Epoch 196/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8844 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2455 - val_loss: 0.8795 - val_binary_accuracy: 0.2549 - val_categorical_accuracy: 0.2508\n",
      "Epoch 197/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8810 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2541 - val_loss: 0.8782 - val_binary_accuracy: 0.2546 - val_categorical_accuracy: 0.2529\n",
      "Epoch 198/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8834 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2549 - val_loss: 0.8772 - val_binary_accuracy: 0.2557 - val_categorical_accuracy: 0.2508\n",
      "Epoch 199/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8817 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2491 - val_loss: 0.8764 - val_binary_accuracy: 0.2553 - val_categorical_accuracy: 0.2446\n",
      "Epoch 200/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8800 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2488 - val_loss: 0.8752 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d94c47148>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_5.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2, callbacks = [model_callbacks], verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89d175f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 2s 2ms/step - loss: 0.6641 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6641414165496826, 0.24962499737739563, 0.2615714371204376]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_5.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce859e9",
   "metadata": {},
   "source": [
    "Overall, the 5th Tensorflow model seems to provide the best overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f6147e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keras_model_6():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(64,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dropout(0.11))\n",
    "    keras_model.add(tf.keras.layers.Dense(64,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(32,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_6 = generate_keras_model_6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f9e3248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_6.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam_2, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5141188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 2.7022 - binary_accuracy: 0.2458 - categorical_accuracy: 0.0691 - val_loss: 2.5472 - val_binary_accuracy: 0.2601 - val_categorical_accuracy: 0.3833\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 2.5215 - binary_accuracy: 0.2532 - categorical_accuracy: 0.3875 - val_loss: 2.4176 - val_binary_accuracy: 0.2633 - val_categorical_accuracy: 0.4529\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 2.3884 - binary_accuracy: 0.2574 - categorical_accuracy: 0.4084 - val_loss: 2.2770 - val_binary_accuracy: 0.2679 - val_categorical_accuracy: 0.2933\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 2.2525 - binary_accuracy: 0.2583 - categorical_accuracy: 0.2552 - val_loss: 2.1719 - val_binary_accuracy: 0.2659 - val_categorical_accuracy: 0.1604\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 2.1551 - binary_accuracy: 0.2574 - categorical_accuracy: 0.1625 - val_loss: 2.0753 - val_binary_accuracy: 0.2644 - val_categorical_accuracy: 0.1471\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 2.0617 - binary_accuracy: 0.2553 - categorical_accuracy: 0.1624 - val_loss: 1.9749 - val_binary_accuracy: 0.2623 - val_categorical_accuracy: 0.2062\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 1.9672 - binary_accuracy: 0.2568 - categorical_accuracy: 0.2175 - val_loss: 1.8852 - val_binary_accuracy: 0.2619 - val_categorical_accuracy: 0.2608\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.8826 - binary_accuracy: 0.2558 - categorical_accuracy: 0.2639 - val_loss: 1.8036 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.2550\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.8052 - binary_accuracy: 0.2557 - categorical_accuracy: 0.2361 - val_loss: 1.7315 - val_binary_accuracy: 0.2595 - val_categorical_accuracy: 0.2037\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.7364 - binary_accuracy: 0.2548 - categorical_accuracy: 0.1880 - val_loss: 1.6693 - val_binary_accuracy: 0.2573 - val_categorical_accuracy: 0.1783\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.6771 - binary_accuracy: 0.2533 - categorical_accuracy: 0.1672 - val_loss: 1.6112 - val_binary_accuracy: 0.2576 - val_categorical_accuracy: 0.1787\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 1.6190 - binary_accuracy: 0.2532 - categorical_accuracy: 0.1758 - val_loss: 1.5612 - val_binary_accuracy: 0.2598 - val_categorical_accuracy: 0.2013\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 1.5710 - binary_accuracy: 0.2556 - categorical_accuracy: 0.1952 - val_loss: 1.5173 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.1929\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 1.5275 - binary_accuracy: 0.2564 - categorical_accuracy: 0.1760 - val_loss: 1.4746 - val_binary_accuracy: 0.2610 - val_categorical_accuracy: 0.1592\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 1.4881 - binary_accuracy: 0.2561 - categorical_accuracy: 0.1525 - val_loss: 1.4380 - val_binary_accuracy: 0.2611 - val_categorical_accuracy: 0.1554\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.4528 - binary_accuracy: 0.2557 - categorical_accuracy: 0.1497 - val_loss: 1.4049 - val_binary_accuracy: 0.2630 - val_categorical_accuracy: 0.1713\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 1.4205 - binary_accuracy: 0.2564 - categorical_accuracy: 0.1699 - val_loss: 1.3764 - val_binary_accuracy: 0.2646 - val_categorical_accuracy: 0.1950\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 1.3912 - binary_accuracy: 0.2593 - categorical_accuracy: 0.1909 - val_loss: 1.3501 - val_binary_accuracy: 0.2652 - val_categorical_accuracy: 0.1883\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 1.3637 - binary_accuracy: 0.2583 - categorical_accuracy: 0.1766 - val_loss: 1.3256 - val_binary_accuracy: 0.2644 - val_categorical_accuracy: 0.1667\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.3414 - binary_accuracy: 0.2579 - categorical_accuracy: 0.1595 - val_loss: 1.3046 - val_binary_accuracy: 0.2639 - val_categorical_accuracy: 0.1679\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.3213 - binary_accuracy: 0.2573 - categorical_accuracy: 0.1675 - val_loss: 1.2849 - val_binary_accuracy: 0.2653 - val_categorical_accuracy: 0.1838\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.3015 - binary_accuracy: 0.2583 - categorical_accuracy: 0.1887 - val_loss: 1.2674 - val_binary_accuracy: 0.2650 - val_categorical_accuracy: 0.1958\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.2827 - binary_accuracy: 0.2582 - categorical_accuracy: 0.1908 - val_loss: 1.2507 - val_binary_accuracy: 0.2658 - val_categorical_accuracy: 0.1808\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 1.2716 - binary_accuracy: 0.2593 - categorical_accuracy: 0.1735 - val_loss: 1.2360 - val_binary_accuracy: 0.2657 - val_categorical_accuracy: 0.1683\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.2545 - binary_accuracy: 0.2586 - categorical_accuracy: 0.1705 - val_loss: 1.2226 - val_binary_accuracy: 0.2655 - val_categorical_accuracy: 0.1813\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.2413 - binary_accuracy: 0.2580 - categorical_accuracy: 0.1778 - val_loss: 1.2095 - val_binary_accuracy: 0.2658 - val_categorical_accuracy: 0.1829\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 1.2273 - binary_accuracy: 0.2590 - categorical_accuracy: 0.1774 - val_loss: 1.1983 - val_binary_accuracy: 0.2643 - val_categorical_accuracy: 0.1933\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.2177 - binary_accuracy: 0.2584 - categorical_accuracy: 0.1954 - val_loss: 1.1886 - val_binary_accuracy: 0.2630 - val_categorical_accuracy: 0.1950\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 1.2105 - binary_accuracy: 0.2577 - categorical_accuracy: 0.1903 - val_loss: 1.1789 - val_binary_accuracy: 0.2649 - val_categorical_accuracy: 0.1704\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.1999 - binary_accuracy: 0.2579 - categorical_accuracy: 0.1689 - val_loss: 1.1697 - val_binary_accuracy: 0.2623 - val_categorical_accuracy: 0.1783\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 1.1905 - binary_accuracy: 0.2567 - categorical_accuracy: 0.1757 - val_loss: 1.1618 - val_binary_accuracy: 0.2631 - val_categorical_accuracy: 0.1912\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 1.1813 - binary_accuracy: 0.2574 - categorical_accuracy: 0.1978 - val_loss: 1.1541 - val_binary_accuracy: 0.2632 - val_categorical_accuracy: 0.2000\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.1735 - binary_accuracy: 0.2576 - categorical_accuracy: 0.1941 - val_loss: 1.1464 - val_binary_accuracy: 0.2629 - val_categorical_accuracy: 0.1779\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.1677 - binary_accuracy: 0.2586 - categorical_accuracy: 0.1753 - val_loss: 1.1389 - val_binary_accuracy: 0.2626 - val_categorical_accuracy: 0.1858\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.1599 - binary_accuracy: 0.2580 - categorical_accuracy: 0.1887 - val_loss: 1.1322 - val_binary_accuracy: 0.2625 - val_categorical_accuracy: 0.1983\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 1.1537 - binary_accuracy: 0.2572 - categorical_accuracy: 0.1990 - val_loss: 1.1255 - val_binary_accuracy: 0.2629 - val_categorical_accuracy: 0.1954\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 1.1459 - binary_accuracy: 0.2580 - categorical_accuracy: 0.1940 - val_loss: 1.1194 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.1912\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 1.1366 - binary_accuracy: 0.2579 - categorical_accuracy: 0.1966 - val_loss: 1.1138 - val_binary_accuracy: 0.2607 - val_categorical_accuracy: 0.1996\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.1340 - binary_accuracy: 0.2570 - categorical_accuracy: 0.2019 - val_loss: 1.1084 - val_binary_accuracy: 0.2619 - val_categorical_accuracy: 0.1917\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 1.1280 - binary_accuracy: 0.2589 - categorical_accuracy: 0.1902 - val_loss: 1.1021 - val_binary_accuracy: 0.2619 - val_categorical_accuracy: 0.1908\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 1.1216 - binary_accuracy: 0.2572 - categorical_accuracy: 0.2029 - val_loss: 1.0976 - val_binary_accuracy: 0.2596 - val_categorical_accuracy: 0.2138\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.1173 - binary_accuracy: 0.2572 - categorical_accuracy: 0.2171 - val_loss: 1.0935 - val_binary_accuracy: 0.2622 - val_categorical_accuracy: 0.1904\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 1.1172 - binary_accuracy: 0.2588 - categorical_accuracy: 0.1932 - val_loss: 1.0877 - val_binary_accuracy: 0.2595 - val_categorical_accuracy: 0.1946\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.1084 - binary_accuracy: 0.2565 - categorical_accuracy: 0.2082 - val_loss: 1.0831 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2058\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.1052 - binary_accuracy: 0.2563 - categorical_accuracy: 0.2119 - val_loss: 1.0799 - val_binary_accuracy: 0.2615 - val_categorical_accuracy: 0.1963\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.1015 - binary_accuracy: 0.2577 - categorical_accuracy: 0.2110 - val_loss: 1.0742 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2113\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.0953 - binary_accuracy: 0.2548 - categorical_accuracy: 0.2227 - val_loss: 1.0704 - val_binary_accuracy: 0.2602 - val_categorical_accuracy: 0.2004\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.0870 - binary_accuracy: 0.2576 - categorical_accuracy: 0.2106 - val_loss: 1.0659 - val_binary_accuracy: 0.2602 - val_categorical_accuracy: 0.1996\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 1.0842 - binary_accuracy: 0.2574 - categorical_accuracy: 0.2073 - val_loss: 1.0615 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2146\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 1.0797 - binary_accuracy: 0.2559 - categorical_accuracy: 0.2198 - val_loss: 1.0575 - val_binary_accuracy: 0.2598 - val_categorical_accuracy: 0.2121\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.0754 - binary_accuracy: 0.2559 - categorical_accuracy: 0.2204 - val_loss: 1.0533 - val_binary_accuracy: 0.2597 - val_categorical_accuracy: 0.2158\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 1.0733 - binary_accuracy: 0.2554 - categorical_accuracy: 0.2192 - val_loss: 1.0490 - val_binary_accuracy: 0.2593 - val_categorical_accuracy: 0.2158\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 1.0683 - binary_accuracy: 0.2560 - categorical_accuracy: 0.2181 - val_loss: 1.0456 - val_binary_accuracy: 0.2581 - val_categorical_accuracy: 0.2262\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.0664 - binary_accuracy: 0.2547 - categorical_accuracy: 0.2341 - val_loss: 1.0419 - val_binary_accuracy: 0.2576 - val_categorical_accuracy: 0.2150\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.0627 - binary_accuracy: 0.2557 - categorical_accuracy: 0.2178 - val_loss: 1.0385 - val_binary_accuracy: 0.2577 - val_categorical_accuracy: 0.2175\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.0574 - binary_accuracy: 0.2545 - categorical_accuracy: 0.2375 - val_loss: 1.0341 - val_binary_accuracy: 0.2569 - val_categorical_accuracy: 0.2362\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.0590 - binary_accuracy: 0.2555 - categorical_accuracy: 0.2299 - val_loss: 1.0313 - val_binary_accuracy: 0.2601 - val_categorical_accuracy: 0.2062\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 1.0533 - binary_accuracy: 0.2559 - categorical_accuracy: 0.2161 - val_loss: 1.0292 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2354\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 1.0500 - binary_accuracy: 0.2520 - categorical_accuracy: 0.2510 - val_loss: 1.0236 - val_binary_accuracy: 0.2572 - val_categorical_accuracy: 0.2183\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 1.0460 - binary_accuracy: 0.2559 - categorical_accuracy: 0.2200 - val_loss: 1.0224 - val_binary_accuracy: 0.2601 - val_categorical_accuracy: 0.2108\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 1.0431 - binary_accuracy: 0.2554 - categorical_accuracy: 0.2362 - val_loss: 1.0190 - val_binary_accuracy: 0.2553 - val_categorical_accuracy: 0.2471\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.0388 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2465 - val_loss: 1.0168 - val_binary_accuracy: 0.2591 - val_categorical_accuracy: 0.2029\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.0332 - binary_accuracy: 0.2572 - categorical_accuracy: 0.2092 - val_loss: 1.0108 - val_binary_accuracy: 0.2569 - val_categorical_accuracy: 0.2308\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.0352 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2534 - val_loss: 1.0088 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2454\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.0262 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2470 - val_loss: 1.0091 - val_binary_accuracy: 0.2597 - val_categorical_accuracy: 0.1992\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 1.0313 - binary_accuracy: 0.2559 - categorical_accuracy: 0.2155 - val_loss: 1.0033 - val_binary_accuracy: 0.2551 - val_categorical_accuracy: 0.2387\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 1.0266 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2581 - val_loss: 1.0002 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2371\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 1.0229 - binary_accuracy: 0.2554 - categorical_accuracy: 0.2330 - val_loss: 0.9970 - val_binary_accuracy: 0.2580 - val_categorical_accuracy: 0.2204\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 1.0176 - binary_accuracy: 0.2549 - categorical_accuracy: 0.2389 - val_loss: 0.9945 - val_binary_accuracy: 0.2552 - val_categorical_accuracy: 0.2517\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 1.0170 - binary_accuracy: 0.2517 - categorical_accuracy: 0.2482 - val_loss: 0.9925 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.2229\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 1.0135 - binary_accuracy: 0.2560 - categorical_accuracy: 0.2333 - val_loss: 0.9891 - val_binary_accuracy: 0.2555 - val_categorical_accuracy: 0.2417\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 1.0099 - binary_accuracy: 0.2529 - categorical_accuracy: 0.2572 - val_loss: 0.9864 - val_binary_accuracy: 0.2551 - val_categorical_accuracy: 0.2396\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 1.0115 - binary_accuracy: 0.2523 - categorical_accuracy: 0.2500 - val_loss: 0.9846 - val_binary_accuracy: 0.2575 - val_categorical_accuracy: 0.2200\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.0037 - binary_accuracy: 0.2545 - categorical_accuracy: 0.2365 - val_loss: 0.9801 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2417\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 1.0021 - binary_accuracy: 0.2511 - categorical_accuracy: 0.2566 - val_loss: 0.9785 - val_binary_accuracy: 0.2560 - val_categorical_accuracy: 0.2517\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.9975 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2517 - val_loss: 0.9780 - val_binary_accuracy: 0.2597 - val_categorical_accuracy: 0.2212\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.9988 - binary_accuracy: 0.2544 - categorical_accuracy: 0.2266 - val_loss: 0.9720 - val_binary_accuracy: 0.2557 - val_categorical_accuracy: 0.2521\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.9954 - binary_accuracy: 0.2516 - categorical_accuracy: 0.2635 - val_loss: 0.9688 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2492\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.9930 - binary_accuracy: 0.2520 - categorical_accuracy: 0.2490 - val_loss: 0.9682 - val_binary_accuracy: 0.2584 - val_categorical_accuracy: 0.2288\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 206ms/step - loss: 0.9940 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2472 - val_loss: 0.9650 - val_binary_accuracy: 0.2557 - val_categorical_accuracy: 0.2558\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.9898 - binary_accuracy: 0.2529 - categorical_accuracy: 0.2525 - val_loss: 0.9618 - val_binary_accuracy: 0.2557 - val_categorical_accuracy: 0.2408\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.9810 - binary_accuracy: 0.2520 - categorical_accuracy: 0.2537 - val_loss: 0.9585 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2500\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.9808 - binary_accuracy: 0.2519 - categorical_accuracy: 0.2534 - val_loss: 0.9567 - val_binary_accuracy: 0.2559 - val_categorical_accuracy: 0.2454\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.9815 - binary_accuracy: 0.2506 - categorical_accuracy: 0.2611 - val_loss: 0.9539 - val_binary_accuracy: 0.2559 - val_categorical_accuracy: 0.2479\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 0.9723 - binary_accuracy: 0.2524 - categorical_accuracy: 0.2530 - val_loss: 0.9515 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2463\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.9709 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2549 - val_loss: 0.9489 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2562\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.9687 - binary_accuracy: 0.2523 - categorical_accuracy: 0.2592 - val_loss: 0.9468 - val_binary_accuracy: 0.2570 - val_categorical_accuracy: 0.2342\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.9681 - binary_accuracy: 0.2523 - categorical_accuracy: 0.2420 - val_loss: 0.9437 - val_binary_accuracy: 0.2553 - val_categorical_accuracy: 0.2612\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.9667 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2671 - val_loss: 0.9426 - val_binary_accuracy: 0.2552 - val_categorical_accuracy: 0.2604\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.9643 - binary_accuracy: 0.2524 - categorical_accuracy: 0.2501 - val_loss: 0.9416 - val_binary_accuracy: 0.2570 - val_categorical_accuracy: 0.2367\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.9613 - binary_accuracy: 0.2512 - categorical_accuracy: 0.2514 - val_loss: 0.9373 - val_binary_accuracy: 0.2540 - val_categorical_accuracy: 0.2637\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 194ms/step - loss: 0.9637 - binary_accuracy: 0.2521 - categorical_accuracy: 0.2661 - val_loss: 0.9360 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2463\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.9594 - binary_accuracy: 0.2514 - categorical_accuracy: 0.2486 - val_loss: 0.9332 - val_binary_accuracy: 0.2548 - val_categorical_accuracy: 0.2604\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.9553 - binary_accuracy: 0.2509 - categorical_accuracy: 0.2627 - val_loss: 0.9325 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2512\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.9522 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2524 - val_loss: 0.9296 - val_binary_accuracy: 0.2544 - val_categorical_accuracy: 0.2492\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.9550 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2617 - val_loss: 0.9264 - val_binary_accuracy: 0.2540 - val_categorical_accuracy: 0.2612\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.9499 - binary_accuracy: 0.2513 - categorical_accuracy: 0.2604 - val_loss: 0.9266 - val_binary_accuracy: 0.2560 - val_categorical_accuracy: 0.2483\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 0.9461 - binary_accuracy: 0.2522 - categorical_accuracy: 0.2589 - val_loss: 0.9225 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2562\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.9464 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2678 - val_loss: 0.9228 - val_binary_accuracy: 0.2561 - val_categorical_accuracy: 0.2404\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.9418 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2496 - val_loss: 0.9191 - val_binary_accuracy: 0.2546 - val_categorical_accuracy: 0.2512\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.9420 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2668 - val_loss: 0.9154 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2608\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.9418 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2634 - val_loss: 0.9151 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2517\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.9402 - binary_accuracy: 0.2519 - categorical_accuracy: 0.2549 - val_loss: 0.9119 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2583\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.9370 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2774 - val_loss: 0.9107 - val_binary_accuracy: 0.2544 - val_categorical_accuracy: 0.2467\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.9374 - binary_accuracy: 0.2517 - categorical_accuracy: 0.2451 - val_loss: 0.9096 - val_binary_accuracy: 0.2552 - val_categorical_accuracy: 0.2454\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.9327 - binary_accuracy: 0.2506 - categorical_accuracy: 0.2629 - val_loss: 0.9066 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2650\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.9307 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2751 - val_loss: 0.9081 - val_binary_accuracy: 0.2579 - val_categorical_accuracy: 0.2325\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.9314 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2431 - val_loss: 0.9019 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2583\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.9292 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2701 - val_loss: 0.9013 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2587\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.9255 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2636 - val_loss: 0.9008 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2383\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.9218 - binary_accuracy: 0.2519 - categorical_accuracy: 0.2535 - val_loss: 0.8960 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2604\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.9224 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2671 - val_loss: 0.8957 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2500\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.9202 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2590 - val_loss: 0.8947 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2554\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.9220 - binary_accuracy: 0.2510 - categorical_accuracy: 0.2591 - val_loss: 0.8914 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2646\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.9179 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2746 - val_loss: 0.8923 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2488\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.9155 - binary_accuracy: 0.2512 - categorical_accuracy: 0.2556 - val_loss: 0.8916 - val_binary_accuracy: 0.2553 - val_categorical_accuracy: 0.2471\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.9176 - binary_accuracy: 0.2515 - categorical_accuracy: 0.2628 - val_loss: 0.8855 - val_binary_accuracy: 0.2503 - val_categorical_accuracy: 0.2700\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.9173 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2753 - val_loss: 0.8882 - val_binary_accuracy: 0.2544 - val_categorical_accuracy: 0.2379\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.9103 - binary_accuracy: 0.2514 - categorical_accuracy: 0.2485 - val_loss: 0.8855 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2571\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.9098 - binary_accuracy: 0.2509 - categorical_accuracy: 0.2715 - val_loss: 0.8809 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2637\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.9136 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2688 - val_loss: 0.8817 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2454\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.9090 - binary_accuracy: 0.2510 - categorical_accuracy: 0.2577 - val_loss: 0.8790 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2587\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.9025 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2752 - val_loss: 0.8764 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2525\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.9022 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2582 - val_loss: 0.8757 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2483\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.9035 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2635 - val_loss: 0.8718 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2579\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.9009 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2696 - val_loss: 0.8722 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2450\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8980 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2580 - val_loss: 0.8709 - val_binary_accuracy: 0.2540 - val_categorical_accuracy: 0.2508\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.8939 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2675 - val_loss: 0.8676 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2587\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8965 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2635 - val_loss: 0.8672 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2471\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8908 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2552 - val_loss: 0.8647 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2633\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.8931 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2781 - val_loss: 0.8638 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2546\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8908 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2564 - val_loss: 0.8629 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2542\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8912 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2731 - val_loss: 0.8621 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2604\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8883 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2663 - val_loss: 0.8617 - val_binary_accuracy: 0.2548 - val_categorical_accuracy: 0.2383\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.8871 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2524 - val_loss: 0.8573 - val_binary_accuracy: 0.2507 - val_categorical_accuracy: 0.2683\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.8881 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2795 - val_loss: 0.8593 - val_binary_accuracy: 0.2542 - val_categorical_accuracy: 0.2454\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.8832 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2548 - val_loss: 0.8563 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2475\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8853 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2654 - val_loss: 0.8537 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2642\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8860 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2728 - val_loss: 0.8543 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2479\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8801 - binary_accuracy: 0.2508 - categorical_accuracy: 0.2574 - val_loss: 0.8524 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2517\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8798 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2637 - val_loss: 0.8498 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2583\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.8777 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2671 - val_loss: 0.8484 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2554\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8783 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2705 - val_loss: 0.8471 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2533\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.8797 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2643 - val_loss: 0.8474 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2471\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8772 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2672 - val_loss: 0.8453 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2496\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.8719 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2676 - val_loss: 0.8442 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2512\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8738 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2649 - val_loss: 0.8435 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2537\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.8681 - binary_accuracy: 0.2511 - categorical_accuracy: 0.2676 - val_loss: 0.8420 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2546\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8706 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2655 - val_loss: 0.8409 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2587\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.8711 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2696 - val_loss: 0.8401 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2517\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8669 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2594 - val_loss: 0.8388 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2471\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.8656 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2654 - val_loss: 0.8365 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2637\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.8669 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2726 - val_loss: 0.8390 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2483\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.8666 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2581 - val_loss: 0.8360 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2558\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.8643 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2706 - val_loss: 0.8341 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2575\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.8661 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2649 - val_loss: 0.8350 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2496\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.8633 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2670 - val_loss: 0.8326 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2600\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.8600 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2707 - val_loss: 0.8322 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2475\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8618 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2620 - val_loss: 0.8296 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2596\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.8587 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2657 - val_loss: 0.8301 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2571\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8618 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2690 - val_loss: 0.8294 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2554\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.8577 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2686 - val_loss: 0.8292 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2500\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8580 - binary_accuracy: 0.2507 - categorical_accuracy: 0.2530 - val_loss: 0.8290 - val_binary_accuracy: 0.2540 - val_categorical_accuracy: 0.2475\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.8582 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2716 - val_loss: 0.8252 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2650\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8544 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2643 - val_loss: 0.8289 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2387\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8541 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2586 - val_loss: 0.8251 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2650\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.8552 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2763 - val_loss: 0.8264 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2458\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.8551 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2502 - val_loss: 0.8236 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2546\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.8515 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2782 - val_loss: 0.8229 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2600\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8515 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2620 - val_loss: 0.8254 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2404\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8542 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2608 - val_loss: 0.8217 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2696\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.8482 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2789 - val_loss: 0.8221 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2433\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8502 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2531 - val_loss: 0.8202 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2521\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8500 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2748 - val_loss: 0.8177 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2667\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8465 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2701 - val_loss: 0.8197 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2429\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8485 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2518 - val_loss: 0.8173 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2567\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8472 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2761 - val_loss: 0.8159 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2600\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8421 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2761 - val_loss: 0.8177 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2408\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8424 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2553 - val_loss: 0.8149 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2600\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.8445 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2804 - val_loss: 0.8155 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2479\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.8388 - binary_accuracy: 0.2506 - categorical_accuracy: 0.2553 - val_loss: 0.8142 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2471\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.8438 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2689 - val_loss: 0.8118 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2671\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8434 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2772 - val_loss: 0.8161 - val_binary_accuracy: 0.2552 - val_categorical_accuracy: 0.2371\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8429 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2532 - val_loss: 0.8115 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2558\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.8381 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2716 - val_loss: 0.8114 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2621\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8379 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2707 - val_loss: 0.8141 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2371\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8403 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2542 - val_loss: 0.8094 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2621\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8381 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2805 - val_loss: 0.8088 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2567\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8392 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2618 - val_loss: 0.8109 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2396\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8376 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2598 - val_loss: 0.8069 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2633\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8379 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2744 - val_loss: 0.8091 - val_binary_accuracy: 0.2539 - val_categorical_accuracy: 0.2492\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.8344 - binary_accuracy: 0.2511 - categorical_accuracy: 0.2574 - val_loss: 0.8093 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2471\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8404 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2668 - val_loss: 0.8072 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2562\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.8333 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2668 - val_loss: 0.8089 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2463\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.8325 - binary_accuracy: 0.2506 - categorical_accuracy: 0.2578 - val_loss: 0.8058 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2550\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.8332 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2713 - val_loss: 0.8042 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2554\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8324 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2678 - val_loss: 0.8065 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2450\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8310 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2587 - val_loss: 0.8044 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2554\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8344 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2698 - val_loss: 0.8030 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2554\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8300 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2708 - val_loss: 0.8032 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2458\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.8297 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2591 - val_loss: 0.8015 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2612\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8302 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2744 - val_loss: 0.8008 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2533\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8293 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2621 - val_loss: 0.8020 - val_binary_accuracy: 0.2539 - val_categorical_accuracy: 0.2525\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8288 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2665 - val_loss: 0.8008 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2604\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8310 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2733 - val_loss: 0.8003 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2475\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.8286 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2626 - val_loss: 0.8001 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2525\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.8256 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2709 - val_loss: 0.7990 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2567\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.8283 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2637 - val_loss: 0.8006 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2421\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.8260 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2574 - val_loss: 0.7982 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2646\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8263 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2748 - val_loss: 0.7970 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2517\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8243 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2653 - val_loss: 0.7989 - val_binary_accuracy: 0.2544 - val_categorical_accuracy: 0.2433\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8229 - binary_accuracy: 0.2508 - categorical_accuracy: 0.2602 - val_loss: 0.7967 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2688\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8234 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2784 - val_loss: 0.7971 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2446\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8266 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2599 - val_loss: 0.7957 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2454\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.8216 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2665 - val_loss: 0.7929 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2575\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.8206 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2674 - val_loss: 0.7954 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2429\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.8209 - binary_accuracy: 0.2507 - categorical_accuracy: 0.2586 - val_loss: 0.7947 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2525\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8208 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2684 - val_loss: 0.7935 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2562\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8215 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2706 - val_loss: 0.7935 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2537\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8190 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2645 - val_loss: 0.7935 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2492\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.8218 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2640 - val_loss: 0.7920 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2496\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.8205 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2679 - val_loss: 0.7922 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2562\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8170 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2614 - val_loss: 0.7920 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2463\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8198 - binary_accuracy: 0.2506 - categorical_accuracy: 0.2673 - val_loss: 0.7896 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2546\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8176 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2700 - val_loss: 0.7900 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2504\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8174 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2602 - val_loss: 0.7903 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2483\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.8164 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2684 - val_loss: 0.7884 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2642\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8191 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2731 - val_loss: 0.7919 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2371\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.8159 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2536 - val_loss: 0.7872 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2579\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.8125 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2734 - val_loss: 0.7880 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2575\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.8157 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2670 - val_loss: 0.7900 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2417\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8144 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2646 - val_loss: 0.7865 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2617\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8177 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2725 - val_loss: 0.7886 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2446\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8149 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2597 - val_loss: 0.7867 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2483\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.8148 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2646 - val_loss: 0.7852 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2608\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.8155 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2721 - val_loss: 0.7870 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2504\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.8098 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2621 - val_loss: 0.7854 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2537\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.8108 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2663 - val_loss: 0.7841 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2554\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.8105 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2694 - val_loss: 0.7856 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2433\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.8122 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2600 - val_loss: 0.7841 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2479\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.8074 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2657 - val_loss: 0.7831 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2608\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8094 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2714 - val_loss: 0.7844 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2463\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.8136 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2628 - val_loss: 0.7832 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2529\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.8078 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2649 - val_loss: 0.7823 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2587\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.8116 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2659 - val_loss: 0.7831 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2492\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8113 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2591 - val_loss: 0.7806 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2558\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8089 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2716 - val_loss: 0.7811 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2562\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.8047 - binary_accuracy: 0.2510 - categorical_accuracy: 0.2618 - val_loss: 0.7816 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2492\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8078 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2689 - val_loss: 0.7796 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2592\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.8046 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2647 - val_loss: 0.7811 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2471\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.8057 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2575 - val_loss: 0.7794 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2604\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8079 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2735 - val_loss: 0.7782 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2587\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.8063 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2649 - val_loss: 0.7812 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2429\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8047 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2561 - val_loss: 0.7774 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2617\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8040 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2738 - val_loss: 0.7774 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2492\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.8050 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2586 - val_loss: 0.7778 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2537\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8051 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2711 - val_loss: 0.7767 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2575\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.8064 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2608 - val_loss: 0.7790 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2417\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.8027 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2593 - val_loss: 0.7754 - val_binary_accuracy: 0.2505 - val_categorical_accuracy: 0.2733\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8013 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2828 - val_loss: 0.7774 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2450\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8040 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2549 - val_loss: 0.7769 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2471\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7992 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2665 - val_loss: 0.7741 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2696\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.8040 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2767 - val_loss: 0.7770 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2417\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.8033 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2515 - val_loss: 0.7745 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2546\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7996 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2706 - val_loss: 0.7738 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2625\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.8013 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2716 - val_loss: 0.7763 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2412\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.8022 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2543 - val_loss: 0.7734 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2600\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.7970 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2756 - val_loss: 0.7726 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2583\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.8048 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2634 - val_loss: 0.7754 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2433\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.8018 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2637 - val_loss: 0.7717 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2683\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7997 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2792 - val_loss: 0.7722 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2488\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7983 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2561 - val_loss: 0.7734 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2408\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.8005 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2628 - val_loss: 0.7712 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2696\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 0.7968 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2789 - val_loss: 0.7714 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2512\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.8045 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2626 - val_loss: 0.7715 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2467\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7987 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2636 - val_loss: 0.7711 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2604\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7995 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2699 - val_loss: 0.7719 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2458\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7963 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2614 - val_loss: 0.7694 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2554\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7975 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2715 - val_loss: 0.7701 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2517\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7955 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2632 - val_loss: 0.7706 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2463\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.7953 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2640 - val_loss: 0.7680 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2612\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7923 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2709 - val_loss: 0.7691 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2475\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7917 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2602 - val_loss: 0.7673 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2521\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7922 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2659 - val_loss: 0.7665 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2592\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7965 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2698 - val_loss: 0.7677 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2533\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.7956 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2633 - val_loss: 0.7685 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2529\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7955 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2681 - val_loss: 0.7668 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2562\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7922 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2625 - val_loss: 0.7671 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2517\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7903 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2671 - val_loss: 0.7669 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2612\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7932 - binary_accuracy: 0.2508 - categorical_accuracy: 0.2694 - val_loss: 0.7668 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2529\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7881 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2618 - val_loss: 0.7651 - val_binary_accuracy: 0.2505 - val_categorical_accuracy: 0.2579\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7946 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2699 - val_loss: 0.7655 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2521\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.7910 - binary_accuracy: 0.2508 - categorical_accuracy: 0.2611 - val_loss: 0.7651 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2533\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7923 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2707 - val_loss: 0.7642 - val_binary_accuracy: 0.2507 - val_categorical_accuracy: 0.2617\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7902 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2651 - val_loss: 0.7664 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2417\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7927 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2571 - val_loss: 0.7621 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2633\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7921 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2742 - val_loss: 0.7619 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2575\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7872 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2675 - val_loss: 0.7631 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2471\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7899 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2618 - val_loss: 0.7623 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2554\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7884 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2637 - val_loss: 0.7615 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2567\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7870 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2720 - val_loss: 0.7624 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2554\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7877 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2601 - val_loss: 0.7631 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2492\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7873 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2675 - val_loss: 0.7601 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2654\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7882 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2697 - val_loss: 0.7620 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2475\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.7842 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2607 - val_loss: 0.7590 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2612\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7878 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2739 - val_loss: 0.7601 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2542\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7873 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2615 - val_loss: 0.7618 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2492\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7847 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2611 - val_loss: 0.7591 - val_binary_accuracy: 0.2506 - val_categorical_accuracy: 0.2642\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7869 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2758 - val_loss: 0.7605 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2467\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7853 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2598 - val_loss: 0.7601 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2508\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7869 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2696 - val_loss: 0.7581 - val_binary_accuracy: 0.2506 - val_categorical_accuracy: 0.2671\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7847 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2727 - val_loss: 0.7605 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2458\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7882 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2561 - val_loss: 0.7595 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2517\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7851 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2699 - val_loss: 0.7572 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2596\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7884 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2642 - val_loss: 0.7589 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2488\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7820 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2653 - val_loss: 0.7575 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2646\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.7848 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2734 - val_loss: 0.7589 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2438\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7819 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2582 - val_loss: 0.7571 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2529\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7835 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2693 - val_loss: 0.7566 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2579\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7842 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2683 - val_loss: 0.7573 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2467\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7839 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2616 - val_loss: 0.7566 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2483\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7824 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2693 - val_loss: 0.7552 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2600\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7812 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2657 - val_loss: 0.7579 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2404\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7830 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2560 - val_loss: 0.7542 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2600\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.7817 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2754 - val_loss: 0.7541 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2625\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.7788 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2678 - val_loss: 0.7569 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2429\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.7811 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2559 - val_loss: 0.7541 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2646\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.7796 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2761 - val_loss: 0.7534 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2612\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.7842 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2659 - val_loss: 0.7562 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2421\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7812 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2592 - val_loss: 0.7526 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2642\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7802 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2721 - val_loss: 0.7520 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2587\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7770 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2648 - val_loss: 0.7542 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2471\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7821 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2600 - val_loss: 0.7522 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2600\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7783 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2679 - val_loss: 0.7529 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2533\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.7790 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2628 - val_loss: 0.7537 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2463\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7795 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2624 - val_loss: 0.7513 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2617\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7781 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2698 - val_loss: 0.7516 - val_binary_accuracy: 0.2508 - val_categorical_accuracy: 0.2521\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7774 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2590 - val_loss: 0.7517 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2537\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7774 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2674 - val_loss: 0.7512 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2579\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7783 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2694 - val_loss: 0.7524 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2475\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7797 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2560 - val_loss: 0.7523 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2546\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.7784 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2694 - val_loss: 0.7495 - val_binary_accuracy: 0.2506 - val_categorical_accuracy: 0.2642\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7757 - binary_accuracy: 0.2475 - categorical_accuracy: 0.2679 - val_loss: 0.7516 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2450\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7760 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2658 - val_loss: 0.7515 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2612\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7825 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2686 - val_loss: 0.7520 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2488\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7746 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2612 - val_loss: 0.7495 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2625\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7763 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2758 - val_loss: 0.7513 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2537\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7768 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2596 - val_loss: 0.7517 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2425\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7772 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2600 - val_loss: 0.7481 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2671\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7775 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2777 - val_loss: 0.7502 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2504\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7764 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2571 - val_loss: 0.7507 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2404\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7754 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2643 - val_loss: 0.7466 - val_binary_accuracy: 0.2507 - val_categorical_accuracy: 0.2696\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7755 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2754 - val_loss: 0.7494 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2458\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7761 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2572 - val_loss: 0.7487 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2488\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7736 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2695 - val_loss: 0.7475 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2621\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7696 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2686 - val_loss: 0.7491 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2450\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7746 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2606 - val_loss: 0.7475 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2500\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7767 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2634 - val_loss: 0.7464 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2517\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7719 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2640 - val_loss: 0.7458 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2571\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7727 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2739 - val_loss: 0.7477 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2463\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7670 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2602 - val_loss: 0.7472 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2496\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7728 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2702 - val_loss: 0.7451 - val_binary_accuracy: 0.2501 - val_categorical_accuracy: 0.2650\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.7729 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2701 - val_loss: 0.7461 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2546\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7762 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2676 - val_loss: 0.7456 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2562\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7691 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2637 - val_loss: 0.7456 - val_binary_accuracy: 0.2505 - val_categorical_accuracy: 0.2467\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.7719 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2607 - val_loss: 0.7434 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2625\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7701 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2697 - val_loss: 0.7456 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2492\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7707 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2576 - val_loss: 0.7450 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2529\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7682 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2641 - val_loss: 0.7433 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2617\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.7651 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2705 - val_loss: 0.7448 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2463\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7709 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2614 - val_loss: 0.7434 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2562\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7725 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2665 - val_loss: 0.7431 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2608\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.7658 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2678 - val_loss: 0.7435 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2537\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7654 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2623 - val_loss: 0.7434 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2542\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.7671 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2678 - val_loss: 0.7423 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2587\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7660 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2682 - val_loss: 0.7435 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2508\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7680 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2581 - val_loss: 0.7426 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2537\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7693 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2635 - val_loss: 0.7410 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2596\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7720 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2642 - val_loss: 0.7423 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2496\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.7665 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2651 - val_loss: 0.7401 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2621\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7676 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2725 - val_loss: 0.7419 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2496\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.7695 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2617 - val_loss: 0.7420 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2517\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.7716 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2657 - val_loss: 0.7404 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2604\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7680 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2648 - val_loss: 0.7417 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2458\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7677 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2631 - val_loss: 0.7400 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2600\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7656 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2685 - val_loss: 0.7408 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2496\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.7652 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2602 - val_loss: 0.7395 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2546\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7701 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2679 - val_loss: 0.7389 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2583\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7631 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2718 - val_loss: 0.7401 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2504\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7611 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2618 - val_loss: 0.7397 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2512\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7652 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2660 - val_loss: 0.7387 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2587\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.7655 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2720 - val_loss: 0.7395 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2512\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7609 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2571 - val_loss: 0.7392 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2467\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7669 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2668 - val_loss: 0.7365 - val_binary_accuracy: 0.2502 - val_categorical_accuracy: 0.2654\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7617 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2714 - val_loss: 0.7406 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2412\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.7631 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2519 - val_loss: 0.7386 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2554\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7624 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2683 - val_loss: 0.7358 - val_binary_accuracy: 0.2507 - val_categorical_accuracy: 0.2696\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7628 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2707 - val_loss: 0.7391 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2450\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7619 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2568 - val_loss: 0.7374 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2617\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7616 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2734 - val_loss: 0.7366 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2604\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.7634 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2619 - val_loss: 0.7387 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2450\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7633 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2600 - val_loss: 0.7366 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2617\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7618 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2694 - val_loss: 0.7364 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2517\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7650 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2648 - val_loss: 0.7366 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2492\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7631 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2649 - val_loss: 0.7357 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2587\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7607 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2669 - val_loss: 0.7367 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2517\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7635 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2645 - val_loss: 0.7340 - val_binary_accuracy: 0.2504 - val_categorical_accuracy: 0.2650\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.7618 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2715 - val_loss: 0.7348 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2537\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.7597 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2642 - val_loss: 0.7370 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2425\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7607 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2618 - val_loss: 0.7349 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2571\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.7568 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2654 - val_loss: 0.7355 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2500\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7588 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2642 - val_loss: 0.7360 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2483\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7573 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2614 - val_loss: 0.7333 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2583\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 0.7646 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2695 - val_loss: 0.7333 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2550\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7587 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2660 - val_loss: 0.7354 - val_binary_accuracy: 0.2540 - val_categorical_accuracy: 0.2492\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.7606 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2629 - val_loss: 0.7339 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2550\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.7603 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2683 - val_loss: 0.7335 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2592\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7597 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2674 - val_loss: 0.7339 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2529\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7579 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2620 - val_loss: 0.7337 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2533\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7566 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2660 - val_loss: 0.7327 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2596\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.7542 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2663 - val_loss: 0.7334 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2542\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7586 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2653 - val_loss: 0.7317 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2583\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7577 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2714 - val_loss: 0.7320 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2542\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7582 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2614 - val_loss: 0.7329 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2471\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7577 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2606 - val_loss: 0.7309 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2558\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7569 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2716 - val_loss: 0.7308 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2571\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.7567 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2635 - val_loss: 0.7328 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2496\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 0.7568 - binary_accuracy: 0.2509 - categorical_accuracy: 0.2620 - val_loss: 0.7309 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2571\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7578 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2697 - val_loss: 0.7308 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2567\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7587 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2680 - val_loss: 0.7329 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2463\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7557 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2573 - val_loss: 0.7303 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2558\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.7589 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2674 - val_loss: 0.7309 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2554\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7558 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2677 - val_loss: 0.7318 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2492\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7585 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2614 - val_loss: 0.7296 - val_binary_accuracy: 0.2506 - val_categorical_accuracy: 0.2587\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.7553 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2704 - val_loss: 0.7297 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2600\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.7548 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2681 - val_loss: 0.7304 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2504\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7569 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2579 - val_loss: 0.7296 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2575\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7576 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2693 - val_loss: 0.7301 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2554\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.7550 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2624 - val_loss: 0.7310 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2504\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7549 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2642 - val_loss: 0.7294 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2579\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.7522 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2681 - val_loss: 0.7293 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2562\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.7548 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2623 - val_loss: 0.7306 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2483\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7543 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2629 - val_loss: 0.7278 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2579\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.7588 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2686 - val_loss: 0.7278 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2567\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7556 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2691 - val_loss: 0.7291 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2492\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.7544 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2579 - val_loss: 0.7286 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2554\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7564 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2667 - val_loss: 0.7283 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2575\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.7504 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2654 - val_loss: 0.7296 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2496\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7523 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2639 - val_loss: 0.7286 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2529\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7537 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2695 - val_loss: 0.7268 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2625\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7517 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2682 - val_loss: 0.7291 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2446\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7529 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2603 - val_loss: 0.7270 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2525\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7538 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2696 - val_loss: 0.7258 - val_binary_accuracy: 0.2507 - val_categorical_accuracy: 0.2617\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7536 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2683 - val_loss: 0.7299 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2463\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7488 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2585 - val_loss: 0.7274 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2525\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7517 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2688 - val_loss: 0.7262 - val_binary_accuracy: 0.2500 - val_categorical_accuracy: 0.2587\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7523 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2664 - val_loss: 0.7294 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2450\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7530 - binary_accuracy: 0.2510 - categorical_accuracy: 0.2542 - val_loss: 0.7261 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2529\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7507 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2703 - val_loss: 0.7249 - val_binary_accuracy: 0.2496 - val_categorical_accuracy: 0.2629\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7500 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2723 - val_loss: 0.7294 - val_binary_accuracy: 0.2539 - val_categorical_accuracy: 0.2421\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7505 - binary_accuracy: 0.2508 - categorical_accuracy: 0.2574 - val_loss: 0.7261 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2533\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7517 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2729 - val_loss: 0.7265 - val_binary_accuracy: 0.2502 - val_categorical_accuracy: 0.2550\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7495 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2634 - val_loss: 0.7279 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2475\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7488 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2632 - val_loss: 0.7264 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2571\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7511 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2702 - val_loss: 0.7258 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2529\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7555 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2641 - val_loss: 0.7257 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2521\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7470 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2667 - val_loss: 0.7246 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2567\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7482 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2694 - val_loss: 0.7247 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2529\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7443 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2642 - val_loss: 0.7247 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2529\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7469 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2627 - val_loss: 0.7237 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2583\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7504 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2743 - val_loss: 0.7237 - val_binary_accuracy: 0.2503 - val_categorical_accuracy: 0.2575\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7484 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2688 - val_loss: 0.7268 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2433\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7478 - binary_accuracy: 0.2507 - categorical_accuracy: 0.2576 - val_loss: 0.7245 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2546\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7499 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2700 - val_loss: 0.7234 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2579\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7480 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2715 - val_loss: 0.7251 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2479\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7471 - binary_accuracy: 0.2508 - categorical_accuracy: 0.2606 - val_loss: 0.7246 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2550\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7498 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2708 - val_loss: 0.7237 - val_binary_accuracy: 0.2503 - val_categorical_accuracy: 0.2542\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7482 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2644 - val_loss: 0.7243 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2517\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7456 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2626 - val_loss: 0.7234 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2562\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7437 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2646 - val_loss: 0.7228 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2575\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7508 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2696 - val_loss: 0.7225 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2558\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7471 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2657 - val_loss: 0.7233 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2529\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7457 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2604 - val_loss: 0.7235 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2496\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7464 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2667 - val_loss: 0.7216 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2567\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7470 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2655 - val_loss: 0.7211 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2558\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7458 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2676 - val_loss: 0.7216 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2533\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7467 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2664 - val_loss: 0.7220 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2542\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7435 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2646 - val_loss: 0.7220 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2525\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7435 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2621 - val_loss: 0.7223 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2550\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7429 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2658 - val_loss: 0.7210 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2575\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.7483 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2684 - val_loss: 0.7220 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2492\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.7432 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2623 - val_loss: 0.7202 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2579\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7445 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2643 - val_loss: 0.7199 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2562\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.7391 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2640 - val_loss: 0.7193 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2567\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.7434 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2678 - val_loss: 0.7192 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2533\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7467 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2639 - val_loss: 0.7189 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2550\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.7419 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2648 - val_loss: 0.7191 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2546\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7419 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2663 - val_loss: 0.7194 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2546\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7464 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2644 - val_loss: 0.7195 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2542\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7427 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2667 - val_loss: 0.7198 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2533\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7442 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2647 - val_loss: 0.7205 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2500\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7425 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2625 - val_loss: 0.7194 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2571\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.7460 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2664 - val_loss: 0.7187 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2512\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7439 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2655 - val_loss: 0.7181 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2546\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.7442 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2711 - val_loss: 0.7198 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2512\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7445 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2622 - val_loss: 0.7200 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2467\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7375 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2592 - val_loss: 0.7173 - val_binary_accuracy: 0.2508 - val_categorical_accuracy: 0.2604\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.7386 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2700 - val_loss: 0.7182 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2596\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.7423 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2640 - val_loss: 0.7193 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2467\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7409 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2629 - val_loss: 0.7165 - val_binary_accuracy: 0.2507 - val_categorical_accuracy: 0.2646\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.7407 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2743 - val_loss: 0.7176 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2567\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.7459 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2626 - val_loss: 0.7190 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2475\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.7392 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2616 - val_loss: 0.7166 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2642\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7414 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2706 - val_loss: 0.7170 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2567\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7401 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2636 - val_loss: 0.7183 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2492\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7394 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2603 - val_loss: 0.7165 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2579\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.7385 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2707 - val_loss: 0.7169 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2533\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7402 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2646 - val_loss: 0.7174 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2463\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 0.7382 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2626 - val_loss: 0.7159 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2550\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7379 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2682 - val_loss: 0.7161 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2542\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7381 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2644 - val_loss: 0.7169 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2475\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7372 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2551 - val_loss: 0.7153 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2592\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7380 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2740 - val_loss: 0.7158 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2562\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7381 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2615 - val_loss: 0.7169 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2475\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7394 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2586 - val_loss: 0.7147 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2587\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7394 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2703 - val_loss: 0.7151 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2575\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7406 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2666 - val_loss: 0.7168 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2479\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7398 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2628 - val_loss: 0.7157 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2508\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.7401 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2612 - val_loss: 0.7139 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2579\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7371 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2718 - val_loss: 0.7134 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2558\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.7393 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2625 - val_loss: 0.7147 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2488\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.7364 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2615 - val_loss: 0.7143 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2583\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7371 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2690 - val_loss: 0.7145 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2554\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7349 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2614 - val_loss: 0.7140 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2542\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7365 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2637 - val_loss: 0.7132 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2621\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7348 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2704 - val_loss: 0.7145 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2517\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7380 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2635 - val_loss: 0.7144 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2554\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7400 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2664 - val_loss: 0.7131 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2558\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7360 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2631 - val_loss: 0.7134 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2508\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7339 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2645 - val_loss: 0.7128 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2583\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7386 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2653 - val_loss: 0.7133 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2512\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7315 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2640 - val_loss: 0.7120 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2592\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7394 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2671 - val_loss: 0.7128 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2554\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7379 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2656 - val_loss: 0.7130 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2525\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.7341 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2610 - val_loss: 0.7116 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2562\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7314 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2716 - val_loss: 0.7113 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2562\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7410 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2608 - val_loss: 0.7140 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2463\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7319 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2587 - val_loss: 0.7111 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2617\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7361 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2693 - val_loss: 0.7120 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2554\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.7346 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2625 - val_loss: 0.7128 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2525\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7353 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2620 - val_loss: 0.7114 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2575\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7332 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2704 - val_loss: 0.7116 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2517\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7336 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2618 - val_loss: 0.7118 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2517\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7334 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2632 - val_loss: 0.7094 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2629\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7306 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2715 - val_loss: 0.7116 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2517\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7335 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2605 - val_loss: 0.7121 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2525\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7345 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2589 - val_loss: 0.7108 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2592\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7349 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2665 - val_loss: 0.7108 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2558\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7340 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2651 - val_loss: 0.7094 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2579\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.7352 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2661 - val_loss: 0.7088 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2608\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.7319 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2725 - val_loss: 0.7099 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2567\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7348 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2628 - val_loss: 0.7115 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2471\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7360 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2584 - val_loss: 0.7093 - val_binary_accuracy: 0.2508 - val_categorical_accuracy: 0.2571\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7333 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2704 - val_loss: 0.7090 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2562\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.7287 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2679 - val_loss: 0.7098 - val_binary_accuracy: 0.2506 - val_categorical_accuracy: 0.2529\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7264 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2655 - val_loss: 0.7097 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2533\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7317 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2658 - val_loss: 0.7086 - val_binary_accuracy: 0.2508 - val_categorical_accuracy: 0.2533\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.7349 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2606 - val_loss: 0.7081 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2542\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.7319 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2677 - val_loss: 0.7079 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2583\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7345 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2692 - val_loss: 0.7083 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2575\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7338 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2711 - val_loss: 0.7092 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2517\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7309 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2590 - val_loss: 0.7080 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2558\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7330 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2656 - val_loss: 0.7084 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2579\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7324 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2655 - val_loss: 0.7099 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2483\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7299 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2633 - val_loss: 0.7071 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2583\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7286 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2681 - val_loss: 0.7081 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2537\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7321 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2619 - val_loss: 0.7085 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2479\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7289 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2627 - val_loss: 0.7048 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2637\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7288 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2736 - val_loss: 0.7080 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2496\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7289 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2578 - val_loss: 0.7078 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2504\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7334 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2637 - val_loss: 0.7053 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2658\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7305 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2698 - val_loss: 0.7074 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2517\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7278 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2591 - val_loss: 0.7069 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2533\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7292 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2656 - val_loss: 0.7054 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2579\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.7278 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2671 - val_loss: 0.7071 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2496\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7265 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2587 - val_loss: 0.7058 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2533\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.7337 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2675 - val_loss: 0.7054 - val_binary_accuracy: 0.2506 - val_categorical_accuracy: 0.2575\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.7290 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2656 - val_loss: 0.7077 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2512\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7317 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2595 - val_loss: 0.7065 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2567\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7308 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2623 - val_loss: 0.7052 - val_binary_accuracy: 0.2508 - val_categorical_accuracy: 0.2587\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7307 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2734 - val_loss: 0.7063 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2567\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7300 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2672 - val_loss: 0.7081 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2475\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.7286 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2611 - val_loss: 0.7059 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2575\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7297 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2669 - val_loss: 0.7051 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2571\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.7276 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2689 - val_loss: 0.7075 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2458\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7266 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2589 - val_loss: 0.7049 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2546\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7285 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2655 - val_loss: 0.7043 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2592\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7272 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2719 - val_loss: 0.7059 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2537\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7281 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2571 - val_loss: 0.7061 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2500\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7280 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2616 - val_loss: 0.7038 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2663\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7303 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2772 - val_loss: 0.7056 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2537\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7270 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2582 - val_loss: 0.7056 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2508\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7254 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2623 - val_loss: 0.7028 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2646\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7257 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2721 - val_loss: 0.7051 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2504\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7254 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2575 - val_loss: 0.7050 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2517\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7259 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2646 - val_loss: 0.7032 - val_binary_accuracy: 0.2510 - val_categorical_accuracy: 0.2608\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7228 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2731 - val_loss: 0.7053 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2504\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.7236 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2548 - val_loss: 0.7057 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2500\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7293 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2669 - val_loss: 0.7020 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2612\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7255 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2705 - val_loss: 0.7042 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2504\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7245 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2590 - val_loss: 0.7048 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2479\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.7260 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2600 - val_loss: 0.7016 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2646\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7286 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2773 - val_loss: 0.7031 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2529\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7250 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2627 - val_loss: 0.7060 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2442\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7258 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2598 - val_loss: 0.7031 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2617\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7218 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2719 - val_loss: 0.7033 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2558\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7269 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2623 - val_loss: 0.7036 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2521\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7249 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2611 - val_loss: 0.7013 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2625\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7253 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2692 - val_loss: 0.7015 - val_binary_accuracy: 0.2508 - val_categorical_accuracy: 0.2558\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7291 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2649 - val_loss: 0.7024 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2550\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7278 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2670 - val_loss: 0.7013 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2579\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7252 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2660 - val_loss: 0.7017 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2537\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7265 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2643 - val_loss: 0.7014 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2542\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7271 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2691 - val_loss: 0.7007 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2571\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7254 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2695 - val_loss: 0.7024 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2546\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.7275 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2609 - val_loss: 0.7032 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2525\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7224 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2641 - val_loss: 0.7016 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2537\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7204 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2659 - val_loss: 0.7013 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2542\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7257 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2647 - val_loss: 0.7022 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2500\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.7223 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2591 - val_loss: 0.7003 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2571\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7207 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2674 - val_loss: 0.6994 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2604\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7247 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2696 - val_loss: 0.7023 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2475\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 0.7238 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2576 - val_loss: 0.7013 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2500\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.7268 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2668 - val_loss: 0.6996 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2604\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7242 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2694 - val_loss: 0.7018 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2504\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7227 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2610 - val_loss: 0.7006 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2550\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7241 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2667 - val_loss: 0.7006 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2562\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7243 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2604 - val_loss: 0.7009 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2492\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7231 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2631 - val_loss: 0.6997 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2592\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7229 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2688 - val_loss: 0.7000 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2529\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7183 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2622 - val_loss: 0.7005 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2517\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7204 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2651 - val_loss: 0.6995 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2562\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7202 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2695 - val_loss: 0.6999 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2529\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7189 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2653 - val_loss: 0.6999 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2508\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.7178 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2647 - val_loss: 0.6989 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2558\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7209 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2701 - val_loss: 0.6984 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2554\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7198 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2674 - val_loss: 0.6994 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2504\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7202 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2591 - val_loss: 0.6983 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2587\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7206 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2735 - val_loss: 0.6997 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2529\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7188 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2568 - val_loss: 0.6996 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2512\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7201 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2605 - val_loss: 0.6970 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2642\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7204 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2761 - val_loss: 0.6983 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2542\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7182 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2599 - val_loss: 0.6993 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2496\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7208 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2611 - val_loss: 0.6958 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2658\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7211 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2747 - val_loss: 0.6965 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2558\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.7168 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2631 - val_loss: 0.6989 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2479\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7215 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2627 - val_loss: 0.6972 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2579\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7175 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2681 - val_loss: 0.6971 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2537\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7201 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2610 - val_loss: 0.6982 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2458\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.7214 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2621 - val_loss: 0.6969 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2612\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.7182 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2685 - val_loss: 0.6971 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2517\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7172 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2658 - val_loss: 0.6984 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2512\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7224 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2624 - val_loss: 0.6974 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2583\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7212 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2653 - val_loss: 0.6964 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2550\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7193 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2651 - val_loss: 0.6970 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2533\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.7178 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2628 - val_loss: 0.6961 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2608\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.7186 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2660 - val_loss: 0.6970 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2533\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7172 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2647 - val_loss: 0.6967 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2517\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7176 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2670 - val_loss: 0.6956 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2571\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7185 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2673 - val_loss: 0.6963 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2537\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.7206 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2606 - val_loss: 0.6964 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2504\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7200 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2607 - val_loss: 0.6946 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2612\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7180 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2713 - val_loss: 0.6949 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2562\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.7197 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2631 - val_loss: 0.6961 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2475\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.7173 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2579 - val_loss: 0.6944 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2550\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7195 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2670 - val_loss: 0.6941 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2592\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7156 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2672 - val_loss: 0.6952 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2496\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7140 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2587 - val_loss: 0.6947 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2500\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7144 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2618 - val_loss: 0.6939 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2575\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7170 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2698 - val_loss: 0.6945 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2533\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7183 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2681 - val_loss: 0.6943 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2537\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7177 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2636 - val_loss: 0.6943 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2562\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7123 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2657 - val_loss: 0.6949 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2512\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7134 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2637 - val_loss: 0.6955 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2529\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7218 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2628 - val_loss: 0.6948 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2554\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7143 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2665 - val_loss: 0.6940 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2542\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7136 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2617 - val_loss: 0.6945 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2512\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7167 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2627 - val_loss: 0.6935 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2637\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7154 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2670 - val_loss: 0.6945 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2533\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7157 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2607 - val_loss: 0.6943 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2512\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7153 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2639 - val_loss: 0.6921 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2654\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7143 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2731 - val_loss: 0.6936 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2504\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.7102 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2566 - val_loss: 0.6935 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2533\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7154 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2640 - val_loss: 0.6928 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2571\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7138 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2695 - val_loss: 0.6941 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2525\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7175 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2619 - val_loss: 0.6938 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2504\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.7141 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2644 - val_loss: 0.6927 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2596\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.7152 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2688 - val_loss: 0.6941 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2508\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7173 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2587 - val_loss: 0.6939 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2496\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7108 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2627 - val_loss: 0.6921 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2571\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7133 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2705 - val_loss: 0.6930 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2546\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7170 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2652 - val_loss: 0.6932 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2537\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7175 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2614 - val_loss: 0.6921 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2512\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7153 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2678 - val_loss: 0.6907 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2571\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7142 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2661 - val_loss: 0.6920 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2504\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.7116 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2685 - val_loss: 0.6926 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2500\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7087 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2614 - val_loss: 0.6930 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2475\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7118 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2622 - val_loss: 0.6905 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2617\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7123 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2697 - val_loss: 0.6921 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2483\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.7144 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2616 - val_loss: 0.6930 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2504\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.7149 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2604 - val_loss: 0.6905 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2633\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7152 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2723 - val_loss: 0.6911 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2571\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7090 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2625 - val_loss: 0.6940 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2488\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7155 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2601 - val_loss: 0.6918 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2571\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7150 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2675 - val_loss: 0.6921 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2542\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.7116 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2622 - val_loss: 0.6920 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2517\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7169 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2654 - val_loss: 0.6915 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2550\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7137 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2671 - val_loss: 0.6920 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2521\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7107 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2578 - val_loss: 0.6909 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2558\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7155 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2728 - val_loss: 0.6900 - val_binary_accuracy: 0.2514 - val_categorical_accuracy: 0.2579\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7141 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2663 - val_loss: 0.6927 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2496\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7129 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2562 - val_loss: 0.6912 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2529\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7102 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2640 - val_loss: 0.6895 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2629\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.7125 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2736 - val_loss: 0.6908 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2529\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7114 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2585 - val_loss: 0.6917 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2492\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7104 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2594 - val_loss: 0.6891 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2608\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7104 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2709 - val_loss: 0.6910 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2529\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7104 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2618 - val_loss: 0.6903 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2512\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7101 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2641 - val_loss: 0.6888 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2537\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.7082 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2653 - val_loss: 0.6883 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2554\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.7091 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2610 - val_loss: 0.6898 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2529\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7123 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2648 - val_loss: 0.6889 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2621\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7109 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2694 - val_loss: 0.6898 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2537\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.7151 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2596 - val_loss: 0.6899 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2529\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7119 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2645 - val_loss: 0.6880 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2575\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7102 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2651 - val_loss: 0.6900 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2508\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7134 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2590 - val_loss: 0.6892 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2583\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7137 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2697 - val_loss: 0.6878 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2587\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7120 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2681 - val_loss: 0.6887 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2521\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7136 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2606 - val_loss: 0.6893 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2521\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 0.7099 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2634 - val_loss: 0.6878 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2587\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7090 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2669 - val_loss: 0.6895 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2504\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7124 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2584 - val_loss: 0.6888 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2533\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7110 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2650 - val_loss: 0.6874 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2558\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7123 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2652 - val_loss: 0.6886 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2488\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7098 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2580 - val_loss: 0.6873 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2571\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7095 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2741 - val_loss: 0.6880 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2542\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7075 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2609 - val_loss: 0.6906 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2458\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7102 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2581 - val_loss: 0.6866 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2663\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7097 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2771 - val_loss: 0.6869 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2542\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7120 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2614 - val_loss: 0.6889 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2458\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7084 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2653 - val_loss: 0.6852 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2658\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7106 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2727 - val_loss: 0.6874 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2500\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7073 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2576 - val_loss: 0.6890 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2504\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7076 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2626 - val_loss: 0.6873 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2612\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.7070 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2675 - val_loss: 0.6866 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2554\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7064 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2637 - val_loss: 0.6867 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2529\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7102 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2657 - val_loss: 0.6878 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2504\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.7066 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2624 - val_loss: 0.6880 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2533\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.7066 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2633 - val_loss: 0.6859 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2562\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7120 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2697 - val_loss: 0.6864 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2533\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7076 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2621 - val_loss: 0.6860 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2521\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7102 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2627 - val_loss: 0.6859 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2567\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 0s 157ms/step - loss: 0.7055 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2686 - val_loss: 0.6855 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2558\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7054 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2623 - val_loss: 0.6878 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2492\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7069 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2596 - val_loss: 0.6856 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2583\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7090 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2680 - val_loss: 0.6859 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2533\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7067 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2686 - val_loss: 0.6869 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2492\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.7055 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2593 - val_loss: 0.6849 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2567\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 0.7078 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2684 - val_loss: 0.6847 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2579\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7059 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2636 - val_loss: 0.6860 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2512\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7078 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2587 - val_loss: 0.6849 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2550\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7066 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2660 - val_loss: 0.6847 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2604\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 0.7056 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2673 - val_loss: 0.6850 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2550\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.7022 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2650 - val_loss: 0.6862 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2504\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7084 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2575 - val_loss: 0.6845 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2575\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7027 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2696 - val_loss: 0.6843 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2587\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7047 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2639 - val_loss: 0.6862 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2492\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.7028 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2537 - val_loss: 0.6854 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2537\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.7086 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2680 - val_loss: 0.6842 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2633\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7070 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2701 - val_loss: 0.6863 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2512\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7085 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2577 - val_loss: 0.6856 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2529\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.7028 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2640 - val_loss: 0.6851 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2612\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.7021 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2690 - val_loss: 0.6861 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2496\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.7093 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2551 - val_loss: 0.6844 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2550\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7082 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2703 - val_loss: 0.6840 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2629\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.7064 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2658 - val_loss: 0.6862 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2467\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.7051 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2551 - val_loss: 0.6840 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2558\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.7019 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2718 - val_loss: 0.6836 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2571\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7011 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2641 - val_loss: 0.6851 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2496\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 0.7044 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2601 - val_loss: 0.6834 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2621\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.7058 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2698 - val_loss: 0.6850 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2521\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.7068 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2621 - val_loss: 0.6841 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2508\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.7012 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2643 - val_loss: 0.6820 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2579\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.7043 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2698 - val_loss: 0.6840 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2525\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.7043 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2591 - val_loss: 0.6834 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2533\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.7033 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2671 - val_loss: 0.6817 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2642\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.7012 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2742 - val_loss: 0.6832 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2554\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7043 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2606 - val_loss: 0.6846 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2479\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.7041 - binary_accuracy: 0.2506 - categorical_accuracy: 0.2600 - val_loss: 0.6817 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2587\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7019 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2705 - val_loss: 0.6824 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2579\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7063 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2652 - val_loss: 0.6840 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2492\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7037 - binary_accuracy: 0.2506 - categorical_accuracy: 0.2587 - val_loss: 0.6813 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2567\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.7065 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2689 - val_loss: 0.6815 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2579\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7002 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2640 - val_loss: 0.6834 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2500\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7044 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2596 - val_loss: 0.6818 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2575\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.7036 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2688 - val_loss: 0.6809 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2587\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7030 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2626 - val_loss: 0.6819 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2525\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.7018 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2586 - val_loss: 0.6808 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2550\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.7024 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2672 - val_loss: 0.6803 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2575\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.6997 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2689 - val_loss: 0.6831 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2529\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.7045 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2633 - val_loss: 0.6828 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2533\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7007 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2660 - val_loss: 0.6818 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2558\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7034 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2652 - val_loss: 0.6830 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2508\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7006 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2565 - val_loss: 0.6810 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2554\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7022 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2709 - val_loss: 0.6802 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2575\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7002 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2677 - val_loss: 0.6827 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2508\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7021 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2633 - val_loss: 0.6823 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2533\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.7037 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2644 - val_loss: 0.6795 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2650\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7014 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2758 - val_loss: 0.6799 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2567\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.7017 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2617 - val_loss: 0.6822 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2475\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6992 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2562 - val_loss: 0.6795 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2604\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6995 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2713 - val_loss: 0.6790 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2621\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.7034 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2689 - val_loss: 0.6818 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2500\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7014 - binary_accuracy: 0.2507 - categorical_accuracy: 0.2568 - val_loss: 0.6804 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2537\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.7008 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2621 - val_loss: 0.6782 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2608\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7006 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2689 - val_loss: 0.6794 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2542\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6993 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2586 - val_loss: 0.6808 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2512\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.7019 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2629 - val_loss: 0.6781 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2621\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7027 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2699 - val_loss: 0.6789 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2537\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.7013 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2627 - val_loss: 0.6803 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2537\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7013 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2658 - val_loss: 0.6796 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2546\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.7007 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2621 - val_loss: 0.6808 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2508\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.7018 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2622 - val_loss: 0.6804 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2558\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.7005 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2680 - val_loss: 0.6791 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2567\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.7014 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2630 - val_loss: 0.6798 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2529\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7022 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2609 - val_loss: 0.6796 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2533\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6993 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2659 - val_loss: 0.6788 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2600\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7000 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2661 - val_loss: 0.6807 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2492\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.7010 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2562 - val_loss: 0.6786 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2554\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7030 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2684 - val_loss: 0.6771 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2600\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6988 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2668 - val_loss: 0.6803 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2496\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6985 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2567 - val_loss: 0.6787 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2583\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.6996 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2685 - val_loss: 0.6772 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2587\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.6982 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2639 - val_loss: 0.6792 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2483\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.7004 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2590 - val_loss: 0.6776 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2617\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.7008 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2703 - val_loss: 0.6781 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2575\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.7005 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2621 - val_loss: 0.6785 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2537\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6997 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2642 - val_loss: 0.6774 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2608\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6979 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2673 - val_loss: 0.6782 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2533\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6992 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2603 - val_loss: 0.6779 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2546\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6992 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2617 - val_loss: 0.6782 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2562\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6975 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2641 - val_loss: 0.6769 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2608\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.6987 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2672 - val_loss: 0.6792 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2504\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6971 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2568 - val_loss: 0.6780 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2554\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6953 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2688 - val_loss: 0.6777 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2571\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 0.6967 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2640 - val_loss: 0.6787 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2512\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6989 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2615 - val_loss: 0.6781 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2554\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.6998 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2636 - val_loss: 0.6775 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2567\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.6970 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2644 - val_loss: 0.6778 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2525\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.6983 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2616 - val_loss: 0.6784 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2512\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6979 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2597 - val_loss: 0.6766 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2600\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6979 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2723 - val_loss: 0.6773 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2533\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.6987 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2576 - val_loss: 0.6779 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2512\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6987 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2630 - val_loss: 0.6752 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2629\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 0.6974 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2692 - val_loss: 0.6771 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2533\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.7018 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2570 - val_loss: 0.6772 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2558\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6974 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2652 - val_loss: 0.6750 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2617\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6982 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2716 - val_loss: 0.6775 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2496\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6960 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2535 - val_loss: 0.6766 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2546\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7006 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2669 - val_loss: 0.6750 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2675\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6984 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2722 - val_loss: 0.6776 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2512\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6972 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2574 - val_loss: 0.6775 - val_binary_accuracy: 0.2542 - val_categorical_accuracy: 0.2529\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6998 - binary_accuracy: 0.2507 - categorical_accuracy: 0.2623 - val_loss: 0.6747 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2637\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6953 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2690 - val_loss: 0.6765 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2508\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6939 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2570 - val_loss: 0.6770 - val_binary_accuracy: 0.2539 - val_categorical_accuracy: 0.2529\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6968 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2637 - val_loss: 0.6752 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2608\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6969 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2725 - val_loss: 0.6765 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2512\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.7007 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2572 - val_loss: 0.6755 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2537\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6982 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2639 - val_loss: 0.6743 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2608\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7001 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2665 - val_loss: 0.6757 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2508\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6968 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2597 - val_loss: 0.6756 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2525\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6943 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2628 - val_loss: 0.6747 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2583\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.6989 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2680 - val_loss: 0.6769 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2500\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6938 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2569 - val_loss: 0.6761 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2542\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6947 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2683 - val_loss: 0.6749 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2604\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6960 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2674 - val_loss: 0.6772 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2467\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.6962 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2598 - val_loss: 0.6747 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2550\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.6968 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2673 - val_loss: 0.6740 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2612\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.7000 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2647 - val_loss: 0.6759 - val_binary_accuracy: 0.2539 - val_categorical_accuracy: 0.2479\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 0.6983 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2567 - val_loss: 0.6740 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2575\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.6951 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2677 - val_loss: 0.6742 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2600\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6967 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2643 - val_loss: 0.6763 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2517\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6987 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2591 - val_loss: 0.6748 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2558\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6942 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2664 - val_loss: 0.6735 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2629\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6931 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2653 - val_loss: 0.6757 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2500\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6952 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2568 - val_loss: 0.6736 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2579\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 0.6950 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2718 - val_loss: 0.6745 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2562\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6933 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2616 - val_loss: 0.6749 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2525\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.6937 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2632 - val_loss: 0.6731 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2612\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6968 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2736 - val_loss: 0.6740 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2554\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6922 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2583 - val_loss: 0.6739 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2537\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6955 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2672 - val_loss: 0.6727 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2579\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6955 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2681 - val_loss: 0.6744 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2483\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6954 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2530 - val_loss: 0.6734 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2542\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6940 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2661 - val_loss: 0.6719 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2650\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.6943 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2696 - val_loss: 0.6749 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2471\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 0.6954 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2560 - val_loss: 0.6728 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2571\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.6983 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2644 - val_loss: 0.6723 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2567\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6947 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2660 - val_loss: 0.6742 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2521\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6977 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2627 - val_loss: 0.6752 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2533\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6918 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2645 - val_loss: 0.6745 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2554\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 0.6923 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2627 - val_loss: 0.6758 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2479\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6947 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2608 - val_loss: 0.6728 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2575\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.6906 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2665 - val_loss: 0.6716 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2579\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6954 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2705 - val_loss: 0.6747 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2512\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6972 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2559 - val_loss: 0.6748 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2504\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.6915 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2632 - val_loss: 0.6722 - val_binary_accuracy: 0.2506 - val_categorical_accuracy: 0.2683\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 0.6918 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2767 - val_loss: 0.6741 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2525\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6961 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2587 - val_loss: 0.6743 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2508\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.6891 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2627 - val_loss: 0.6724 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2621\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6927 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2713 - val_loss: 0.6728 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2554\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.6910 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2587 - val_loss: 0.6737 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2517\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.6923 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2644 - val_loss: 0.6715 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2650\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6881 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2673 - val_loss: 0.6729 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2554\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.6932 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2589 - val_loss: 0.6732 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2550\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 0.6919 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2606 - val_loss: 0.6720 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2575\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6946 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2647 - val_loss: 0.6718 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2567\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.6917 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2647 - val_loss: 0.6713 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2575\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6908 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2636 - val_loss: 0.6734 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2575\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 0.6958 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2672 - val_loss: 0.6721 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2517\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6898 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2617 - val_loss: 0.6708 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2558\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 0.6932 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2693 - val_loss: 0.6717 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2562\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6943 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2644 - val_loss: 0.6721 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2492\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6901 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2602 - val_loss: 0.6699 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2621\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6908 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2716 - val_loss: 0.6711 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2562\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6931 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2621 - val_loss: 0.6727 - val_binary_accuracy: 0.2542 - val_categorical_accuracy: 0.2488\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6876 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2589 - val_loss: 0.6707 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2554\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.6906 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2679 - val_loss: 0.6702 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2608\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6947 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2655 - val_loss: 0.6712 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2504\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6884 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2567 - val_loss: 0.6695 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2579\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.6899 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2711 - val_loss: 0.6694 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2625\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6911 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2620 - val_loss: 0.6710 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2517\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.6867 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2569 - val_loss: 0.6702 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2571\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.6882 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2684 - val_loss: 0.6698 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2612\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6883 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2673 - val_loss: 0.6712 - val_binary_accuracy: 0.2533 - val_categorical_accuracy: 0.2517\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.6870 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2596 - val_loss: 0.6703 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2575\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.6883 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2646 - val_loss: 0.6690 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2608\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6915 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2690 - val_loss: 0.6709 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2537\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.6918 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2596 - val_loss: 0.6707 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2550\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.6907 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2626 - val_loss: 0.6684 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2658\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6940 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2791 - val_loss: 0.6708 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2517\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6894 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2565 - val_loss: 0.6705 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2508\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.6891 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2633 - val_loss: 0.6681 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2654\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.6895 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2725 - val_loss: 0.6703 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2521\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6872 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2590 - val_loss: 0.6707 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2521\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6908 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2596 - val_loss: 0.6687 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2658\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 0.6907 - binary_accuracy: 0.2494 - categorical_accuracy: 0.2704 - val_loss: 0.6699 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2542\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 0s 127ms/step - loss: 0.6855 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2623 - val_loss: 0.6700 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2521\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 0.6858 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2634 - val_loss: 0.6688 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2575\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 0.6951 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2670 - val_loss: 0.6690 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2579\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 0.6921 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2648 - val_loss: 0.6692 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2525\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6894 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2635 - val_loss: 0.6702 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2554\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 0.6856 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2627 - val_loss: 0.6690 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2546\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6881 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2617 - val_loss: 0.6678 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2579\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6884 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2686 - val_loss: 0.6691 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2562\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 0.6873 - binary_accuracy: 0.2503 - categorical_accuracy: 0.2618 - val_loss: 0.6706 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2488\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.6910 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2591 - val_loss: 0.6688 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2592\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 0.6892 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2670 - val_loss: 0.6687 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2604\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 0.6907 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2671 - val_loss: 0.6703 - val_binary_accuracy: 0.2540 - val_categorical_accuracy: 0.2525\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6924 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2615 - val_loss: 0.6676 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2596\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 0.6888 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2699 - val_loss: 0.6676 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2583\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6879 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2616 - val_loss: 0.6699 - val_binary_accuracy: 0.2544 - val_categorical_accuracy: 0.2517\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6920 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2623 - val_loss: 0.6678 - val_binary_accuracy: 0.2518 - val_categorical_accuracy: 0.2571\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 0.6905 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2666 - val_loss: 0.6674 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2604\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6876 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2698 - val_loss: 0.6694 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2550\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 0.6892 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2627 - val_loss: 0.6692 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2546\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 0.6863 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2630 - val_loss: 0.6675 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2600\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.6900 - binary_accuracy: 0.2497 - categorical_accuracy: 0.2668 - val_loss: 0.6691 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2488\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6922 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2591 - val_loss: 0.6678 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2567\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 0.6872 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2640 - val_loss: 0.6667 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2633\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6900 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2715 - val_loss: 0.6678 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2579\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6870 - binary_accuracy: 0.2500 - categorical_accuracy: 0.2635 - val_loss: 0.6689 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2529\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.6886 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2633 - val_loss: 0.6669 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2600\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.6869 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2688 - val_loss: 0.6677 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2542\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 0.6870 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2575 - val_loss: 0.6681 - val_binary_accuracy: 0.2540 - val_categorical_accuracy: 0.2521\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6880 - binary_accuracy: 0.2504 - categorical_accuracy: 0.2641 - val_loss: 0.6662 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2658\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6885 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2666 - val_loss: 0.6688 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2500\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.6875 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2577 - val_loss: 0.6669 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2575\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 0.6900 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2669 - val_loss: 0.6669 - val_binary_accuracy: 0.2539 - val_categorical_accuracy: 0.2587\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 0.6878 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2648 - val_loss: 0.6682 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2521\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6846 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2568 - val_loss: 0.6661 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2587\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 0.6884 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2679 - val_loss: 0.6665 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2583\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 0.6869 - binary_accuracy: 0.2499 - categorical_accuracy: 0.2660 - val_loss: 0.6698 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2463\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.6866 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2580 - val_loss: 0.6670 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2608\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 0.6874 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2694 - val_loss: 0.6681 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2583\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.6892 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2654 - val_loss: 0.6687 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2504\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.6883 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2593 - val_loss: 0.6660 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2596\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 0.6820 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2694 - val_loss: 0.6663 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2562\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.6866 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2624 - val_loss: 0.6674 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c9e759cc40>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8774 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2577 - val_loss: 0.8943 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2579\n",
      "Epoch 146/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8818 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2636 - val_loss: 0.8926 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2646\n",
      "Epoch 147/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8746 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2653 - val_loss: 0.8919 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2525\n",
      "Epoch 148/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8751 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2564 - val_loss: 0.8911 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2738\n",
      "Epoch 149/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8773 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2783 - val_loss: 0.8909 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2575\n",
      "Epoch 150/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8730 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2648 - val_loss: 0.8893 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2579\n",
      "Epoch 151/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8737 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2646 - val_loss: 0.8883 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2642\n",
      "Epoch 152/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8699 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2681 - val_loss: 0.8875 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2637\n",
      "Epoch 153/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8766 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2677 - val_loss: 0.8857 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2679\n",
      "Epoch 154/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8692 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2719 - val_loss: 0.8848 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2587\n",
      "Epoch 155/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8702 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2591 - val_loss: 0.8837 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2621\n",
      "Epoch 156/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8649 - binary_accuracy: 0.2471 - categorical_accuracy: 0.2719 - val_loss: 0.8825 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2692\n",
      "Epoch 157/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8691 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2629 - val_loss: 0.8821 - val_binary_accuracy: 0.2542 - val_categorical_accuracy: 0.2550\n",
      "Epoch 158/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8675 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2599 - val_loss: 0.8801 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2750\n",
      "Epoch 159/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8690 - binary_accuracy: 0.2467 - categorical_accuracy: 0.2744 - val_loss: 0.8835 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2575\n",
      "Epoch 160/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8682 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2620 - val_loss: 0.8802 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2646\n",
      "Epoch 161/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8588 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2659 - val_loss: 0.8787 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2625\n",
      "Epoch 162/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8615 - binary_accuracy: 0.2467 - categorical_accuracy: 0.2631 - val_loss: 0.8790 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2612\n",
      "Epoch 163/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8640 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2690 - val_loss: 0.8791 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2625\n",
      "Epoch 164/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8610 - binary_accuracy: 0.2466 - categorical_accuracy: 0.2643 - val_loss: 0.8763 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2625\n",
      "Epoch 165/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8633 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2670 - val_loss: 0.8734 - val_binary_accuracy: 0.2508 - val_categorical_accuracy: 0.2758\n",
      "Epoch 166/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8619 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2714 - val_loss: 0.8760 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2571\n",
      "Epoch 167/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8591 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2544 - val_loss: 0.8732 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2700\n",
      "Epoch 168/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8581 - binary_accuracy: 0.2457 - categorical_accuracy: 0.2807 - val_loss: 0.8717 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2612\n",
      "Epoch 169/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8617 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2556 - val_loss: 0.8730 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2579\n",
      "Epoch 170/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8616 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2747 - val_loss: 0.8721 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2775\n",
      "Epoch 171/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8589 - binary_accuracy: 0.2464 - categorical_accuracy: 0.2709 - val_loss: 0.8730 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2483\n",
      "Epoch 172/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8589 - binary_accuracy: 0.2466 - categorical_accuracy: 0.2602 - val_loss: 0.8692 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2758\n",
      "Epoch 173/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8571 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2784 - val_loss: 0.8709 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2562\n",
      "Epoch 174/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8514 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2554 - val_loss: 0.8689 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2692\n",
      "Epoch 175/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8545 - binary_accuracy: 0.2470 - categorical_accuracy: 0.2781 - val_loss: 0.8659 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2688\n",
      "Epoch 176/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8568 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2596 - val_loss: 0.8669 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2537\n",
      "Epoch 177/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8533 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2645 - val_loss: 0.8659 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2804\n",
      "Epoch 178/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8523 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2761 - val_loss: 0.8681 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2512\n",
      "Epoch 179/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8506 - binary_accuracy: 0.2478 - categorical_accuracy: 0.2567 - val_loss: 0.8658 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2675\n",
      "Epoch 180/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8516 - binary_accuracy: 0.2463 - categorical_accuracy: 0.2732 - val_loss: 0.8641 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8505 - binary_accuracy: 0.2469 - categorical_accuracy: 0.2617 - val_loss: 0.8638 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2600\n",
      "Epoch 182/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8503 - binary_accuracy: 0.2462 - categorical_accuracy: 0.2751 - val_loss: 0.8631 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2617\n",
      "Epoch 183/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8481 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2618 - val_loss: 0.8621 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2583\n",
      "Epoch 184/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8515 - binary_accuracy: 0.2467 - categorical_accuracy: 0.2667 - val_loss: 0.8593 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2729\n",
      "Epoch 185/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8482 - binary_accuracy: 0.2451 - categorical_accuracy: 0.2726 - val_loss: 0.8611 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2550\n",
      "Epoch 186/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8464 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2560 - val_loss: 0.8603 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2704\n",
      "Epoch 187/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8486 - binary_accuracy: 0.2470 - categorical_accuracy: 0.2741 - val_loss: 0.8594 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2629\n",
      "Epoch 188/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8481 - binary_accuracy: 0.2471 - categorical_accuracy: 0.2600 - val_loss: 0.8589 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2642\n",
      "Epoch 189/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8465 - binary_accuracy: 0.2463 - categorical_accuracy: 0.2706 - val_loss: 0.8598 - val_binary_accuracy: 0.2540 - val_categorical_accuracy: 0.2663\n",
      "Epoch 190/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8440 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2643 - val_loss: 0.8583 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2554\n",
      "Epoch 191/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8457 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2605 - val_loss: 0.8563 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2792\n",
      "Epoch 192/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8427 - binary_accuracy: 0.2462 - categorical_accuracy: 0.2879 - val_loss: 0.8583 - val_binary_accuracy: 0.2539 - val_categorical_accuracy: 0.2579\n",
      "Epoch 193/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8421 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2495 - val_loss: 0.8551 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2612\n",
      "Epoch 194/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8421 - binary_accuracy: 0.2450 - categorical_accuracy: 0.2808 - val_loss: 0.8533 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2850\n",
      "Epoch 195/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8424 - binary_accuracy: 0.2466 - categorical_accuracy: 0.2786 - val_loss: 0.8606 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2333\n",
      "Epoch 196/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8441 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2403 - val_loss: 0.8520 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2829\n",
      "Epoch 197/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8385 - binary_accuracy: 0.2448 - categorical_accuracy: 0.2922 - val_loss: 0.8510 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2725\n",
      "Epoch 198/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8387 - binary_accuracy: 0.2470 - categorical_accuracy: 0.2696 - val_loss: 0.8555 - val_binary_accuracy: 0.2544 - val_categorical_accuracy: 0.2450\n",
      "Epoch 199/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8390 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2528 - val_loss: 0.8505 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2796\n",
      "Epoch 200/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8386 - binary_accuracy: 0.2452 - categorical_accuracy: 0.2826 - val_loss: 0.8498 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d96d30508>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_6.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e0c7094e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875/875 [==============================] - 2s 3ms/step - loss: 0.6720 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6720336079597473, 0.24975892901420593, 0.25099998712539673]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_6.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99010c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
