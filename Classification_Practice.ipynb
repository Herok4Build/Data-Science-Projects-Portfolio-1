{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f52f1310",
   "metadata": {},
   "source": [
    "<h1>Practice With Classification</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d20136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe74b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference:  https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification\n",
    "\n",
    "\n",
    "def generateData1():\n",
    "    from sklearn.datasets import make_classification\n",
    "    generated_data, generated_labels = make_classification(n_samples=40000, n_features=67,n_informative=6,\n",
    "                                     n_redundant=21,n_classes=4,n_clusters_per_class=3,\n",
    "                                     class_sep=0.85, random_state=4)\n",
    "    return generated_data, generated_labels\n",
    "#Generated a dataset for classification\n",
    "generated_data, generated_labels=generateData1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e86af2fb-c912-4a2d-81c9-f367f23ec860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d25078",
   "metadata": {},
   "source": [
    "<h2>Printing the Data</h2>\n",
    "<p>First going to print the data to be able to observe some of the features and entries. Then move forward to preprocessing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee85fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.55886552 -1.0367371  -2.0716188  ... -1.66748974  0.88442319\n",
      "   2.47414118]\n",
      " [-0.36649363  3.99879789 -0.94638273 ... -2.37814551 -0.76884534\n",
      "  -1.0220301 ]\n",
      " [-1.0572081   0.97359163  0.34744335 ...  1.12169577 -2.40200316\n",
      "   0.56310249]\n",
      " ...\n",
      " [ 0.78227173 -0.47473335 -1.01507181 ...  1.02149934  1.93028971\n",
      "  -0.77386558]\n",
      " [ 0.65287134 -0.32653986 -0.5734769  ...  1.01438409 -1.29947182\n",
      "  -1.83709253]\n",
      " [-0.33382408  0.8938808   0.02252798 ... -1.13487992  0.09518901\n",
      "   0.58224631]]\n"
     ]
    }
   ],
   "source": [
    "print(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3199b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0         1         2         3         4         5         6   \\\n",
      "0      0.558866 -1.036737 -2.071619  2.615634  0.251788 -0.208035  2.895468   \n",
      "1     -0.366494  3.998798 -0.946383 -0.635905  2.286920 -0.637968 -1.108372   \n",
      "2     -1.057208  0.973592  0.347443 -1.655197  2.006350  0.794712 -0.900860   \n",
      "3      1.386458 -0.462859  1.708425 -0.692245 -1.184841 -0.443195 -0.265234   \n",
      "4     -0.675302 -1.535932  1.267888  1.639375 -0.236435 -1.173418  1.149061   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "39995  0.853123 -3.544765  1.625326  0.128059  1.139331  0.728333  0.815937   \n",
      "39996 -0.473624 -2.987561 -0.541470 -0.689567  0.253457 -0.221994  1.305095   \n",
      "39997  0.782272 -0.474733 -1.015072  0.227328  0.263934  0.229079  2.961405   \n",
      "39998  0.652871 -0.326540 -0.573477 -0.997861  2.130370 -0.381276 -2.629324   \n",
      "39999 -0.333824  0.893881  0.022528  0.663176  1.381133  1.004063  0.839596   \n",
      "\n",
      "             7         8         9   ...        57        58        59  \\\n",
      "0      1.198842  0.145180  1.080346  ...  1.892684  0.836829 -1.154116   \n",
      "1      0.385278 -0.520651 -0.200035  ... -0.327254 -1.786240 -1.581214   \n",
      "2      1.090486 -0.540597 -0.721043  ...  0.010024  0.135420  0.655283   \n",
      "3     -0.690467 -0.103353 -0.257949  ...  0.461589  1.174917 -1.349465   \n",
      "4     -0.513452  0.633918 -0.816238  ...  1.111512  0.767437 -1.159393   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "39995 -0.370747 -1.022110 -0.444927  ...  0.867935  1.961165 -1.342611   \n",
      "39996 -0.341721  1.161531  0.124060  ...  1.504860  2.191502 -4.111858   \n",
      "39997 -0.066889 -1.787637 -1.406811  ...  1.396869 -0.188328 -0.744552   \n",
      "39998  0.524710  0.664695 -0.629392  ... -1.020037 -0.045849  0.437240   \n",
      "39999  0.079279 -0.338432  1.294211  ...  0.561051  0.041653 -0.653239   \n",
      "\n",
      "             60        61        62        63        64        65        66  \n",
      "0      1.666794 -0.899628 -0.234645 -1.009528 -1.667490  0.884423  2.474141  \n",
      "1     -2.022363  0.396948  0.838982 -0.389692 -2.378146 -0.768845 -1.022030  \n",
      "2      1.293106 -0.619047  0.376654 -0.870834  1.121696 -2.402003  0.563102  \n",
      "3     -3.061563 -0.442438  1.056667 -1.341212  1.128780  0.788385  0.292775  \n",
      "4      3.272597 -2.224216 -1.437791 -0.189640 -0.155901  0.729326 -2.186898  \n",
      "...         ...       ...       ...       ...       ...       ...       ...  \n",
      "39995 -0.018051 -1.682326 -1.220616 -0.670869 -0.451688  2.706436 -0.190048  \n",
      "39996 -3.695702 -1.997050 -0.038346  0.779446 -1.424520  4.789480 -0.322352  \n",
      "39997  0.916445  0.568651 -1.408191  0.564410  1.021499  1.930290 -0.773866  \n",
      "39998  3.007094 -2.000006 -1.600839  0.938161  1.014384 -1.299472 -1.837093  \n",
      "39999 -2.022648  0.683579  1.271801 -0.004906 -1.134880  0.095189  0.582246  \n",
      "\n",
      "[40000 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "generated_data_dataframe = pd.DataFrame(data=generated_data)\n",
    "scalerObject = StandardScaler().fit(generated_data_dataframe)\n",
    "standardized_generated_dataframe = scalerObject.transform(generated_data_dataframe)\n",
    "print(generated_data_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3b6a98b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.56203181 -0.31366006 -2.0805219  ... -1.65797078  0.41370309\n",
      "   2.47499216]\n",
      " [-0.3660114   1.65838212 -0.95197803 ... -2.36722943 -0.36008486\n",
      "  -1.0264752 ]\n",
      " [-1.05872933  0.47363524  0.34565145 ...  1.12573131 -1.12446028\n",
      "   0.56105859]\n",
      " ...\n",
      " [ 0.78608603 -0.09356526 -1.02086904 ...  1.02573186  0.90320548\n",
      "  -0.77793476]\n",
      " [ 0.65631031 -0.03552896 -0.57797599 ...  1.0186306  -0.60843675\n",
      "  -1.84277231]\n",
      " [-0.3332471   0.44241848  0.01978094 ... -1.12640805  0.04431367\n",
      "   0.5802314 ]]\n"
     ]
    }
   ],
   "source": [
    "print(standardized_generated_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c23e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=2)\n",
      "For  2  features: \n",
      "\n",
      "[[ 1.39242057 -0.06182259]\n",
      " [-0.59950577  0.61543763]\n",
      " [-0.50615914  0.32379436]\n",
      " ...\n",
      " [ 0.7848968  -0.80211247]\n",
      " [-0.51528767 -0.92363826]\n",
      " [-0.00433482  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=3)\n",
      "For  3  features: \n",
      "\n",
      "[[ 1.4820108   1.39242057 -0.06182259]\n",
      " [-0.33590322 -0.59950577  0.61543763]\n",
      " [-0.73089161 -0.50615914  0.32379436]\n",
      " ...\n",
      " [ 0.14106163  0.7848968  -0.80211247]\n",
      " [ 0.38289066 -0.51528767 -0.92363826]\n",
      " [-0.58159775 -0.00433482  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=4)\n",
      "For  4  features: \n",
      "\n",
      "[[ 1.4820108   1.39242057 -0.51858044 -0.06182259]\n",
      " [-0.33590322 -0.59950577  0.35894225  0.61543763]\n",
      " [-0.73089161 -0.50615914 -0.36934665  0.32379436]\n",
      " ...\n",
      " [ 0.14106163  0.7848968  -1.27003793 -0.80211247]\n",
      " [ 0.38289066 -0.51528767  0.19156057 -0.92363826]\n",
      " [-0.58159775 -0.00433482 -0.08401367  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=5)\n",
      "For  5  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   1.39242057 -0.51858044 -0.06182259]\n",
      " [-0.35328617 -0.33590322 -0.59950577  0.35894225  0.61543763]\n",
      " [-0.26103098 -0.73089161 -0.50615914 -0.36934665  0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163  0.7848968  -1.27003793 -0.80211247]\n",
      " [-1.02946779  0.38289066 -0.51528767  0.19156057 -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.00433482 -0.08401367  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=6)\n",
      "For  6  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855  1.39242057 -0.51858044 -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 -0.59950577  0.35894225  0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 -0.50615914 -0.36934665  0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978  0.7848968  -1.27003793 -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 -0.51528767  0.19156057 -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 -0.00433482 -0.08401367  0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=7)\n",
      "For  7  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855 ... -0.51858044  0.16507973\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ...  0.35894225 -0.55629257\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -0.36934665 -0.20552952\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ... -1.27003793  0.20212378\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ...  0.19156057  0.52872378\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ... -0.08401367 -0.6476322\n",
      "   0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=8)\n",
      "For  8  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855 ...  0.16507973  0.54125354\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ... -0.55629257 -0.83817178\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -0.20552952  0.40152665\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ...  0.20212378  0.26068818\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ...  0.52872378  1.04241002\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ... -0.6476322  -0.8382785\n",
      "   0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest(k=9)\n",
      "For  9  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855 ...  0.16507973  0.54125354\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ... -0.55629257 -0.83817178\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -0.20552952  0.40152665\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ...  0.20212378  0.26068818\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ...  0.52872378  1.04241002\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ... -0.6476322  -0.8382785\n",
      "   0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n",
      "SelectKBest()\n",
      "For  10  features: \n",
      "\n",
      "[[ 1.42673235  1.4820108   0.67773855 ...  1.55245915  0.54125354\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ... -0.68410238 -0.83817178\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -1.00096733  0.40152665\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ...  1.02405554  0.26068818\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ... -0.89137174  1.04241002\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ...  0.19909785 -0.8382785\n",
      "   0.88846665]]\n",
      "[4.23954432e-002 0.00000000e+000 5.17241377e-001 6.65940780e-001\n",
      " 8.69729652e-001 9.57887724e-001 0.00000000e+000 1.49275534e-001\n",
      " 3.69397123e-001 3.47746340e-001 4.66626281e-001 7.78691123e-001\n",
      " 7.68519842e-298 1.44738095e-001 7.17716362e-001 8.07975406e-003\n",
      " 3.57050892e-001 4.15474137e-001 3.71510243e-001 6.71971623e-001\n",
      " 9.21941157e-001 8.84510247e-001 1.16247328e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 2.92792044e-001 3.35802420e-001\n",
      " 2.57506869e-001 0.00000000e+000 6.55283704e-001 7.29505298e-251\n",
      " 3.73092834e-001 1.74506608e-148 6.79508212e-001 7.23430662e-001\n",
      " 7.25550925e-001 0.00000000e+000 3.84202661e-001 3.12104286e-001\n",
      " 0.00000000e+000 3.23778881e-001 0.00000000e+000 3.21458487e-280\n",
      " 2.39220867e-160 0.00000000e+000 7.46425140e-001 0.00000000e+000\n",
      " 0.00000000e+000 0.00000000e+000 9.91206341e-001 0.00000000e+000\n",
      " 2.39129700e-002 9.05870317e-001 0.00000000e+000 7.43280499e-001\n",
      " 2.48112999e-001 0.00000000e+000 1.17764803e-199 1.18823941e-200\n",
      " 0.00000000e+000 1.57478292e-210 0.00000000e+000 8.51564246e-001\n",
      " 4.59262601e-001 0.00000000e+000 9.89375674e-001]\n",
      "[2.72759352e+00 6.79259738e+02 7.58493641e-01 5.23732294e-01\n",
      " 2.38248567e-01 1.03768764e-01 1.83442684e+03 1.77620140e+00\n",
      " 1.04928750e+00 1.09978330e+00 8.49448115e-01 3.64434598e-01\n",
      " 4.66310065e+02 1.80012836e+00 4.49407882e-01 3.93572195e+00\n",
      " 1.07775828e+00 9.49735730e-01 1.04449694e+00 5.14934147e-01\n",
      " 1.62021960e-01 2.17219671e-01 1.96896433e+00 1.90431422e+03\n",
      " 1.77442716e+03 2.25599222e+03 1.24153945e+00 1.12882096e+00\n",
      " 1.34568504e+00 9.27023482e+02 5.39384201e-01 3.91818571e+02\n",
      " 1.04092441e+00 2.30817311e+02 5.03996434e-01 4.41351198e-01\n",
      " 4.38367927e-01 7.01196876e+02 1.01620379e+00 1.18922657e+00\n",
      " 8.31340187e+02 1.15898118e+00 1.08874519e+03 4.38321791e+02\n",
      " 2.49381375e+02 1.31488850e+03 4.09155810e-01 7.41852005e+02\n",
      " 1.84016971e+03 6.44182956e+02 3.50658496e-02 1.57755364e+03\n",
      " 3.14899465e+00 1.86155649e-01 1.11111129e+03 4.13539628e-01\n",
      " 1.37559076e+00 8.09500414e+02 3.11062709e+02 3.12629234e+02\n",
      " 1.37457742e+03 3.28172576e+02 2.36681891e+03 2.63741648e-01\n",
      " 8.63317838e-01 6.22617625e+02 3.98922491e-02]\n"
     ]
    }
   ],
   "source": [
    "#https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "def featureSelectionOfKBestMeasure(submitted_data, submittedLabels, focused_number_of_features):\n",
    "    for number in focused_number_of_features:\n",
    "        transform_by_features = SelectKBest(k=number)\n",
    "        transform_by_features.fit(submitted_data, submittedLabels)\n",
    "        print(transform_by_features)\n",
    "        transformed_data = transform_by_features.fit_transform(submitted_data, submittedLabels)\n",
    "        print(\"For \",number,\" features: \\n\")\n",
    "        print(transformed_data)\n",
    "        print(transform_by_features.pvalues_)\n",
    "        print(transform_by_features.scores_)\n",
    "        \n",
    "#    return transformed_data\n",
    "possible_feature_numbers = [2,3,4,5,6,7,8,9,10]\n",
    "featureSelectionOfKBestMeasure(standardized_generated_dataframe, generated_labels,possible_feature_numbers)\n",
    "\n",
    "\n",
    "#Performing transformation to reduce dimensionality of the data\n",
    "#transformed_generated_data = featureSelectionOfKBest(standardized_generated_dataframe, generated_labels, 9)\n",
    "#print(transformed_generated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14fd20c",
   "metadata": {},
   "source": [
    "Using the <code>SelectKBest</code> method with mutual info classifier metric to select the best eight features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f81a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelectKBest(k=8,\n",
      "            score_func=<function mutual_info_classif at 0x000001C9DB096F80>)\n",
      "[[ 1.42673235  1.4820108   0.67773855 ...  0.16507973  0.54125354\n",
      "  -0.06182259]\n",
      " [-0.35328617 -0.33590322  0.44310246 ... -0.55629257 -0.83817178\n",
      "   0.61543763]\n",
      " [-0.26103098 -0.73089161  0.05193602 ... -0.20552952  0.40152665\n",
      "   0.32379436]\n",
      " ...\n",
      " [ 1.45604656  0.14106163 -0.02538978 ...  0.20212378  0.26068818\n",
      "  -0.80211247]\n",
      " [-1.02946779  0.38289066  1.34609545 ...  0.52872378  1.04241002\n",
      "  -0.92363826]\n",
      " [ 0.51273724 -0.58159775 -0.88431274 ... -0.6476322  -0.8382785\n",
      "   0.88846665]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "def featureSelectionOfKBestResult(submitted_data, submittedLabels, focused_number):\n",
    "    transform_by_features = SelectKBest(score_func=mutual_info_classif,k=focused_number)\n",
    "    transform_by_features.fit(X=submitted_data, y=submittedLabels)\n",
    "    print(transform_by_features)\n",
    "    transformed_data = transform_by_features.fit_transform(submitted_data, submittedLabels) \n",
    "    print(transformed_data)\n",
    "    return transformed_data\n",
    "\n",
    "transformed_data = featureSelectionOfKBestResult(standardized_generated_dataframe, generated_labels, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf8d809",
   "metadata": {},
   "source": [
    "<h2>Exploring the Data</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bca1fc5",
   "metadata": {},
   "source": [
    "Using the covariance matrix, we can observe if the whether the relevant features have a positive or negative relationship with one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89afb127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating the empirical covariance of the data:\n",
      "[[ 9.94224004e-01 -2.75944244e-02  3.44190140e-03 ...  4.49019309e-03\n",
      "   1.86278207e-02 -7.61682585e-03]\n",
      " [-2.75944244e-02  6.52016875e+00  3.71517903e-03 ... -1.39513595e-02\n",
      "  -9.39814304e-01  1.30035465e-02]\n",
      " [ 3.44190140e-03  3.71517903e-03  9.94146514e-01 ... -1.22093149e-03\n",
      "   9.02005266e-03 -5.80496093e-05]\n",
      " ...\n",
      " [ 4.49019309e-03 -1.39513595e-02 -1.22093149e-03 ...  1.00394354e+00\n",
      "   4.72660595e-03 -3.57410271e-04]\n",
      " [ 1.86278207e-02 -9.39814304e-01  9.02005266e-03 ...  4.72660595e-03\n",
      "   4.56502205e+00  4.07984927e-03]\n",
      " [-7.61682585e-03  1.30035465e-02 -5.80496093e-05 ... -3.57410271e-04\n",
      "   4.07984927e-03  9.96977225e-01]]\n",
      "SelectKBest(k=8,\n",
      "            score_func=<function mutual_info_classif at 0x000001C9DB096F80>)\n",
      "[[ 2.89546808  3.3208769   1.60383671 ...  0.39309061  1.66679368\n",
      "  -0.23464541]\n",
      " [-1.10837167 -0.27035596  1.18375352 ... -1.8917661  -2.02236295\n",
      "   0.83898195]\n",
      " [-0.9008598  -1.0506433   0.48342452 ... -0.78076793  1.29310592\n",
      "   0.37665421]\n",
      " ...\n",
      " [ 2.96140526  0.67187333  0.34498346 ...  0.51042302  0.91644531\n",
      "  -1.4081906 ]\n",
      " [-2.62932375  1.1495991   2.80043658 ...  1.54488777  3.00709439\n",
      "  -1.60083946]\n",
      " [ 0.83959625 -0.75571791 -1.19279837 ... -2.18107299 -2.02264835\n",
      "   1.27180145]]\n",
      "Calculating the empirical covariance of the transformed data:\n",
      "[[ 5.05946198  1.54303515  0.084714    3.59558993 -3.78328985  2.31973647\n",
      "   1.72969976 -0.89713192]\n",
      " [ 1.54303515  3.90247793  2.90180276  2.054525    0.06269367  1.41994524\n",
      "   1.5159754  -1.12297576]\n",
      " [ 0.084714    2.90180276  3.2053911   0.92979589  0.20127479  1.54287002\n",
      "   1.89203324 -1.15669785]\n",
      " [ 3.59558993  2.054525    0.92979589  3.75815111 -2.97337006  4.39461334\n",
      "   2.14686856 -0.80051075]\n",
      " [-3.78328985  0.06269367  0.20127479 -2.97337006  4.86730929 -4.43864217\n",
      "  -3.70613886  1.49016885]\n",
      " [ 2.31973647  1.41994524  1.54287002  4.39461334 -4.43864217 10.03226563\n",
      "   4.56638245 -2.30576065]\n",
      " [ 1.72969976  1.5159754   1.89203324  2.14686856 -3.70613886  4.56638245\n",
      "   7.15249894 -2.28110091]\n",
      " [-0.89713192 -1.12297576 -1.15669785 -0.80051075  1.49016885 -2.30576065\n",
      "  -2.28110091  2.51302038]]\n",
      "(40000, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.covariance import empirical_covariance\n",
    "print(\"Calculating the empirical covariance of the data:\")\n",
    "print(empirical_covariance(pd.DataFrame(data=generated_data)))\n",
    "transformed_origin_generated_data = featureSelectionOfKBestResult(pd.DataFrame(data=generated_data), generated_labels, 8)\n",
    "print(\"Calculating the empirical covariance of the transformed data:\")\n",
    "print(empirical_covariance(transformed_origin_generated_data))\n",
    "print(transformed_origin_generated_data.shape)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1e200",
   "metadata": {},
   "source": [
    "<h2>Cross-Validation</h2>\n",
    "<p>Implmenting the cross-validation for the selected model. This will be done for an assortment of models and their resulting performance will be accessed.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0987220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_model_function(model,data,labels):\n",
    "    resultsFromCV = cross_validate(estimator=model, X=data, y=labels,cv = 10,\n",
    "                                   n_jobs = 3,\n",
    "                                   #pre_dispatch =1,\n",
    "                                   return_train_score=True, \n",
    "                                   scoring= {\"accuracy\": \"accuracy\", \n",
    "                                             \"balanced_accuracy\": \"balanced_accuracy\",\n",
    "                                             \"F1\": \"f1_micro\"\n",
    "                                            })\n",
    "    return resultsFromCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac9de1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp_neural_network_cl = MLPClassifier(hidden_layer_sizes=(8,4),activation=\"relu\", solver=\"adam\", learning_rate_init=0.01,max_iter=100,)\n",
    "mlp_neural_network_cl_v2 = MLPClassifier(hidden_layer_sizes=(8,4),activation=\"relu\", solver=\"adam\", learning_rate_init=0.05,max_iter=100,)\n",
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0af449c",
   "metadata": {},
   "source": [
    "<p>Will be using multilayer perceptron neural network below with <code>activation=\"relu\"</code> and <code>solver=adam</code>. The neural network consists of an input layer that accepts the input data, the hidden layers where calculations are made to perform computations on supplied features, then the ouput layer that will produce the resulting prediction. Neural networks are a more complex predictive modeling method, and can be difficult to interpret.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a56ff099",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_neural_network_cross_validation = cross_validate_model_function(\n",
    "    mlp_neural_network_cl,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "mlp_neural_network_cross_validation_v2 = cross_validate_model_function(\n",
    "    mlp_neural_network_cl_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6db5abcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training and testing scores for first MLP, learning rate = 0.009: \n",
      "\n",
      "train_accuracy  (median):  0.653\n",
      "train_accuracy  (mean):  0.652 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.653\n",
      "train_balanced_accuracy  (mean):  0.652 \n",
      "\n",
      "train_F1  (median):  0.653\n",
      "train_F1  (mean):  0.652 \n",
      "\n",
      "test_accuracy  (median):  0.651\n",
      "test_accuracy  (mean):  0.651 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.651\n",
      "test_balanced_accuracy  (mean):  0.651 \n",
      "\n",
      "test_F1  (median):  0.651\n",
      "test_F1  (mean):  0.651 \n",
      "\n",
      "\n",
      " The training and testing scores for second MLP, learning rate = 0.01: \n",
      "\n",
      "train_accuracy  (median):  0.633\n",
      "train_accuracy  (mean):  0.637 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.633\n",
      "train_balanced_accuracy  (mean):  0.637 \n",
      "\n",
      "train_F1  (median):  0.633\n",
      "train_F1  (mean):  0.637 \n",
      "\n",
      "test_accuracy  (median):  0.633\n",
      "test_accuracy  (mean):  0.634 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.633\n",
      "test_balanced_accuracy  (mean):  0.634 \n",
      "\n",
      "test_F1  (median):  0.633\n",
      "test_F1  (mean):  0.634 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_model_scores(score_key_list, score_dict):\n",
    "    for key in score_key_list:\n",
    "        print(key,\" (median): \" ,round(np.median(score_dict[key]),3))\n",
    "        print(key, \" (mean): \", round(np.mean(score_dict[key]),3), \"\\n\")\n",
    "\n",
    "def score_extract(score_dict):\n",
    "    train_score_list = [key for key in score_dict if \"train\" in key]\n",
    "    test_score_list = [key for key in score_dict if \"test\" in key]\n",
    "    get_model_scores(train_score_list, score_dict)\n",
    "    get_model_scores(test_score_list, score_dict)\n",
    "    \n",
    "print(\"The training and testing scores for first MLP, learning rate = 0.009: \\n\")\n",
    "score_extract(mlp_neural_network_cross_validation)\n",
    "\n",
    "\n",
    "print(\"\\n The training and testing scores for second MLP, learning rate = 0.01: \\n\")\n",
    "score_extract(mlp_neural_network_cross_validation_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f097595",
   "metadata": {},
   "source": [
    "<p>The KNN classifier is being used next. The models are being parallelized across three cores each.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8fcf731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model_cl_v1 = KNeighborsClassifier(n_neighbors =9, metric=\"euclidean\",n_jobs = 3)\n",
    "knn_model_cl_v2 = KNeighborsClassifier(n_neighbors =11, metric=\"euclidean\",n_jobs = 3)\n",
    "knn_model_cl_v3 = KNeighborsClassifier(n_neighbors =13, metric=\"euclidean\",n_jobs = 3)\n",
    "knn_model_cl_v4 = KNeighborsClassifier(n_neighbors =15, metric=\"euclidean\",n_jobs = 3)\n",
    "knn_model_cl_v1_validation =cross_validate_model_function(\n",
    "    knn_model_cl_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "knn_model_cl_v2_validation =cross_validate_model_function(\n",
    "knn_model_cl_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "knn_model_cl_v3_validation =cross_validate_model_function(\n",
    "    knn_model_cl_v3,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "knn_model_cl_v4_validation =cross_validate_model_function(\n",
    "    knn_model_cl_v4,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a76030d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of KNN with 9 neighbors:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.823\n",
      "train_accuracy  (mean):  0.823 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.823\n",
      "train_balanced_accuracy  (mean):  0.823 \n",
      "\n",
      "train_F1  (median):  0.823\n",
      "train_F1  (mean):  0.823 \n",
      "\n",
      "test_accuracy  (median):  0.776\n",
      "test_accuracy  (mean):  0.775 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.776\n",
      "test_balanced_accuracy  (mean):  0.775 \n",
      "\n",
      "test_F1  (median):  0.776\n",
      "test_F1  (mean):  0.775 \n",
      "\n",
      "The result of KNN with 11 neighbors:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.815\n",
      "train_accuracy  (mean):  0.816 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.815\n",
      "train_balanced_accuracy  (mean):  0.816 \n",
      "\n",
      "train_F1  (median):  0.815\n",
      "train_F1  (mean):  0.816 \n",
      "\n",
      "test_accuracy  (median):  0.778\n",
      "test_accuracy  (mean):  0.776 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.778\n",
      "test_balanced_accuracy  (mean):  0.776 \n",
      "\n",
      "test_F1  (median):  0.778\n",
      "test_F1  (mean):  0.776 \n",
      "\n",
      "The result of KNN with 13 neighbors:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.81\n",
      "train_accuracy  (mean):  0.81 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.81\n",
      "train_balanced_accuracy  (mean):  0.81 \n",
      "\n",
      "train_F1  (median):  0.81\n",
      "train_F1  (mean):  0.81 \n",
      "\n",
      "test_accuracy  (median):  0.773\n",
      "test_accuracy  (mean):  0.774 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.773\n",
      "test_balanced_accuracy  (mean):  0.774 \n",
      "\n",
      "test_F1  (median):  0.773\n",
      "test_F1  (mean):  0.774 \n",
      "\n",
      "The result of KNN with 15 neighbors:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.805\n",
      "train_accuracy  (mean):  0.805 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.805\n",
      "train_balanced_accuracy  (mean):  0.805 \n",
      "\n",
      "train_F1  (median):  0.805\n",
      "train_F1  (mean):  0.805 \n",
      "\n",
      "test_accuracy  (median):  0.775\n",
      "test_accuracy  (mean):  0.774 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.775\n",
      "test_balanced_accuracy  (mean):  0.774 \n",
      "\n",
      "test_F1  (median):  0.775\n",
      "test_F1  (mean):  0.774 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The result of KNN with 9 neighbors:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(knn_model_cl_v1_validation)\n",
    "\n",
    "print(\"The result of KNN with 11 neighbors:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(knn_model_cl_v2_validation)\n",
    "\n",
    "print(\"The result of KNN with 13 neighbors:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(knn_model_cl_v3_validation)\n",
    "\n",
    "print(\"The result of KNN with 15 neighbors:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(knn_model_cl_v4_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a325222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc_ensemble_cl_v1 = GradientBoostingClassifier(n_estimators=5,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v2 = GradientBoostingClassifier(n_estimators=10,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v3 = GradientBoostingClassifier(n_estimators=15,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v4 = GradientBoostingClassifier(n_estimators=20,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v5 = GradientBoostingClassifier(n_estimators=50,learning_rate=0.215,random_state=3)\n",
    "gbc_ensemble_cl_v1_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "gbc_ensemble_cl_v2_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "gbc_ensemble_cl_v3_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v3,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "gbc_ensemble_cl_v4_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v4,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "gbc_ensemble_cl_v5_validation = cross_validate_model_function(\n",
    "    gbc_ensemble_cl_v5,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "724d4051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of Gradient Boost Classifier with 50 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.558\n",
      "train_accuracy  (mean):  0.558 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.558\n",
      "train_balanced_accuracy  (mean):  0.558 \n",
      "\n",
      "train_F1  (median):  0.558\n",
      "train_F1  (mean):  0.558 \n",
      "\n",
      "test_accuracy  (median):  0.552\n",
      "test_accuracy  (mean):  0.552 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.552\n",
      "test_balanced_accuracy  (mean):  0.552 \n",
      "\n",
      "test_F1  (median):  0.552\n",
      "test_F1  (mean):  0.552 \n",
      "\n",
      "The result of Gradient Boost Classifier with 100 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.581\n",
      "train_accuracy  (mean):  0.581 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.581\n",
      "train_balanced_accuracy  (mean):  0.581 \n",
      "\n",
      "train_F1  (median):  0.581\n",
      "train_F1  (mean):  0.581 \n",
      "\n",
      "test_accuracy  (median):  0.572\n",
      "test_accuracy  (mean):  0.572 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.573\n",
      "test_balanced_accuracy  (mean):  0.572 \n",
      "\n",
      "test_F1  (median):  0.572\n",
      "test_F1  (mean):  0.572 \n",
      "\n",
      "The result of Gradient Boost Classifier with 150 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.601\n",
      "train_accuracy  (mean):  0.6 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.601\n",
      "train_balanced_accuracy  (mean):  0.6 \n",
      "\n",
      "train_F1  (median):  0.601\n",
      "train_F1  (mean):  0.6 \n",
      "\n",
      "test_accuracy  (median):  0.588\n",
      "test_accuracy  (mean):  0.589 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.588\n",
      "test_balanced_accuracy  (mean):  0.589 \n",
      "\n",
      "test_F1  (median):  0.588\n",
      "test_F1  (mean):  0.589 \n",
      "\n",
      "The result of Gradient Boost Classifier with 200 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.616\n",
      "train_accuracy  (mean):  0.615 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.616\n",
      "train_balanced_accuracy  (mean):  0.615 \n",
      "\n",
      "train_F1  (median):  0.616\n",
      "train_F1  (mean):  0.615 \n",
      "\n",
      "test_accuracy  (median):  0.602\n",
      "test_accuracy  (mean):  0.603 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.602\n",
      "test_balanced_accuracy  (mean):  0.603 \n",
      "\n",
      "test_F1  (median):  0.602\n",
      "test_F1  (mean):  0.603 \n",
      "\n",
      "The result of Gradient Boost Classifier with 50 trees:\n",
      "The training and testing scores:\n",
      "train_accuracy  (median):  0.674\n",
      "train_accuracy  (mean):  0.675 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.675\n",
      "train_balanced_accuracy  (mean):  0.675 \n",
      "\n",
      "train_F1  (median):  0.674\n",
      "train_F1  (mean):  0.675 \n",
      "\n",
      "test_accuracy  (median):  0.653\n",
      "test_accuracy  (mean):  0.652 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.653\n",
      "test_balanced_accuracy  (mean):  0.652 \n",
      "\n",
      "test_F1  (median):  0.653\n",
      "test_F1  (mean):  0.652 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The result of Gradient Boost Classifier with 50 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v1_validation)\n",
    "\n",
    "print(\"The result of Gradient Boost Classifier with 100 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v2_validation)\n",
    "\n",
    "print(\"The result of Gradient Boost Classifier with 150 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v3_validation)\n",
    "\n",
    "print(\"The result of Gradient Boost Classifier with 200 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v4_validation)\n",
    "\n",
    "print(\"The result of Gradient Boost Classifier with 50 trees:\")\n",
    "print(\"The training and testing scores:\")\n",
    "score_extract(gbc_ensemble_cl_v5_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ed88a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_red_cl_v1 = LogisticRegression(penalty=\"l2\",C=0.85, random_state = 3, solver=\"newton-cg\", max_iter=200,n_jobs=2)\n",
    "log_red_cl_v2 = LogisticRegression(penalty=\"l2\",C=0.85, random_state = 3, solver=\"sag\", max_iter=200,n_jobs=2)\n",
    "log_red_cl_v3 = LogisticRegression(penalty=\"l2\",C=0.75, random_state = 3, solver=\"newton-cg\", max_iter=200,n_jobs=2)\n",
    "log_red_cl_v4 = LogisticRegression(penalty=\"l2\",C=0.75, random_state = 3, solver=\"sag\", max_iter=200,n_jobs=2)\n",
    "log_red_cl_v1_validation = cross_validate_model_function(\n",
    "    log_red_cl_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_red_cl_v2_validation = cross_validate_model_function(\n",
    "    log_red_cl_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_red_cl_v3_validation = cross_validate_model_function(\n",
    "    log_red_cl_v3,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_red_cl_v4_validation = cross_validate_model_function(\n",
    "    log_red_cl_v4,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9ce0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cv_train_test_results(results_dict):\n",
    "    print(\"The training scores:\")\n",
    "    print(results_dict[\"train_score\"])\n",
    "    print(\"The testing scores:\")\n",
    "    print(results_dict[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1255cb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression train and test scores: \n",
      "Newton solver logistic regression C = 0.85:\n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n",
      "SAG solverlogistic regression C = 0.85: \n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n",
      "Newton solver logistic regression C = 0.75:\n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n",
      "SAG solverlogistic regression C = 0.75: \n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Going into logistic regression\n",
    "# Printing the training and testing scores\n",
    "print(\"Logistic Regression train and test scores: \")\n",
    "print(\"Newton solver logistic regression C = 0.85:\" )\n",
    "score_extract(log_red_cl_v1_validation)\n",
    "print(\"SAG solverlogistic regression C = 0.85: \")\n",
    "score_extract(log_red_cl_v2_validation)\n",
    "print(\"Newton solver logistic regression C = 0.75:\")\n",
    "score_extract(log_red_cl_v3_validation)\n",
    "print(\"SAG solverlogistic regression C = 0.75: \")\n",
    "score_extract(log_red_cl_v4_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47a0d040-8df2-42b9-ae72-335a21f621cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sklearn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msklearn\u001b[49m\u001b[38;5;241m.\u001b[39m__version__\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sklearn' is not defined"
     ]
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c97b18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with logistic regression Newton solver C= 0.85:\n",
      "Training and testing scores:\n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n",
      "Bagging with logistic regression SAG solver C= 0.85:\n",
      "Training and testing scores:\n",
      "train_accuracy  (median):  0.477\n",
      "train_accuracy  (mean):  0.477 \n",
      "\n",
      "train_balanced_accuracy  (median):  0.477\n",
      "train_balanced_accuracy  (mean):  0.477 \n",
      "\n",
      "train_F1  (median):  0.477\n",
      "train_F1  (mean):  0.477 \n",
      "\n",
      "test_accuracy  (median):  0.476\n",
      "test_accuracy  (mean):  0.476 \n",
      "\n",
      "test_balanced_accuracy  (median):  0.476\n",
      "test_balanced_accuracy  (mean):  0.476 \n",
      "\n",
      "test_F1  (median):  0.476\n",
      "test_F1  (mean):  0.476 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "log_reg_cl_use_bagging_v1 = BaggingClassifier(estimator=log_red_cl_v1,n_estimators=5, n_jobs = 2 ,random_state=3)\n",
    "log_reg_cl_use_bagging_v2 = BaggingClassifier(estimator=log_red_cl_v2,n_estimators=5, n_jobs = 2 ,random_state=3)\n",
    "\n",
    "log_reg_cl_use_bagging_v1_validation = cross_validate_model_function(\n",
    "    log_reg_cl_use_bagging_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_reg_cl_use_bagging_v2_validation = cross_validate_model_function(\n",
    "    log_reg_cl_use_bagging_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "\n",
    "print(\"Bagging with logistic regression Newton solver C= 0.85:\")\n",
    "print(\"Training and testing scores:\")\n",
    "score_extract(log_reg_cl_use_bagging_v1_validation)\n",
    "print(\"Bagging with logistic regression SAG solver C= 0.85:\")\n",
    "print(\"Training and testing scores:\")\n",
    "score_extract(log_reg_cl_use_bagging_v2_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c01a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "log_reg_cl_adaboost_v1 = AdaBoostClassifier(estimator=log_red_cl_v1,n_estimators=15,random_state=3)\n",
    "log_reg_cl_adaboost_v2 = AdaBoostClassifier(estimator=log_red_cl_v2,n_estimators=15,random_state=3)\n",
    "\n",
    "log_reg_cl_adaboost_v1_validation = cross_validate_model_function(\n",
    "    log_reg_cl_adaboost_v1,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "log_reg_cl_adaboost_v2_validation = cross_validate_model_function(\n",
    "    log_reg_cl_adaboost_v2,pd.DataFrame(data=transformed_origin_generated_data),generated_labels)\n",
    "\n",
    "print(\"Adaboosting with Logistic Regression: \")\n",
    "print(\"Bagging with logistic regression Newton solver C= 0.85:\")\n",
    "print(\"Training and testing scores:\")\n",
    "score_extract(log_reg_cl_adaboost_v1_validation)\n",
    "print(\"Bagging with logistic regression SAG solver C= 0.85:\")\n",
    "print(\"Training and testing scores:\")\n",
    "score_extract(log_reg_cl_adaboost_v2_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34848bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference: https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "# Reference: https://stats.stackexchange.com/questions/362619/why-the-accuracy-of-my-neural-network-is-falling-when-epoch-increases by Tonca\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "opimize_by_adam =keras.optimizers.Adam(learning_rate=0.001)\n",
    "#opimize_by_adam =Adam(learning_rate=0.000023)\n",
    "def generate_keras_model():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance = generate_keras_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_epochs = 500\n",
    "set_metrics = [\"binary_accuracy\", \"categorical_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08da3b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(transformed_origin_generated_data,generated_labels, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59f9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 146/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2247 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2225\n",
      "Epoch 147/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2247 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2225\n",
      "Epoch 148/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2225\n",
      "Epoch 149/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2249 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2225\n",
      "Epoch 150/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2250 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2225\n",
      "Epoch 151/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2250 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2225\n",
      "Epoch 152/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2225\n",
      "Epoch 153/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2250 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2225\n",
      "Epoch 154/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2250 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2225\n",
      "Epoch 155/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2249 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2225\n",
      "Epoch 156/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2249 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2221\n",
      "Epoch 157/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2249 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2221\n",
      "Epoch 158/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2221\n",
      "Epoch 159/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2221\n",
      "Epoch 160/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2217\n",
      "Epoch 161/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2247 - val_loss: 1.2155 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2217\n",
      "Epoch 162/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2212\n",
      "Epoch 163/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2245 - val_loss: 1.2155 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2212\n",
      "Epoch 164/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2244 - val_loss: 1.2155 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2212\n",
      "Epoch 165/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2246 - val_loss: 1.2155 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2212\n",
      "Epoch 166/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2221\n",
      "Epoch 167/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2250 - val_loss: 1.2155 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2221\n",
      "Epoch 168/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2250 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2221\n",
      "Epoch 169/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2471 - categorical_accuracy: 0.2252 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2225\n",
      "Epoch 170/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2471 - categorical_accuracy: 0.2252 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2225\n",
      "Epoch 171/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2252 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2225\n",
      "Epoch 172/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2251 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 173/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2249 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2225\n",
      "Epoch 174/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2251 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2221\n",
      "Epoch 175/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2250 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2221\n",
      "Epoch 176/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2251 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2221\n",
      "Epoch 177/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2221\n",
      "Epoch 178/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2249 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2217\n",
      "Epoch 179/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2217\n",
      "Epoch 180/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2246 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2245 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2212\n",
      "Epoch 182/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2245 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2212\n",
      "Epoch 183/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2246 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2217\n",
      "Epoch 184/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2246 - val_loss: 1.2155 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2217\n",
      "Epoch 185/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2246 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2212\n",
      "Epoch 186/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2247 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 187/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2245 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 188/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2246 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 189/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2246 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2212\n",
      "Epoch 190/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2246 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2212\n",
      "Epoch 191/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2247 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2212\n",
      "Epoch 192/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 193/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2249 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 194/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2249 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 195/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2250 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 196/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2249 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 197/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2247 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 198/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 199/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n",
      "Epoch 200/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1932 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2248 - val_loss: 1.2155 - val_binary_accuracy: 0.2566 - val_categorical_accuracy: 0.2217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d91bb2e08>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ff653",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b6ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keras_model_2():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(8,activation=\"relu\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_2 = generate_keras_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8304d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d3581a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1143 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2058 - val_loss: 1.1389 - val_binary_accuracy: 0.2592 - val_categorical_accuracy: 0.2200\n",
      "Epoch 146/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1140 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2059 - val_loss: 1.1387 - val_binary_accuracy: 0.2590 - val_categorical_accuracy: 0.2200\n",
      "Epoch 147/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1137 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2056 - val_loss: 1.1385 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2196\n",
      "Epoch 148/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1134 - binary_accuracy: 0.2530 - categorical_accuracy: 0.2058 - val_loss: 1.1383 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2196\n",
      "Epoch 149/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1132 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2057 - val_loss: 1.1381 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2183\n",
      "Epoch 150/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1129 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2066 - val_loss: 1.1379 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2179\n",
      "Epoch 151/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1127 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2065 - val_loss: 1.1377 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2175\n",
      "Epoch 152/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1124 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2064 - val_loss: 1.1375 - val_binary_accuracy: 0.2590 - val_categorical_accuracy: 0.2163\n",
      "Epoch 153/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1122 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2056 - val_loss: 1.1373 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2158\n",
      "Epoch 154/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1119 - binary_accuracy: 0.2529 - categorical_accuracy: 0.2050 - val_loss: 1.1371 - val_binary_accuracy: 0.2591 - val_categorical_accuracy: 0.2158\n",
      "Epoch 155/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1117 - binary_accuracy: 0.2530 - categorical_accuracy: 0.2046 - val_loss: 1.1369 - val_binary_accuracy: 0.2592 - val_categorical_accuracy: 0.2146\n",
      "Epoch 156/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1114 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2043 - val_loss: 1.1367 - val_binary_accuracy: 0.2593 - val_categorical_accuracy: 0.2142\n",
      "Epoch 157/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1112 - binary_accuracy: 0.2530 - categorical_accuracy: 0.2044 - val_loss: 1.1364 - val_binary_accuracy: 0.2594 - val_categorical_accuracy: 0.2142\n",
      "Epoch 158/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1109 - binary_accuracy: 0.2530 - categorical_accuracy: 0.2044 - val_loss: 1.1362 - val_binary_accuracy: 0.2594 - val_categorical_accuracy: 0.2142\n",
      "Epoch 159/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1107 - binary_accuracy: 0.2529 - categorical_accuracy: 0.2046 - val_loss: 1.1361 - val_binary_accuracy: 0.2594 - val_categorical_accuracy: 0.2146\n",
      "Epoch 160/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1104 - binary_accuracy: 0.2529 - categorical_accuracy: 0.2045 - val_loss: 1.1359 - val_binary_accuracy: 0.2593 - val_categorical_accuracy: 0.2154\n",
      "Epoch 161/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1102 - binary_accuracy: 0.2529 - categorical_accuracy: 0.2042 - val_loss: 1.1357 - val_binary_accuracy: 0.2594 - val_categorical_accuracy: 0.2154\n",
      "Epoch 162/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1100 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2043 - val_loss: 1.1355 - val_binary_accuracy: 0.2592 - val_categorical_accuracy: 0.2150\n",
      "Epoch 163/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1098 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2042 - val_loss: 1.1353 - val_binary_accuracy: 0.2590 - val_categorical_accuracy: 0.2158\n",
      "Epoch 164/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1095 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2046 - val_loss: 1.1352 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2163\n",
      "Epoch 165/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1093 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2046 - val_loss: 1.1350 - val_binary_accuracy: 0.2590 - val_categorical_accuracy: 0.2158\n",
      "Epoch 166/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1091 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2045 - val_loss: 1.1348 - val_binary_accuracy: 0.2591 - val_categorical_accuracy: 0.2158\n",
      "Epoch 167/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1089 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2047 - val_loss: 1.1347 - val_binary_accuracy: 0.2590 - val_categorical_accuracy: 0.2171\n",
      "Epoch 168/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1086 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2047 - val_loss: 1.1345 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2179\n",
      "Epoch 169/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1084 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2048 - val_loss: 1.1344 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2175\n",
      "Epoch 170/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1082 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2046 - val_loss: 1.1342 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2175\n",
      "Epoch 171/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1080 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2044 - val_loss: 1.1340 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2179\n",
      "Epoch 172/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1078 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2042 - val_loss: 1.1339 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2179\n",
      "Epoch 173/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1076 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2043 - val_loss: 1.1337 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2179\n",
      "Epoch 174/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1074 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2037 - val_loss: 1.1335 - val_binary_accuracy: 0.2586 - val_categorical_accuracy: 0.2179\n",
      "Epoch 175/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1072 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2040 - val_loss: 1.1334 - val_binary_accuracy: 0.2586 - val_categorical_accuracy: 0.2188\n",
      "Epoch 176/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1070 - binary_accuracy: 0.2524 - categorical_accuracy: 0.2042 - val_loss: 1.1332 - val_binary_accuracy: 0.2584 - val_categorical_accuracy: 0.2192\n",
      "Epoch 177/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1067 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2039 - val_loss: 1.1330 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.2192\n",
      "Epoch 178/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1065 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2040 - val_loss: 1.1328 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.2200\n",
      "Epoch 179/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1063 - binary_accuracy: 0.2524 - categorical_accuracy: 0.2039 - val_loss: 1.1326 - val_binary_accuracy: 0.2584 - val_categorical_accuracy: 0.2204\n",
      "Epoch 180/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1061 - binary_accuracy: 0.2524 - categorical_accuracy: 0.2035 - val_loss: 1.1324 - val_binary_accuracy: 0.2584 - val_categorical_accuracy: 0.2200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1059 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2035 - val_loss: 1.1322 - val_binary_accuracy: 0.2584 - val_categorical_accuracy: 0.2200\n",
      "Epoch 182/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1057 - binary_accuracy: 0.2524 - categorical_accuracy: 0.2039 - val_loss: 1.1320 - val_binary_accuracy: 0.2584 - val_categorical_accuracy: 0.2204\n",
      "Epoch 183/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1055 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2043 - val_loss: 1.1319 - val_binary_accuracy: 0.2583 - val_categorical_accuracy: 0.2204\n",
      "Epoch 184/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1053 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2035 - val_loss: 1.1317 - val_binary_accuracy: 0.2583 - val_categorical_accuracy: 0.2204\n",
      "Epoch 185/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1051 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2036 - val_loss: 1.1315 - val_binary_accuracy: 0.2583 - val_categorical_accuracy: 0.2208\n",
      "Epoch 186/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1049 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2035 - val_loss: 1.1314 - val_binary_accuracy: 0.2583 - val_categorical_accuracy: 0.2204\n",
      "Epoch 187/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1047 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2035 - val_loss: 1.1312 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.2196\n",
      "Epoch 188/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1045 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2039 - val_loss: 1.1311 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.2196\n",
      "Epoch 189/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1043 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2035 - val_loss: 1.1309 - val_binary_accuracy: 0.2586 - val_categorical_accuracy: 0.2204\n",
      "Epoch 190/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1041 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2036 - val_loss: 1.1307 - val_binary_accuracy: 0.2586 - val_categorical_accuracy: 0.2200\n",
      "Epoch 191/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1039 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2036 - val_loss: 1.1305 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2200\n",
      "Epoch 192/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1037 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2036 - val_loss: 1.1304 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2204\n",
      "Epoch 193/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1035 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2033 - val_loss: 1.1302 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2208\n",
      "Epoch 194/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1033 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2032 - val_loss: 1.1300 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2204\n",
      "Epoch 195/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1031 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2034 - val_loss: 1.1299 - val_binary_accuracy: 0.2589 - val_categorical_accuracy: 0.2212\n",
      "Epoch 196/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1029 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2035 - val_loss: 1.1297 - val_binary_accuracy: 0.2590 - val_categorical_accuracy: 0.2212\n",
      "Epoch 197/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1027 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2034 - val_loss: 1.1295 - val_binary_accuracy: 0.2590 - val_categorical_accuracy: 0.2212\n",
      "Epoch 198/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1025 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2032 - val_loss: 1.1294 - val_binary_accuracy: 0.2592 - val_categorical_accuracy: 0.2217\n",
      "Epoch 199/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1023 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2030 - val_loss: 1.1292 - val_binary_accuracy: 0.2592 - val_categorical_accuracy: 0.2217\n",
      "Epoch 200/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 1.1021 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2029 - val_loss: 1.1290 - val_binary_accuracy: 0.2591 - val_categorical_accuracy: 0.2208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d91dc4e88>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_2.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb87c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe434673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keras_model_3():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(8,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(16,activation=\"relu\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_3 = generate_keras_model_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bcb3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_3.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0411a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9989 - binary_accuracy: 0.2535 - categorical_accuracy: 0.1808 - val_loss: 1.0349 - val_binary_accuracy: 0.2586 - val_categorical_accuracy: 0.1929\n",
      "Epoch 146/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9980 - binary_accuracy: 0.2535 - categorical_accuracy: 0.1810 - val_loss: 1.0340 - val_binary_accuracy: 0.2581 - val_categorical_accuracy: 0.1937\n",
      "Epoch 147/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9970 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1808 - val_loss: 1.0332 - val_binary_accuracy: 0.2582 - val_categorical_accuracy: 0.1929\n",
      "Epoch 148/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9960 - binary_accuracy: 0.2537 - categorical_accuracy: 0.1805 - val_loss: 1.0325 - val_binary_accuracy: 0.2582 - val_categorical_accuracy: 0.1929\n",
      "Epoch 149/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9951 - binary_accuracy: 0.2535 - categorical_accuracy: 0.1818 - val_loss: 1.0319 - val_binary_accuracy: 0.2580 - val_categorical_accuracy: 0.1942\n",
      "Epoch 150/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9941 - binary_accuracy: 0.2537 - categorical_accuracy: 0.1821 - val_loss: 1.0311 - val_binary_accuracy: 0.2582 - val_categorical_accuracy: 0.1950\n",
      "Epoch 151/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9932 - binary_accuracy: 0.2535 - categorical_accuracy: 0.1823 - val_loss: 1.0302 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.1967\n",
      "Epoch 152/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9922 - binary_accuracy: 0.2535 - categorical_accuracy: 0.1829 - val_loss: 1.0293 - val_binary_accuracy: 0.2584 - val_categorical_accuracy: 0.1967\n",
      "Epoch 153/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9912 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1828 - val_loss: 1.0284 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.1963\n",
      "Epoch 154/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9903 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1831 - val_loss: 1.0275 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.1975\n",
      "Epoch 155/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9893 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1833 - val_loss: 1.0267 - val_binary_accuracy: 0.2582 - val_categorical_accuracy: 0.1967\n",
      "Epoch 156/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9883 - binary_accuracy: 0.2538 - categorical_accuracy: 0.1828 - val_loss: 1.0257 - val_binary_accuracy: 0.2581 - val_categorical_accuracy: 0.1975\n",
      "Epoch 157/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9874 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1835 - val_loss: 1.0248 - val_binary_accuracy: 0.2583 - val_categorical_accuracy: 0.2000\n",
      "Epoch 158/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9864 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1838 - val_loss: 1.0238 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.2004\n",
      "Epoch 159/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9855 - binary_accuracy: 0.2537 - categorical_accuracy: 0.1846 - val_loss: 1.0229 - val_binary_accuracy: 0.2583 - val_categorical_accuracy: 0.2008\n",
      "Epoch 160/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9846 - binary_accuracy: 0.2537 - categorical_accuracy: 0.1848 - val_loss: 1.0221 - val_binary_accuracy: 0.2582 - val_categorical_accuracy: 0.2000\n",
      "Epoch 161/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9837 - binary_accuracy: 0.2535 - categorical_accuracy: 0.1856 - val_loss: 1.0212 - val_binary_accuracy: 0.2586 - val_categorical_accuracy: 0.2008\n",
      "Epoch 162/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9827 - binary_accuracy: 0.2535 - categorical_accuracy: 0.1858 - val_loss: 1.0203 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.1992\n",
      "Epoch 163/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9818 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1870 - val_loss: 1.0195 - val_binary_accuracy: 0.2586 - val_categorical_accuracy: 0.1975\n",
      "Epoch 164/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9808 - binary_accuracy: 0.2537 - categorical_accuracy: 0.1869 - val_loss: 1.0187 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.1988\n",
      "Epoch 165/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9798 - binary_accuracy: 0.2535 - categorical_accuracy: 0.1880 - val_loss: 1.0178 - val_binary_accuracy: 0.2591 - val_categorical_accuracy: 0.1988\n",
      "Epoch 166/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9789 - binary_accuracy: 0.2534 - categorical_accuracy: 0.1883 - val_loss: 1.0169 - val_binary_accuracy: 0.2591 - val_categorical_accuracy: 0.1992\n",
      "Epoch 167/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9779 - binary_accuracy: 0.2533 - categorical_accuracy: 0.1890 - val_loss: 1.0159 - val_binary_accuracy: 0.2593 - val_categorical_accuracy: 0.1996\n",
      "Epoch 168/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9770 - binary_accuracy: 0.2534 - categorical_accuracy: 0.1892 - val_loss: 1.0148 - val_binary_accuracy: 0.2592 - val_categorical_accuracy: 0.2004\n",
      "Epoch 169/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9760 - binary_accuracy: 0.2534 - categorical_accuracy: 0.1887 - val_loss: 1.0138 - val_binary_accuracy: 0.2593 - val_categorical_accuracy: 0.2004\n",
      "Epoch 170/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9750 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1904 - val_loss: 1.0127 - val_binary_accuracy: 0.2593 - val_categorical_accuracy: 0.2025\n",
      "Epoch 171/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9740 - binary_accuracy: 0.2534 - categorical_accuracy: 0.1916 - val_loss: 1.0116 - val_binary_accuracy: 0.2595 - val_categorical_accuracy: 0.2033\n",
      "Epoch 172/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9730 - binary_accuracy: 0.2534 - categorical_accuracy: 0.1919 - val_loss: 1.0107 - val_binary_accuracy: 0.2597 - val_categorical_accuracy: 0.2046\n",
      "Epoch 173/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9720 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1930 - val_loss: 1.0095 - val_binary_accuracy: 0.2597 - val_categorical_accuracy: 0.2046\n",
      "Epoch 174/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9710 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1932 - val_loss: 1.0085 - val_binary_accuracy: 0.2592 - val_categorical_accuracy: 0.2042\n",
      "Epoch 175/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9700 - binary_accuracy: 0.2537 - categorical_accuracy: 0.1928 - val_loss: 1.0075 - val_binary_accuracy: 0.2594 - val_categorical_accuracy: 0.2033\n",
      "Epoch 176/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9691 - binary_accuracy: 0.2537 - categorical_accuracy: 0.1923 - val_loss: 1.0068 - val_binary_accuracy: 0.2593 - val_categorical_accuracy: 0.2042\n",
      "Epoch 177/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9680 - binary_accuracy: 0.2535 - categorical_accuracy: 0.1922 - val_loss: 1.0059 - val_binary_accuracy: 0.2595 - val_categorical_accuracy: 0.2025\n",
      "Epoch 178/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9671 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1939 - val_loss: 1.0048 - val_binary_accuracy: 0.2597 - val_categorical_accuracy: 0.2037\n",
      "Epoch 179/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9661 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1956 - val_loss: 1.0039 - val_binary_accuracy: 0.2598 - val_categorical_accuracy: 0.2050\n",
      "Epoch 180/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9651 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1965 - val_loss: 1.0028 - val_binary_accuracy: 0.2600 - val_categorical_accuracy: 0.2033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9642 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1961 - val_loss: 1.0017 - val_binary_accuracy: 0.2601 - val_categorical_accuracy: 0.2033\n",
      "Epoch 182/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9633 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1977 - val_loss: 1.0007 - val_binary_accuracy: 0.2601 - val_categorical_accuracy: 0.2067\n",
      "Epoch 183/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9624 - binary_accuracy: 0.2536 - categorical_accuracy: 0.1988 - val_loss: 0.9998 - val_binary_accuracy: 0.2604 - val_categorical_accuracy: 0.2075\n",
      "Epoch 184/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9615 - binary_accuracy: 0.2538 - categorical_accuracy: 0.1995 - val_loss: 0.9990 - val_binary_accuracy: 0.2597 - val_categorical_accuracy: 0.2079\n",
      "Epoch 185/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9605 - binary_accuracy: 0.2539 - categorical_accuracy: 0.1997 - val_loss: 0.9981 - val_binary_accuracy: 0.2597 - val_categorical_accuracy: 0.2092\n",
      "Epoch 186/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9597 - binary_accuracy: 0.2535 - categorical_accuracy: 0.2006 - val_loss: 0.9973 - val_binary_accuracy: 0.2595 - val_categorical_accuracy: 0.2075\n",
      "Epoch 187/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9588 - binary_accuracy: 0.2534 - categorical_accuracy: 0.2002 - val_loss: 0.9964 - val_binary_accuracy: 0.2594 - val_categorical_accuracy: 0.2067\n",
      "Epoch 188/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9580 - binary_accuracy: 0.2536 - categorical_accuracy: 0.2004 - val_loss: 0.9956 - val_binary_accuracy: 0.2598 - val_categorical_accuracy: 0.2067\n",
      "Epoch 189/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9571 - binary_accuracy: 0.2535 - categorical_accuracy: 0.2003 - val_loss: 0.9946 - val_binary_accuracy: 0.2595 - val_categorical_accuracy: 0.2067\n",
      "Epoch 190/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9564 - binary_accuracy: 0.2533 - categorical_accuracy: 0.1998 - val_loss: 0.9934 - val_binary_accuracy: 0.2592 - val_categorical_accuracy: 0.2087\n",
      "Epoch 191/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9556 - binary_accuracy: 0.2533 - categorical_accuracy: 0.2008 - val_loss: 0.9924 - val_binary_accuracy: 0.2590 - val_categorical_accuracy: 0.2100\n",
      "Epoch 192/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9547 - binary_accuracy: 0.2532 - categorical_accuracy: 0.2020 - val_loss: 0.9916 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2108\n",
      "Epoch 193/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9539 - binary_accuracy: 0.2530 - categorical_accuracy: 0.2035 - val_loss: 0.9908 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2125\n",
      "Epoch 194/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9532 - binary_accuracy: 0.2532 - categorical_accuracy: 0.2042 - val_loss: 0.9899 - val_binary_accuracy: 0.2586 - val_categorical_accuracy: 0.2121\n",
      "Epoch 195/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9525 - binary_accuracy: 0.2533 - categorical_accuracy: 0.2049 - val_loss: 0.9893 - val_binary_accuracy: 0.2590 - val_categorical_accuracy: 0.2108\n",
      "Epoch 196/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9517 - binary_accuracy: 0.2532 - categorical_accuracy: 0.2044 - val_loss: 0.9883 - val_binary_accuracy: 0.2591 - val_categorical_accuracy: 0.2113\n",
      "Epoch 197/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9509 - binary_accuracy: 0.2533 - categorical_accuracy: 0.2041 - val_loss: 0.9874 - val_binary_accuracy: 0.2591 - val_categorical_accuracy: 0.2092\n",
      "Epoch 198/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9502 - binary_accuracy: 0.2532 - categorical_accuracy: 0.2025 - val_loss: 0.9863 - val_binary_accuracy: 0.2586 - val_categorical_accuracy: 0.2092\n",
      "Epoch 199/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9494 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2017 - val_loss: 0.9853 - val_binary_accuracy: 0.2585 - val_categorical_accuracy: 0.2083\n",
      "Epoch 200/200\n",
      "9600/9600 [==============================] - 0s 1us/sample - loss: 0.9486 - binary_accuracy: 0.2532 - categorical_accuracy: 0.2024 - val_loss: 0.9844 - val_binary_accuracy: 0.2582 - val_categorical_accuracy: 0.2113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d921dfc48>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_3.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d0706",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_3.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fc50d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://www.tensorflow.org/tutorials/keras/overfit_and_underfit\n",
    "# Reduction of overfitting by dropout decreased learning rate over time\n",
    "\n",
    "def generate_keras_model_4():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(32,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dropout(0.25))\n",
    "    keras_model.add(tf.keras.layers.Dense(32,activation=\"relu\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_4 = generate_keras_model_4()\n",
    "\n",
    "optim_schedule = keras.optimizers.schedules.InverseTimeDecay(\n",
    "    0.0012, decay_steps =4000,decay_rate=0.5)\n",
    "opimize_by_adam_2 = keras.optimizers.Adam(optim_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_4.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam_2, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003adbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0136 - binary_accuracy: 0.2544 - categorical_accuracy: 0.2136 - val_loss: 0.9759 - val_binary_accuracy: 0.2621 - val_categorical_accuracy: 0.2258\n",
      "Epoch 146/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0161 - binary_accuracy: 0.2541 - categorical_accuracy: 0.2166 - val_loss: 0.9744 - val_binary_accuracy: 0.2615 - val_categorical_accuracy: 0.2267\n",
      "Epoch 147/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0158 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2233 - val_loss: 0.9731 - val_binary_accuracy: 0.2617 - val_categorical_accuracy: 0.2258\n",
      "Epoch 148/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0145 - binary_accuracy: 0.2540 - categorical_accuracy: 0.2166 - val_loss: 0.9717 - val_binary_accuracy: 0.2618 - val_categorical_accuracy: 0.2212\n",
      "Epoch 149/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0066 - binary_accuracy: 0.2537 - categorical_accuracy: 0.2152 - val_loss: 0.9705 - val_binary_accuracy: 0.2619 - val_categorical_accuracy: 0.2217\n",
      "Epoch 150/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0060 - binary_accuracy: 0.2539 - categorical_accuracy: 0.2146 - val_loss: 0.9694 - val_binary_accuracy: 0.2626 - val_categorical_accuracy: 0.2183\n",
      "Epoch 151/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0012 - binary_accuracy: 0.2532 - categorical_accuracy: 0.2117 - val_loss: 0.9684 - val_binary_accuracy: 0.2622 - val_categorical_accuracy: 0.2208\n",
      "Epoch 152/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0073 - binary_accuracy: 0.2537 - categorical_accuracy: 0.2067 - val_loss: 0.9674 - val_binary_accuracy: 0.2622 - val_categorical_accuracy: 0.2237\n",
      "Epoch 153/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0013 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2102 - val_loss: 0.9663 - val_binary_accuracy: 0.2616 - val_categorical_accuracy: 0.2279\n",
      "Epoch 154/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0068 - binary_accuracy: 0.2532 - categorical_accuracy: 0.2156 - val_loss: 0.9654 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.2329\n",
      "Epoch 155/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0029 - binary_accuracy: 0.2534 - categorical_accuracy: 0.2212 - val_loss: 0.9643 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.2362\n",
      "Epoch 156/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0097 - binary_accuracy: 0.2523 - categorical_accuracy: 0.2268 - val_loss: 0.9630 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.2346\n",
      "Epoch 157/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 1.0003 - binary_accuracy: 0.2529 - categorical_accuracy: 0.2258 - val_loss: 0.9615 - val_binary_accuracy: 0.2619 - val_categorical_accuracy: 0.2313\n",
      "Epoch 158/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9988 - binary_accuracy: 0.2536 - categorical_accuracy: 0.2132 - val_loss: 0.9599 - val_binary_accuracy: 0.2617 - val_categorical_accuracy: 0.2250\n",
      "Epoch 159/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9937 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2126 - val_loss: 0.9584 - val_binary_accuracy: 0.2619 - val_categorical_accuracy: 0.2242\n",
      "Epoch 160/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9919 - binary_accuracy: 0.2543 - categorical_accuracy: 0.2180 - val_loss: 0.9571 - val_binary_accuracy: 0.2620 - val_categorical_accuracy: 0.2221\n",
      "Epoch 161/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9933 - binary_accuracy: 0.2534 - categorical_accuracy: 0.2177 - val_loss: 0.9558 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.2204\n",
      "Epoch 162/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9934 - binary_accuracy: 0.2537 - categorical_accuracy: 0.2148 - val_loss: 0.9545 - val_binary_accuracy: 0.2617 - val_categorical_accuracy: 0.2225\n",
      "Epoch 163/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9925 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2191 - val_loss: 0.9533 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.2246\n",
      "Epoch 164/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9941 - binary_accuracy: 0.2525 - categorical_accuracy: 0.2188 - val_loss: 0.9520 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.2262\n",
      "Epoch 165/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9923 - binary_accuracy: 0.2522 - categorical_accuracy: 0.2229 - val_loss: 0.9507 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.2288\n",
      "Epoch 166/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9918 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2150 - val_loss: 0.9494 - val_binary_accuracy: 0.2611 - val_categorical_accuracy: 0.2296\n",
      "Epoch 167/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9913 - binary_accuracy: 0.2533 - categorical_accuracy: 0.2220 - val_loss: 0.9481 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.2288\n",
      "Epoch 168/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9869 - binary_accuracy: 0.2534 - categorical_accuracy: 0.2234 - val_loss: 0.9469 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.2267\n",
      "Epoch 169/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9879 - binary_accuracy: 0.2543 - categorical_accuracy: 0.2151 - val_loss: 0.9458 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.2262\n",
      "Epoch 170/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9913 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2105 - val_loss: 0.9449 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.2242\n",
      "Epoch 171/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9901 - binary_accuracy: 0.2532 - categorical_accuracy: 0.2165 - val_loss: 0.9440 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.2304\n",
      "Epoch 172/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9786 - binary_accuracy: 0.2530 - categorical_accuracy: 0.2171 - val_loss: 0.9430 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.2304\n",
      "Epoch 173/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9846 - binary_accuracy: 0.2536 - categorical_accuracy: 0.2180 - val_loss: 0.9419 - val_binary_accuracy: 0.2608 - val_categorical_accuracy: 0.2325\n",
      "Epoch 174/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9791 - binary_accuracy: 0.2530 - categorical_accuracy: 0.2217 - val_loss: 0.9408 - val_binary_accuracy: 0.2607 - val_categorical_accuracy: 0.2333\n",
      "Epoch 175/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9841 - binary_accuracy: 0.2532 - categorical_accuracy: 0.2191 - val_loss: 0.9396 - val_binary_accuracy: 0.2607 - val_categorical_accuracy: 0.2329\n",
      "Epoch 176/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9804 - binary_accuracy: 0.2534 - categorical_accuracy: 0.2216 - val_loss: 0.9383 - val_binary_accuracy: 0.2609 - val_categorical_accuracy: 0.2321\n",
      "Epoch 177/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9746 - binary_accuracy: 0.2536 - categorical_accuracy: 0.2179 - val_loss: 0.9373 - val_binary_accuracy: 0.2609 - val_categorical_accuracy: 0.2296\n",
      "Epoch 178/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9782 - binary_accuracy: 0.2521 - categorical_accuracy: 0.2208 - val_loss: 0.9362 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.2296\n",
      "Epoch 179/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9705 - binary_accuracy: 0.2529 - categorical_accuracy: 0.2229 - val_loss: 0.9347 - val_binary_accuracy: 0.2616 - val_categorical_accuracy: 0.2304\n",
      "Epoch 180/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9731 - binary_accuracy: 0.2530 - categorical_accuracy: 0.2206 - val_loss: 0.9333 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9713 - binary_accuracy: 0.2523 - categorical_accuracy: 0.2206 - val_loss: 0.9321 - val_binary_accuracy: 0.2611 - val_categorical_accuracy: 0.2375\n",
      "Epoch 182/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9715 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2250 - val_loss: 0.9311 - val_binary_accuracy: 0.2612 - val_categorical_accuracy: 0.2392\n",
      "Epoch 183/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9731 - binary_accuracy: 0.2521 - categorical_accuracy: 0.2261 - val_loss: 0.9300 - val_binary_accuracy: 0.2611 - val_categorical_accuracy: 0.2387\n",
      "Epoch 184/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9728 - binary_accuracy: 0.2528 - categorical_accuracy: 0.2299 - val_loss: 0.9289 - val_binary_accuracy: 0.2605 - val_categorical_accuracy: 0.2375\n",
      "Epoch 185/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9755 - binary_accuracy: 0.2519 - categorical_accuracy: 0.2186 - val_loss: 0.9278 - val_binary_accuracy: 0.2607 - val_categorical_accuracy: 0.2342\n",
      "Epoch 186/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9756 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2150 - val_loss: 0.9269 - val_binary_accuracy: 0.2610 - val_categorical_accuracy: 0.2342\n",
      "Epoch 187/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9708 - binary_accuracy: 0.2524 - categorical_accuracy: 0.2256 - val_loss: 0.9258 - val_binary_accuracy: 0.2614 - val_categorical_accuracy: 0.2354\n",
      "Epoch 188/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9688 - binary_accuracy: 0.2517 - categorical_accuracy: 0.2241 - val_loss: 0.9250 - val_binary_accuracy: 0.2609 - val_categorical_accuracy: 0.2375\n",
      "Epoch 189/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9678 - binary_accuracy: 0.2520 - categorical_accuracy: 0.2270 - val_loss: 0.9242 - val_binary_accuracy: 0.2604 - val_categorical_accuracy: 0.2400\n",
      "Epoch 190/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9657 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2222 - val_loss: 0.9231 - val_binary_accuracy: 0.2603 - val_categorical_accuracy: 0.2400\n",
      "Epoch 191/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9713 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2177 - val_loss: 0.9221 - val_binary_accuracy: 0.2601 - val_categorical_accuracy: 0.2379\n",
      "Epoch 192/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9673 - binary_accuracy: 0.2535 - categorical_accuracy: 0.2200 - val_loss: 0.9210 - val_binary_accuracy: 0.2603 - val_categorical_accuracy: 0.2379\n",
      "Epoch 193/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9623 - binary_accuracy: 0.2531 - categorical_accuracy: 0.2194 - val_loss: 0.9197 - val_binary_accuracy: 0.2604 - val_categorical_accuracy: 0.2387\n",
      "Epoch 194/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9564 - binary_accuracy: 0.2526 - categorical_accuracy: 0.2286 - val_loss: 0.9183 - val_binary_accuracy: 0.2600 - val_categorical_accuracy: 0.2404\n",
      "Epoch 195/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9611 - binary_accuracy: 0.2536 - categorical_accuracy: 0.2242 - val_loss: 0.9169 - val_binary_accuracy: 0.2599 - val_categorical_accuracy: 0.2404\n",
      "Epoch 196/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9632 - binary_accuracy: 0.2530 - categorical_accuracy: 0.2277 - val_loss: 0.9155 - val_binary_accuracy: 0.2596 - val_categorical_accuracy: 0.2421\n",
      "Epoch 197/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9543 - binary_accuracy: 0.2533 - categorical_accuracy: 0.2236 - val_loss: 0.9144 - val_binary_accuracy: 0.2597 - val_categorical_accuracy: 0.2404\n",
      "Epoch 198/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9503 - binary_accuracy: 0.2527 - categorical_accuracy: 0.2244 - val_loss: 0.9133 - val_binary_accuracy: 0.2595 - val_categorical_accuracy: 0.2400\n",
      "Epoch 199/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9536 - binary_accuracy: 0.2523 - categorical_accuracy: 0.2221 - val_loss: 0.9123 - val_binary_accuracy: 0.2591 - val_categorical_accuracy: 0.2404\n",
      "Epoch 200/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9533 - binary_accuracy: 0.2516 - categorical_accuracy: 0.2288 - val_loss: 0.9113 - val_binary_accuracy: 0.2587 - val_categorical_accuracy: 0.2400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d93486708>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_4.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40947e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_4.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42e2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keras_model_5():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(64,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dropout(0.25))\n",
    "    keras_model.add(tf.keras.layers.Dense(64,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_5 = generate_keras_model_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e51718",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_5.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam_2, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9d844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9131 - binary_accuracy: 0.2513 - categorical_accuracy: 0.2421 - val_loss: 0.9109 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2479\n",
      "Epoch 146/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9141 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2454 - val_loss: 0.9094 - val_binary_accuracy: 0.2552 - val_categorical_accuracy: 0.2542\n",
      "Epoch 147/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9123 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2548 - val_loss: 0.9093 - val_binary_accuracy: 0.2570 - val_categorical_accuracy: 0.2500\n",
      "Epoch 148/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9132 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2452 - val_loss: 0.9095 - val_binary_accuracy: 0.2558 - val_categorical_accuracy: 0.2438\n",
      "Epoch 149/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9111 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2420 - val_loss: 0.9088 - val_binary_accuracy: 0.2558 - val_categorical_accuracy: 0.2475\n",
      "Epoch 150/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9081 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2522 - val_loss: 0.9077 - val_binary_accuracy: 0.2547 - val_categorical_accuracy: 0.2571\n",
      "Epoch 151/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9114 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2493 - val_loss: 0.9064 - val_binary_accuracy: 0.2569 - val_categorical_accuracy: 0.2479\n",
      "Epoch 152/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9111 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2443 - val_loss: 0.9057 - val_binary_accuracy: 0.2560 - val_categorical_accuracy: 0.2446\n",
      "Epoch 153/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9057 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2441 - val_loss: 0.9050 - val_binary_accuracy: 0.2559 - val_categorical_accuracy: 0.2533\n",
      "Epoch 154/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9082 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2522 - val_loss: 0.9050 - val_binary_accuracy: 0.2556 - val_categorical_accuracy: 0.2529\n",
      "Epoch 155/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9087 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2439 - val_loss: 0.9047 - val_binary_accuracy: 0.2569 - val_categorical_accuracy: 0.2392\n",
      "Epoch 156/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9044 - binary_accuracy: 0.2495 - categorical_accuracy: 0.2412 - val_loss: 0.9030 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2550\n",
      "Epoch 157/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9068 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2498 - val_loss: 0.9025 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2554\n",
      "Epoch 158/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9055 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2549 - val_loss: 0.9014 - val_binary_accuracy: 0.2547 - val_categorical_accuracy: 0.2508\n",
      "Epoch 159/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9046 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2515 - val_loss: 0.9007 - val_binary_accuracy: 0.2570 - val_categorical_accuracy: 0.2479\n",
      "Epoch 160/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9042 - binary_accuracy: 0.2505 - categorical_accuracy: 0.2458 - val_loss: 0.9002 - val_binary_accuracy: 0.2572 - val_categorical_accuracy: 0.2454\n",
      "Epoch 161/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8993 - binary_accuracy: 0.2502 - categorical_accuracy: 0.2402 - val_loss: 0.8994 - val_binary_accuracy: 0.2549 - val_categorical_accuracy: 0.2483\n",
      "Epoch 162/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8987 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2522 - val_loss: 0.8990 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2550\n",
      "Epoch 163/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9028 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2509 - val_loss: 0.8985 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2525\n",
      "Epoch 164/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9016 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2501 - val_loss: 0.8982 - val_binary_accuracy: 0.2558 - val_categorical_accuracy: 0.2467\n",
      "Epoch 165/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9028 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2421 - val_loss: 0.8967 - val_binary_accuracy: 0.2557 - val_categorical_accuracy: 0.2512\n",
      "Epoch 166/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9026 - binary_accuracy: 0.2496 - categorical_accuracy: 0.2569 - val_loss: 0.8957 - val_binary_accuracy: 0.2542 - val_categorical_accuracy: 0.2525\n",
      "Epoch 167/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.9011 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2526 - val_loss: 0.8953 - val_binary_accuracy: 0.2555 - val_categorical_accuracy: 0.2425\n",
      "Epoch 168/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8966 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2398 - val_loss: 0.8941 - val_binary_accuracy: 0.2562 - val_categorical_accuracy: 0.2463\n",
      "Epoch 169/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.9000 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2564 - val_loss: 0.8936 - val_binary_accuracy: 0.2558 - val_categorical_accuracy: 0.2571\n",
      "Epoch 170/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8939 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2574 - val_loss: 0.8948 - val_binary_accuracy: 0.2561 - val_categorical_accuracy: 0.2454\n",
      "Epoch 171/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8929 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2423 - val_loss: 0.8952 - val_binary_accuracy: 0.2546 - val_categorical_accuracy: 0.2417\n",
      "Epoch 172/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8906 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2453 - val_loss: 0.8934 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2583\n",
      "Epoch 173/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8920 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2650 - val_loss: 0.8928 - val_binary_accuracy: 0.2549 - val_categorical_accuracy: 0.2533\n",
      "Epoch 174/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8946 - binary_accuracy: 0.2486 - categorical_accuracy: 0.2516 - val_loss: 0.8928 - val_binary_accuracy: 0.2565 - val_categorical_accuracy: 0.2400\n",
      "Epoch 175/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8927 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2377 - val_loss: 0.8905 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2508\n",
      "Epoch 176/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8902 - binary_accuracy: 0.2466 - categorical_accuracy: 0.2535 - val_loss: 0.8897 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2571\n",
      "Epoch 177/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8941 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2572 - val_loss: 0.8903 - val_binary_accuracy: 0.2545 - val_categorical_accuracy: 0.2446\n",
      "Epoch 178/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8907 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2470 - val_loss: 0.8895 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2417\n",
      "Epoch 179/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8932 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2530 - val_loss: 0.8874 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2571\n",
      "Epoch 180/200\n",
      "9600/9600 [==============================] - 0s 4us/sample - loss: 0.8909 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2586 - val_loss: 0.8873 - val_binary_accuracy: 0.2553 - val_categorical_accuracy: 0.2517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8879 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2474 - val_loss: 0.8874 - val_binary_accuracy: 0.2555 - val_categorical_accuracy: 0.2463\n",
      "Epoch 182/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8886 - binary_accuracy: 0.2485 - categorical_accuracy: 0.2468 - val_loss: 0.8863 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2517\n",
      "Epoch 183/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8914 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2571 - val_loss: 0.8839 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2571\n",
      "Epoch 184/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8917 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2559 - val_loss: 0.8843 - val_binary_accuracy: 0.2564 - val_categorical_accuracy: 0.2454\n",
      "Epoch 185/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8864 - binary_accuracy: 0.2498 - categorical_accuracy: 0.2428 - val_loss: 0.8838 - val_binary_accuracy: 0.2551 - val_categorical_accuracy: 0.2408\n",
      "Epoch 186/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8917 - binary_accuracy: 0.2479 - categorical_accuracy: 0.2485 - val_loss: 0.8833 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2488\n",
      "Epoch 187/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8848 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2574 - val_loss: 0.8832 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2467\n",
      "Epoch 188/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8850 - binary_accuracy: 0.2491 - categorical_accuracy: 0.2510 - val_loss: 0.8821 - val_binary_accuracy: 0.2550 - val_categorical_accuracy: 0.2475\n",
      "Epoch 189/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8913 - binary_accuracy: 0.2493 - categorical_accuracy: 0.2456 - val_loss: 0.8809 - val_binary_accuracy: 0.2545 - val_categorical_accuracy: 0.2442\n",
      "Epoch 190/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8855 - binary_accuracy: 0.2492 - categorical_accuracy: 0.2459 - val_loss: 0.8801 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2521\n",
      "Epoch 191/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8874 - binary_accuracy: 0.2471 - categorical_accuracy: 0.2610 - val_loss: 0.8803 - val_binary_accuracy: 0.2549 - val_categorical_accuracy: 0.2533\n",
      "Epoch 192/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8824 - binary_accuracy: 0.2501 - categorical_accuracy: 0.2486 - val_loss: 0.8808 - val_binary_accuracy: 0.2553 - val_categorical_accuracy: 0.2442\n",
      "Epoch 193/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8833 - binary_accuracy: 0.2484 - categorical_accuracy: 0.2460 - val_loss: 0.8796 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2521\n",
      "Epoch 194/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8813 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2594 - val_loss: 0.8786 - val_binary_accuracy: 0.2546 - val_categorical_accuracy: 0.2533\n",
      "Epoch 195/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8819 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2510 - val_loss: 0.8803 - val_binary_accuracy: 0.2561 - val_categorical_accuracy: 0.2429\n",
      "Epoch 196/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8844 - binary_accuracy: 0.2490 - categorical_accuracy: 0.2455 - val_loss: 0.8795 - val_binary_accuracy: 0.2549 - val_categorical_accuracy: 0.2508\n",
      "Epoch 197/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8810 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2541 - val_loss: 0.8782 - val_binary_accuracy: 0.2546 - val_categorical_accuracy: 0.2529\n",
      "Epoch 198/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8834 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2549 - val_loss: 0.8772 - val_binary_accuracy: 0.2557 - val_categorical_accuracy: 0.2508\n",
      "Epoch 199/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8817 - binary_accuracy: 0.2487 - categorical_accuracy: 0.2491 - val_loss: 0.8764 - val_binary_accuracy: 0.2553 - val_categorical_accuracy: 0.2446\n",
      "Epoch 200/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8800 - binary_accuracy: 0.2489 - categorical_accuracy: 0.2488 - val_loss: 0.8752 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d94c47148>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_5.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d175f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_5.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce859e9",
   "metadata": {},
   "source": [
    "Overall, the 5th Tensorflow model seems to provide the best overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6147e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keras_model_6():\n",
    "    keras_model = tf.keras.Sequential()\n",
    "    keras_model.add(tf.keras.Input(shape=(8,),sparse=False))\n",
    "    keras_model.add(tf.keras.layers.Dense(64,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dropout(0.11))\n",
    "    keras_model.add(tf.keras.layers.Dense(64,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(32,activation=\"relu\", kernel_regularizer = \"l2\"))\n",
    "    keras_model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
    "    return keras_model\n",
    "\n",
    "keras_model_instance_6 = generate_keras_model_6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_6.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opimize_by_adam_2, metrics=set_metrics,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5141188b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8774 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2577 - val_loss: 0.8943 - val_binary_accuracy: 0.2537 - val_categorical_accuracy: 0.2579\n",
      "Epoch 146/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8818 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2636 - val_loss: 0.8926 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2646\n",
      "Epoch 147/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8746 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2653 - val_loss: 0.8919 - val_binary_accuracy: 0.2541 - val_categorical_accuracy: 0.2525\n",
      "Epoch 148/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8751 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2564 - val_loss: 0.8911 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2738\n",
      "Epoch 149/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8773 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2783 - val_loss: 0.8909 - val_binary_accuracy: 0.2515 - val_categorical_accuracy: 0.2575\n",
      "Epoch 150/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8730 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2648 - val_loss: 0.8893 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2579\n",
      "Epoch 151/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8737 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2646 - val_loss: 0.8883 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2642\n",
      "Epoch 152/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8699 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2681 - val_loss: 0.8875 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2637\n",
      "Epoch 153/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8766 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2677 - val_loss: 0.8857 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2679\n",
      "Epoch 154/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8692 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2719 - val_loss: 0.8848 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2587\n",
      "Epoch 155/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8702 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2591 - val_loss: 0.8837 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2621\n",
      "Epoch 156/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8649 - binary_accuracy: 0.2471 - categorical_accuracy: 0.2719 - val_loss: 0.8825 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2692\n",
      "Epoch 157/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8691 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2629 - val_loss: 0.8821 - val_binary_accuracy: 0.2542 - val_categorical_accuracy: 0.2550\n",
      "Epoch 158/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8675 - binary_accuracy: 0.2480 - categorical_accuracy: 0.2599 - val_loss: 0.8801 - val_binary_accuracy: 0.2512 - val_categorical_accuracy: 0.2750\n",
      "Epoch 159/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8690 - binary_accuracy: 0.2467 - categorical_accuracy: 0.2744 - val_loss: 0.8835 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2575\n",
      "Epoch 160/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8682 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2620 - val_loss: 0.8802 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2646\n",
      "Epoch 161/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8588 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2659 - val_loss: 0.8787 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2625\n",
      "Epoch 162/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8615 - binary_accuracy: 0.2467 - categorical_accuracy: 0.2631 - val_loss: 0.8790 - val_binary_accuracy: 0.2530 - val_categorical_accuracy: 0.2612\n",
      "Epoch 163/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8640 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2690 - val_loss: 0.8791 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2625\n",
      "Epoch 164/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8610 - binary_accuracy: 0.2466 - categorical_accuracy: 0.2643 - val_loss: 0.8763 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2625\n",
      "Epoch 165/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8633 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2670 - val_loss: 0.8734 - val_binary_accuracy: 0.2508 - val_categorical_accuracy: 0.2758\n",
      "Epoch 166/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8619 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2714 - val_loss: 0.8760 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2571\n",
      "Epoch 167/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8591 - binary_accuracy: 0.2483 - categorical_accuracy: 0.2544 - val_loss: 0.8732 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2700\n",
      "Epoch 168/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8581 - binary_accuracy: 0.2457 - categorical_accuracy: 0.2807 - val_loss: 0.8717 - val_binary_accuracy: 0.2526 - val_categorical_accuracy: 0.2612\n",
      "Epoch 169/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8617 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2556 - val_loss: 0.8730 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2579\n",
      "Epoch 170/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8616 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2747 - val_loss: 0.8721 - val_binary_accuracy: 0.2509 - val_categorical_accuracy: 0.2775\n",
      "Epoch 171/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8589 - binary_accuracy: 0.2464 - categorical_accuracy: 0.2709 - val_loss: 0.8730 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2483\n",
      "Epoch 172/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8589 - binary_accuracy: 0.2466 - categorical_accuracy: 0.2602 - val_loss: 0.8692 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2758\n",
      "Epoch 173/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8571 - binary_accuracy: 0.2472 - categorical_accuracy: 0.2784 - val_loss: 0.8709 - val_binary_accuracy: 0.2527 - val_categorical_accuracy: 0.2562\n",
      "Epoch 174/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8514 - binary_accuracy: 0.2473 - categorical_accuracy: 0.2554 - val_loss: 0.8689 - val_binary_accuracy: 0.2522 - val_categorical_accuracy: 0.2692\n",
      "Epoch 175/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8545 - binary_accuracy: 0.2470 - categorical_accuracy: 0.2781 - val_loss: 0.8659 - val_binary_accuracy: 0.2523 - val_categorical_accuracy: 0.2688\n",
      "Epoch 176/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8568 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2596 - val_loss: 0.8669 - val_binary_accuracy: 0.2535 - val_categorical_accuracy: 0.2537\n",
      "Epoch 177/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8533 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2645 - val_loss: 0.8659 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2804\n",
      "Epoch 178/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8523 - binary_accuracy: 0.2465 - categorical_accuracy: 0.2761 - val_loss: 0.8681 - val_binary_accuracy: 0.2532 - val_categorical_accuracy: 0.2512\n",
      "Epoch 179/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8506 - binary_accuracy: 0.2478 - categorical_accuracy: 0.2567 - val_loss: 0.8658 - val_binary_accuracy: 0.2534 - val_categorical_accuracy: 0.2675\n",
      "Epoch 180/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8516 - binary_accuracy: 0.2463 - categorical_accuracy: 0.2732 - val_loss: 0.8641 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8505 - binary_accuracy: 0.2469 - categorical_accuracy: 0.2617 - val_loss: 0.8638 - val_binary_accuracy: 0.2531 - val_categorical_accuracy: 0.2600\n",
      "Epoch 182/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8503 - binary_accuracy: 0.2462 - categorical_accuracy: 0.2751 - val_loss: 0.8631 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2617\n",
      "Epoch 183/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8481 - binary_accuracy: 0.2477 - categorical_accuracy: 0.2618 - val_loss: 0.8621 - val_binary_accuracy: 0.2543 - val_categorical_accuracy: 0.2583\n",
      "Epoch 184/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8515 - binary_accuracy: 0.2467 - categorical_accuracy: 0.2667 - val_loss: 0.8593 - val_binary_accuracy: 0.2521 - val_categorical_accuracy: 0.2729\n",
      "Epoch 185/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8482 - binary_accuracy: 0.2451 - categorical_accuracy: 0.2726 - val_loss: 0.8611 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2550\n",
      "Epoch 186/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8464 - binary_accuracy: 0.2468 - categorical_accuracy: 0.2560 - val_loss: 0.8603 - val_binary_accuracy: 0.2536 - val_categorical_accuracy: 0.2704\n",
      "Epoch 187/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8486 - binary_accuracy: 0.2470 - categorical_accuracy: 0.2741 - val_loss: 0.8594 - val_binary_accuracy: 0.2529 - val_categorical_accuracy: 0.2629\n",
      "Epoch 188/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8481 - binary_accuracy: 0.2471 - categorical_accuracy: 0.2600 - val_loss: 0.8589 - val_binary_accuracy: 0.2516 - val_categorical_accuracy: 0.2642\n",
      "Epoch 189/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8465 - binary_accuracy: 0.2463 - categorical_accuracy: 0.2706 - val_loss: 0.8598 - val_binary_accuracy: 0.2540 - val_categorical_accuracy: 0.2663\n",
      "Epoch 190/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8440 - binary_accuracy: 0.2481 - categorical_accuracy: 0.2643 - val_loss: 0.8583 - val_binary_accuracy: 0.2520 - val_categorical_accuracy: 0.2554\n",
      "Epoch 191/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8457 - binary_accuracy: 0.2474 - categorical_accuracy: 0.2605 - val_loss: 0.8563 - val_binary_accuracy: 0.2524 - val_categorical_accuracy: 0.2792\n",
      "Epoch 192/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8427 - binary_accuracy: 0.2462 - categorical_accuracy: 0.2879 - val_loss: 0.8583 - val_binary_accuracy: 0.2539 - val_categorical_accuracy: 0.2579\n",
      "Epoch 193/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8421 - binary_accuracy: 0.2482 - categorical_accuracy: 0.2495 - val_loss: 0.8551 - val_binary_accuracy: 0.2525 - val_categorical_accuracy: 0.2612\n",
      "Epoch 194/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8421 - binary_accuracy: 0.2450 - categorical_accuracy: 0.2808 - val_loss: 0.8533 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2850\n",
      "Epoch 195/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8424 - binary_accuracy: 0.2466 - categorical_accuracy: 0.2786 - val_loss: 0.8606 - val_binary_accuracy: 0.2554 - val_categorical_accuracy: 0.2333\n",
      "Epoch 196/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8441 - binary_accuracy: 0.2488 - categorical_accuracy: 0.2403 - val_loss: 0.8520 - val_binary_accuracy: 0.2519 - val_categorical_accuracy: 0.2829\n",
      "Epoch 197/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8385 - binary_accuracy: 0.2448 - categorical_accuracy: 0.2922 - val_loss: 0.8510 - val_binary_accuracy: 0.2511 - val_categorical_accuracy: 0.2725\n",
      "Epoch 198/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8387 - binary_accuracy: 0.2470 - categorical_accuracy: 0.2696 - val_loss: 0.8555 - val_binary_accuracy: 0.2544 - val_categorical_accuracy: 0.2450\n",
      "Epoch 199/200\n",
      "9600/9600 [==============================] - 0s 3us/sample - loss: 0.8390 - binary_accuracy: 0.2476 - categorical_accuracy: 0.2528 - val_loss: 0.8505 - val_binary_accuracy: 0.2528 - val_categorical_accuracy: 0.2796\n",
      "Epoch 200/200\n",
      "9600/9600 [==============================] - 0s 2us/sample - loss: 0.8386 - binary_accuracy: 0.2452 - categorical_accuracy: 0.2826 - val_loss: 0.8498 - val_binary_accuracy: 0.2517 - val_categorical_accuracy: 0.2646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21d96d30508>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model_instance_6.fit(x_train,y_train, epochs=set_epochs, batch_size=5000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_instance_6.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d99010c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
